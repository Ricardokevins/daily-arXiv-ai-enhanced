{"id": "2506.14900", "pdf": "https://arxiv.org/pdf/2506.14900", "abs": "https://arxiv.org/abs/2506.14900", "authors": ["Imane Guellil", "Salom\u00e9 Andres", "Atul Anand", "Bruce Guthrie", "Huayu Zhang", "Abul Hasan", "Honghan Wu", "Beatrice Alex"], "title": "Adverse Event Extraction from Discharge Summaries: A New Dataset, Annotation Scheme, and Initial Findings", "categories": ["cs.CL"], "comment": "Accepted and will be published at ACL2025 (main conference)", "summary": "In this work, we present a manually annotated corpus for Adverse Event (AE)\nextraction from discharge summaries of elderly patients, a population often\nunderrepresented in clinical NLP resources. The dataset includes 14 clinically\nsignificant AEs-such as falls, delirium, and intracranial haemorrhage, along\nwith contextual attributes like negation, diagnosis type, and in-hospital\noccurrence. Uniquely, the annotation schema supports both discontinuous and\noverlapping entities, addressing challenges rarely tackled in prior work. We\nevaluate multiple models using FlairNLP across three annotation granularities:\nfine-grained, coarse-grained, and coarse-grained with negation. While\ntransformer-based models (e.g., BERT-cased) achieve strong performance on\ndocument-level coarse-grained extraction (F1 = 0.943), performance drops\nnotably for fine-grained entity-level tasks (e.g., F1 = 0.675), particularly\nfor rare events and complex attributes. These results demonstrate that despite\nhigh-level scores, significant challenges remain in detecting underrepresented\nAEs and capturing nuanced clinical language. Developed within a Trusted\nResearch Environment (TRE), the dataset is available upon request via DataLoch\nand serves as a robust benchmark for evaluating AE extraction methods and\nsupporting future cross-dataset generalisation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u9488\u5bf9\u8001\u5e74\u60a3\u8005\u51fa\u9662\u603b\u7ed3\u4e2d\u4e0d\u826f\u4e8b\u4ef6\uff08AE\uff09\u63d0\u53d6\u7684\u624b\u52a8\u6807\u6ce8\u8bed\u6599\u5e93\u3002\u8be5\u8bed\u6599\u5e93\u652f\u6301\u975e\u8fde\u7eed\u548c\u91cd\u53e0\u5b9e\u4f53\u3002\u867d\u7136\u7c97\u7c92\u5ea6\u63d0\u53d6\u6027\u80fd\u826f\u597d\uff0c\u4f46\u7ec6\u7c92\u5ea6\u4efb\u52a1\uff08\u7279\u522b\u662f\u5bf9\u4e8e\u7f55\u89c1\u4e8b\u4ef6\uff09\u4ecd\u9762\u4e34\u663e\u8457\u6311\u6218\uff0c\u7a81\u663e\u4e86\u68c0\u6d4b\u672a\u5145\u5206\u4ee3\u8868\u7684AE\u7684\u9700\u6c42\u3002", "motivation": "\u76ee\u524d\u7f3a\u4e4f\u7528\u4e8e\u8001\u5e74\u60a3\u8005\u51fa\u9662\u603b\u7ed3\u4e2d\u4e0d\u826f\u4e8b\u4ef6\uff08AE\uff09\u63d0\u53d6\u7684\u624b\u52a8\u6807\u6ce8\u8bed\u6599\u5e93\uff0c\u8001\u5e74\u60a3\u8005\u7fa4\u4f53\u5728\u4e34\u5e8aNLP\u8d44\u6e90\u4e2d\u7ecf\u5e38\u4ee3\u8868\u6027\u4e0d\u8db3\u3002\u4e4b\u524d\u7684\u7814\u7a76\u4e5f\u5f88\u5c11\u5904\u7406\u975e\u8fde\u7eed\u548c\u91cd\u53e0\u5b9e\u4f53\u7b49\u6311\u6218\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u624b\u52a8\u6807\u6ce8\u7684\u8bed\u6599\u5e93\uff0c\u7528\u4e8e\u4ece\u8001\u5e74\u60a3\u8005\u51fa\u9662\u603b\u7ed3\u4e2d\u63d0\u53d6\u4e0d\u826f\u4e8b\u4ef6\uff08AE\uff09\u3002\u8be5\u6570\u636e\u96c6\u5305\u542b14\u79cd\u4e34\u5e8a\u4e0a\u91cd\u8981\u4e0d\u826f\u4e8b\u4ef6\u53ca\u5176\u4e0a\u4e0b\u6587\u5c5e\u6027\u3002\u7814\u7a76\u4eba\u5458\u4f7f\u7528FlairNLP\u8bc4\u4f30\u4e86\u591a\u79cd\u6a21\u578b\uff0c\u6db5\u76d6\u4e86\u4e09\u79cd\u6807\u6ce8\u7c92\u5ea6\uff1a\u7ec6\u7c92\u5ea6\u3001\u7c97\u7c92\u5ea6\u4ee5\u53ca\u5e26\u5426\u5b9a\u8bcd\u7684\u7c97\u7c92\u5ea6\u3002", "result": "Transformer\u6a21\u578b\u5728\u6587\u6863\u7ea7\u522b\u7684\u7c97\u7c92\u5ea6\u63d0\u53d6\u4e0a\u8868\u73b0\u51fa\u8272\uff08F1 = 0.943\uff09\uff0c\u4f46\u5728\u7ec6\u7c92\u5ea6\u5b9e\u4f53\u7ea7\u522b\u4efb\u52a1\u4e0a\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff08\u4f8b\u5982F1 = 0.675\uff09\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u7f55\u89c1\u4e8b\u4ef6\u548c\u590d\u6742\u5c5e\u6027\u3002", "conclusion": "\u5c3d\u7ba1\u53d6\u5f97\u4e86\u8f83\u9ad8\u7684\u5206\u6570\uff0c\u4f46\u5728\u68c0\u6d4b\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u4e0d\u826f\u4e8b\u4ef6\u548c\u6355\u83b7\u7ec6\u5fae\u7684\u4e34\u5e8a\u8bed\u8a00\u65b9\u9762\u4ecd\u7136\u5b58\u5728\u91cd\u5927\u6311\u6218\u3002\u8be5\u6570\u636e\u96c6\u53ef\u4f5c\u4e3a\u8bc4\u4f30AE\u63d0\u53d6\u65b9\u6cd5\u7684\u5f3a\u5927\u57fa\u51c6\uff0c\u5e76\u652f\u6301\u672a\u6765\u7684\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u3002"}}
{"id": "2506.14901", "pdf": "https://arxiv.org/pdf/2506.14901", "abs": "https://arxiv.org/abs/2506.14901", "authors": ["Marija \u0160akota", "Robert West"], "title": "Combining Constrained and Unconstrained Decoding via Boosting: BoostCD and Its Application to Information Extraction", "categories": ["cs.CL"], "comment": null, "summary": "Many recent approaches to structured NLP tasks use an autoregressive language\nmodel $M$ to map unstructured input text $x$ to output text $y$ representing\nstructured objects (such as tuples, lists, trees, code, etc.), where the\ndesired output structure is enforced via constrained decoding. During training,\nthese approaches do not require the model to be aware of the constraints, which\nare merely implicit in the training outputs $y$. This is advantageous as it\nallows for dynamic constraints without requiring retraining, but can lead to\nlow-quality output during constrained decoding at test time. We overcome this\nproblem with Boosted Constrained Decoding (BoostCD), which combines constrained\nand unconstrained decoding in two phases: Phase 1 decodes from the base model\n$M$ twice, in constrained and unconstrained mode, obtaining two weak\npredictions. In phase 2, a learned autoregressive boosted model combines the\ntwo weak predictions into one final prediction. The mistakes made by the base\nmodel with vs. without constraints tend to be complementary, which the boosted\nmodel learns to exploit for improved performance. We demonstrate the power of\nBoostCD by applying it to closed information extraction. Our model, BoostIE,\noutperforms prior approaches both in and out of distribution, addressing\nseveral common errors identified in those approaches.", "AI": {"tldr": "\u4e3a\u89e3\u51b3\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u5728\u53d7\u9650\u89e3\u7801\u65f6\u8f93\u51fa\u8d28\u91cf\u4f4e\u7684\u95ee\u9898\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u4e86Boosted Constrained Decoding (BoostCD) \u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u53d7\u9650\u4e0e\u975e\u53d7\u9650\u89e3\u7801\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7ed3\u6784\u5316NLP\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u5e76\u5728\u4fe1\u606f\u62bd\u53d6\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5f53\u524d\u7ed3\u6784\u5316NLP\u4efb\u52a1\u4e2d\uff0c\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u5728\u8bad\u7ec3\u65f6\u4e0d\u611f\u77e5\u7ea6\u675f\u6761\u4ef6\uff0c\u5c3d\u7ba1\u8fd9\u5141\u8bb8\u52a8\u6001\u7ea6\u675f\uff0c\u4f46\u5728\u6d4b\u8bd5\u9636\u6bb5\u8fdb\u884c\u53d7\u9650\u89e3\u7801\u65f6\u53ef\u80fd\u5bfc\u81f4\u8f93\u51fa\u8d28\u91cf\u4f4e\u4e0b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBoosted Constrained Decoding (BoostCD) \u7684\u4e24\u9636\u6bb5\u89e3\u7801\u65b9\u6cd5\u3002\u7b2c\u4e00\u9636\u6bb5\uff0c\u57fa\u7840\u6a21\u578bM\u5206\u522b\u8fdb\u884c\u53d7\u9650\u548c\u975e\u53d7\u9650\u89e3\u7801\uff0c\u5f97\u5230\u4e24\u4e2a\u521d\u6b65\u9884\u6d4b\u3002\u7b2c\u4e8c\u9636\u6bb5\uff0c\u4e00\u4e2a\u5b66\u4e60\u5230\u7684\u81ea\u56de\u5f52\u589e\u5f3a\u6a21\u578b\u7ed3\u5408\u8fd9\u4e24\u4e2a\u521d\u6b65\u9884\u6d4b\uff0c\u751f\u6210\u6700\u7ec8\u9884\u6d4b\u3002", "result": "\u5c06BoostCD\u5e94\u7528\u4e8e\u5c01\u95ed\u4fe1\u606f\u62bd\u53d6\uff0c\u5f97\u5230\u7684\u6a21\u578bBoostIE\u5728\u5206\u5e03\u5185\u548c\u5206\u5e03\u5916\u6027\u80fd\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u89e3\u51b3\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u4e2d\u5e38\u89c1\u7684\u9519\u8bef\u3002", "conclusion": "BoostCD\u901a\u8fc7\u7ed3\u5408\u53d7\u9650\u548c\u975e\u53d7\u9650\u89e3\u7801\uff0c\u6709\u6548\u5229\u7528\u4e86\u57fa\u7840\u6a21\u578b\u5728\u4e0d\u540c\u6a21\u5f0f\u4e0b\u72af\u9519\u7684\u4e92\u8865\u6027\uff0c\u4ece\u800c\u663e\u8457\u63d0\u9ad8\u4e86\u7ed3\u6784\u5316NLP\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2506.14912", "pdf": "https://arxiv.org/pdf/2506.14912", "abs": "https://arxiv.org/abs/2506.14912", "authors": ["Dyah Adila", "Shuai Zhang", "Boran Han", "Bonan Min", "Yuyang Wang"], "title": "CrEst: Credibility Estimation for Contexts in LLMs via Weak Supervision", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "The integration of contextual information has significantly enhanced the\nperformance of large language models (LLMs) on knowledge-intensive tasks.\nHowever, existing methods often overlook a critical challenge: the credibility\nof context documents can vary widely, potentially leading to the propagation of\nunreliable information. In this paper, we introduce CrEst, a novel weakly\nsupervised framework for assessing the credibility of context documents during\nLLM inference--without requiring manual annotations. Our approach is grounded\nin the insight that credible documents tend to exhibit higher semantic\ncoherence with other credible documents, enabling automated credibility\nestimation through inter-document agreement. To incorporate credibility into\nLLM inference, we propose two integration strategies: a black-box approach for\nmodels without access to internal weights or activations, and a white-box\nmethod that directly modifies attention mechanisms. Extensive experiments\nacross three model architectures and five datasets demonstrate that CrEst\nconsistently outperforms strong baselines, achieving up to a 26.86% improvement\nin accuracy and a 3.49% increase in F1 score. Further analysis shows that CrEst\nmaintains robust performance even under high-noise conditions.", "AI": {"tldr": "CrEst\u662f\u4e00\u4e2a\u65b0\u7684\u5f31\u76d1\u7763\u6846\u67b6\uff0c\u901a\u8fc7\u8bc4\u4f30\u6587\u6863\u95f4\u7684\u8bed\u4e49\u4e00\u81f4\u6027\u6765\u81ea\u52a8\u8bc4\u4f30LLM\u4e0a\u4e0b\u6587\u6587\u6863\u7684\u53ef\u4fe1\u5ea6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86LLM\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u5c24\u5176\u5728\u9ad8\u566a\u58f0\u73af\u5883\u4e0b\u8868\u73b0\u7a33\u5065\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u4e86\u4e0a\u4e0b\u6587\u6587\u6863\u53ef\u4fe1\u5ea6\u5dee\u5f02\u5927\u7684\u95ee\u9898\uff0c\u53ef\u80fd\u5bfc\u81f4\u4e0d\u53ef\u9760\u4fe1\u606f\u7684\u4f20\u64ad\u3002", "method": "\u5f15\u5165CrEst\uff0c\u4e00\u4e2a\u65b0\u578b\u5f31\u76d1\u7763\u6846\u67b6\uff0c\u7528\u4e8e\u5728LLM\u63a8\u7406\u8fc7\u7a0b\u4e2d\u8bc4\u4f30\u4e0a\u4e0b\u6587\u6587\u6863\u7684\u53ef\u4fe1\u5ea6\uff0c\u65e0\u9700\u624b\u52a8\u6807\u6ce8\u3002\u57fa\u4e8e\u53ef\u4fe1\u6587\u6863\u4e0e\u5176\u4ed6\u53ef\u4fe1\u6587\u6863\u8bed\u4e49\u4e00\u81f4\u6027\u66f4\u9ad8\u7684\u6d1e\u5bdf\uff0c\u901a\u8fc7\u6587\u6863\u95f4\u4e00\u81f4\u6027\u5b9e\u73b0\u81ea\u52a8\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u3002\u63d0\u51fa\u4e86\u4e24\u79cd\u6574\u5408\u7b56\u7565\uff1a\u9ed1\u76d2\u65b9\u6cd5\u548c\u767d\u76d2\u65b9\u6cd5\u3002", "result": "\u5728\u4e09\u79cd\u6a21\u578b\u67b6\u6784\u548c\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\uff0cCrEst\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u51c6\u786e\u7387\u63d0\u9ad8\u9ad8\u8fbe26.86%\uff0cF1\u5206\u6570\u63d0\u9ad83.49%\u3002\u5728\u9ad8\u5ea6\u566a\u58f0\u6761\u4ef6\u4e0b\u4ecd\u4fdd\u6301\u7a33\u5065\u6027\u80fd\u3002", "conclusion": "CrEst\u6709\u6548\u89e3\u51b3\u4e86LLM\u63a8\u7406\u4e2d\u4e0a\u4e0b\u6587\u6587\u6863\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u5e76\u5728\u590d\u6742\u73af\u5883\u4e0b\u8868\u73b0\u7a33\u5065\u3002"}}
{"id": "2506.14927", "pdf": "https://arxiv.org/pdf/2506.14927", "abs": "https://arxiv.org/abs/2506.14927", "authors": ["Joseph J. Peper", "Wenzhao Qiu", "Ali Payani", "Lu Wang"], "title": "MDBench: A Synthetic Multi-Document Reasoning Benchmark Generated with Knowledge Guidance", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025 Findings", "summary": "Natural language processing evaluation has made significant progress, largely\ndriven by the proliferation of powerful large language mod-els (LLMs). New\nevaluation benchmarks are of increasing priority as the reasoning capabilities\nof LLMs are expanding at a rapid pace. In particular, while multi-document (MD)\nreasoning is an area of extreme relevance given LLM capabilities in handling\nlonger-context inputs, few benchmarks exist to rigorously examine model\nbehavior in this setting. Moreover, the multi-document setting is historically\nchallenging for benchmark creation due to the expensive cost of annotating long\ninputs. In this work, we introduce MDBench, a new dataset for evaluating LLMs\non the task of multi-document reasoning. Notably, MDBench is created through a\nnovel synthetic generation process, allowing us to controllably and efficiently\ngenerate challenging document sets and the corresponding question-answer (QA)\nexamples. Our novel technique operates on condensed structured seed knowledge,\nmodifying it through LLM-assisted edits to induce MD-specific reasoning\nchallenges. We then convert this structured knowledge into a natural text\nsurface form, generating a document set and corresponding QA example. We\nanalyze the behavior of popular LLMs and prompting techniques, finding that\nMDBENCH poses significant challenges for all methods, even with relatively\nshort document sets. We also see our knowledge-guided generation technique (1)\nallows us to readily perform targeted analysis of MD-specific reasoning\ncapabilities and (2) can be adapted quickly to account for new challenges and\nfuture modeling improvements.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86MDBench\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u591a\u6587\u6863\u63a8\u7406\u80fd\u529b\u7684\u65b0\u6570\u636e\u96c6\u3002MDBench\u901a\u8fc7\u65b0\u9896\u7684\u5408\u6210\u751f\u6210\u8fc7\u7a0b\u521b\u5efa\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u57fa\u51c6\u7a00\u7f3a\u548c\u6807\u6ce8\u6210\u672c\u9ad8\u6602\u7684\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0cMDBench\u5bf9\u73b0\u6709LLMs\u6784\u6210\u4e86\u663e\u8457\u6311\u6218\uff0c\u5e76\u4e14\u5176\u751f\u6210\u65b9\u6cd5\u652f\u6301\u6709\u9488\u5bf9\u6027\u7684\u5206\u6790\u548c\u5feb\u901f\u9002\u5e94\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u8f93\u5165\u65b9\u9762\u80fd\u529b\u65e5\u76ca\u589e\u5f3a\uff0c\u4f46\u5728\u591a\u6587\u6863\uff08MD\uff09\u63a8\u7406\u9886\u57df\uff0c\u7f3a\u4e4f\u8db3\u591f\u4e25\u683c\u7684\u8bc4\u4f30\u57fa\u51c6\u3002\u6b64\u5916\uff0c\u7531\u4e8e\u957f\u6587\u672c\u6807\u6ce8\u6210\u672c\u9ad8\u6602\uff0c\u591a\u6587\u6863\u57fa\u51c6\u7684\u521b\u5efa\u9762\u4e34\u6311\u6218\u3002", "method": "\u672c\u6587\u5f15\u5165\u4e86MDBench\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u65b0\u9896\u7684\u5408\u6210\u751f\u6210\u8fc7\u7a0b\u521b\u5efa\uff0c\u4ee5\u53ef\u63a7\u4e14\u9ad8\u6548\u7684\u65b9\u5f0f\u751f\u6210\u5177\u6709\u6311\u6218\u6027\u7684\u6587\u6863\u96c6\u548c\u76f8\u5e94\u7684\u95ee\u7b54\uff08QA\uff09\u793a\u4f8b\u3002\u8be5\u65b9\u6cd5\u57fa\u4e8e\u6d53\u7f29\u7684\u7ed3\u6784\u5316\u79cd\u5b50\u77e5\u8bc6\uff0c\u901a\u8fc7LLM\u8f85\u52a9\u7f16\u8f91\u5f15\u5165\u591a\u6587\u6863\u7279\u6709\u7684\u63a8\u7406\u6311\u6218\uff0c\u7136\u540e\u5c06\u8fd9\u4e9b\u7ed3\u6784\u5316\u77e5\u8bc6\u8f6c\u6362\u4e3a\u81ea\u7136\u6587\u672c\u5f62\u5f0f\u3002", "result": "MDBench\u5bf9\u6240\u6709\u6d41\u884c\u7684LLMs\u548c\u63d0\u793a\u6280\u672f\u90fd\u6784\u6210\u4e86\u91cd\u5927\u6311\u6218\uff0c\u5373\u4f7f\u6587\u6863\u96c6\u76f8\u5bf9\u8f83\u77ed\u3002\u6b64\u5916\uff0c\u6240\u63d0\u51fa\u7684\u77e5\u8bc6\u5f15\u5bfc\u751f\u6210\u6280\u672f\uff081\uff09\u80fd\u591f\u5bf9MD\u7279\u5b9a\u63a8\u7406\u80fd\u529b\u8fdb\u884c\u6709\u9488\u5bf9\u6027\u7684\u5206\u6790\uff0c\u5e76\u4e14\uff082\uff09\u53ef\u4ee5\u5feb\u901f\u9002\u5e94\u65b0\u7684\u6311\u6218\u548c\u672a\u6765\u7684\u6a21\u578b\u6539\u8fdb\u3002", "conclusion": "MDBench\u662f\u4e00\u4e2a\u6709\u6548\u4e14\u5177\u6709\u6311\u6218\u6027\u7684\u591a\u6587\u6863\u63a8\u7406\u8bc4\u4f30\u57fa\u51c6\uff0c\u5176\u5408\u6210\u751f\u6210\u65b9\u6cd5\u514b\u670d\u4e86\u4f20\u7edf\u57fa\u51c6\u521b\u5efa\u6210\u672c\u9ad8\u6602\u7684\u95ee\u9898\u3002\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u5f53\u524dLLMs\u5728\u591a\u6587\u6863\u63a8\u7406\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u79cd\u9002\u5e94\u6027\u5f3a\u7684\u5206\u6790\u5de5\u5177\u3002"}}
{"id": "2506.14949", "pdf": "https://arxiv.org/pdf/2506.14949", "abs": "https://arxiv.org/abs/2506.14949", "authors": ["Shadman Sakib", "Oishy Fatema Akhand", "Ajwad Abrar"], "title": "From Chat to Checkup: Can Large Language Models Assist in Diabetes Prediction?", "categories": ["cs.CL"], "comment": "Accepted in 1st IEEE QPAIN 2025", "summary": "While Machine Learning (ML) and Deep Learning (DL) models have been widely\nused for diabetes prediction, the use of Large Language Models (LLMs) for\nstructured numerical data is still not well explored. In this study, we test\nthe effectiveness of LLMs in predicting diabetes using zero-shot, one-shot, and\nthree-shot prompting methods. We conduct an empirical analysis using the Pima\nIndian Diabetes Database (PIDD). We evaluate six LLMs, including four\nopen-source models: Gemma-2-27B, Mistral-7B, Llama-3.1-8B, and Llama-3.2-2B. We\nalso test two proprietary models: GPT-4o and Gemini Flash 2.0. In addition, we\ncompare their performance with three traditional machine learning models:\nRandom Forest, Logistic Regression, and Support Vector Machine (SVM). We use\naccuracy, precision, recall, and F1-score as evaluation metrics. Our results\nshow that proprietary LLMs perform better than open-source ones, with GPT-4o\nand Gemma-2-27B achieving the highest accuracy in few-shot settings. Notably,\nGemma-2-27B also outperforms the traditional ML models in terms of F1-score.\nHowever, there are still issues such as performance variation across prompting\nstrategies and the need for domain-specific fine-tuning. This study shows that\nLLMs can be useful for medical prediction tasks and encourages future work on\nprompt engineering and hybrid approaches to improve healthcare predictions.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u7cd6\u5c3f\u75c5\u9884\u6d4b\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0\u4e13\u6709LLMs\u4f18\u4e8e\u5f00\u6e90LLMs\uff0c\u90e8\u5206LLMs\u751a\u81f3\u8d85\u8d8a\u4e86\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002", "motivation": "\u76ee\u524d\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u548c\u6df1\u5ea6\u5b66\u4e60\uff08DL\uff09\u6a21\u578b\u5df2\u5e7f\u6cdb\u7528\u4e8e\u7cd6\u5c3f\u75c5\u9884\u6d4b\uff0c\u4f46\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u7ed3\u6784\u5316\u6570\u503c\u6570\u636e\u4e0a\u7684\u5e94\u7528\u63a2\u7d22\u4e0d\u8db3\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u96f6\u6837\u672c\u3001\u5355\u6837\u672c\u548c\u4e09\u6837\u672c\u63d0\u793a\u65b9\u6cd5\uff0c\u6d4b\u8bd5\u4e86\u516d\u79cdLLMs\uff08\u5305\u62ec\u56db\u79cd\u5f00\u6e90\u6a21\u578b\u548c\u4e24\u79cd\u4e13\u6709\u6a21\u578b\uff09\u5728Pima\u5370\u7b2c\u5b89\u7cd6\u5c3f\u75c5\u6570\u636e\u5e93\uff08PIDD\uff09\u4e0a\u9884\u6d4b\u7cd6\u5c3f\u75c5\u7684\u6709\u6548\u6027\u3002\u540c\u65f6\uff0c\u5c06LLMs\u7684\u6027\u80fd\u4e0e\u4e09\u79cd\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08\u968f\u673a\u68ee\u6797\u3001\u903b\u8f91\u56de\u5f52\u548c\u652f\u6301\u5411\u91cf\u673a\uff09\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u8bc4\u4f30\u6307\u6807\u5305\u62ec\u51c6\u786e\u7387\u3001\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u4e13\u6709LLMs\u7684\u8868\u73b0\u4f18\u4e8e\u5f00\u6e90LLMs\uff0c\u5176\u4e2dGPT-4o\u548cGemma-2-27B\u5728\u5c11\u6837\u672c\u8bbe\u7f6e\u4e2d\u83b7\u5f97\u4e86\u6700\u9ad8\u7684\u51c6\u786e\u7387\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0cGemma-2-27B\u5728F1\u5206\u6570\u65b9\u9762\u4e5f\u8d85\u8d8a\u4e86\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002\u7136\u800c\uff0c\u4ecd\u5b58\u5728\u63d0\u793a\u7b56\u7565\u95f4\u6027\u80fd\u5dee\u5f02\u4ee5\u53ca\u9700\u8981\u8fdb\u884c\u9886\u57df\u7279\u5b9a\u5fae\u8c03\u7b49\u95ee\u9898\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660eLLMs\u53ef\u7528\u4e8e\u533b\u7597\u9884\u6d4b\u4efb\u52a1\uff0c\u5e76\u9f13\u52b1\u672a\u6765\u7684\u7814\u7a76\u5728\u63d0\u793a\u5de5\u7a0b\u548c\u6df7\u5408\u65b9\u6cd5\u65b9\u9762\u8fdb\u884c\u63a2\u7d22\uff0c\u4ee5\u6539\u8fdb\u533b\u7597\u5065\u5eb7\u9884\u6d4b\u3002"}}
{"id": "2506.15001", "pdf": "https://arxiv.org/pdf/2506.15001", "abs": "https://arxiv.org/abs/2506.15001", "authors": ["Ignacio Sastre", "Aiala Ros\u00e1"], "title": "Memory Tokens: Large Language Models Can Generate Reversible Sentence Embeddings", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "This paper will be presented at The First Workshop on Large Language\n  Model Memorization (L2M2) at ACL 2025", "summary": "In this work, we observe an interesting phenomenon: it is possible to\ngenerate reversible sentence embeddings that allow an LLM to reconstruct the\noriginal text exactly, without modifying the model's weights. This is achieved\nby introducing a special memory token, whose embedding is optimized through\ntraining on a fixed sequence. When prompted with this embedding, the model\nreconstructs the fixed sequence exactly. We evaluate this phenomenon across\nEnglish and Spanish datasets, sequences of up to approximately 240 tokens, and\nmodel scales ranging from 100M to 8B parameters. Notably, Llama 3.1 8B\nsuccessfully reconstructs all tested sequences. Our findings highlight an\ninteresting capability of LLMs and suggest potential applications in\nmemory-based retrieval, compression, and controlled text generation.", "AI": {"tldr": "\u901a\u8fc7\u4f18\u5316\u7279\u6b8a\u8bb0\u5fc6token\u7684\u5d4c\u5165\uff0cLLM\u65e0\u9700\u4fee\u6539\u6a21\u578b\u6743\u91cd\u5373\u53ef\u7cbe\u786e\u91cd\u5efa\u539f\u59cb\u6587\u672c\uff0c\u5c55\u793a\u4e86LLM\u7684\u65b0\u80fd\u529b\uff0c\u5728\u8bb0\u5fc6\u68c0\u7d22\u3001\u538b\u7f29\u548c\u53d7\u63a7\u6587\u672c\u751f\u6210\u65b9\u9762\u6709\u6f5c\u5728\u5e94\u7528\u3002", "motivation": "\u63a2\u7d22\u4e00\u79cd\u65e0\u9700\u4fee\u6539LLM\u6a21\u578b\u6743\u91cd\u5373\u53ef\u751f\u6210\u53ef\u9006\u53e5\u5b50\u5d4c\u5165\u7684\u65b9\u6cd5\uff0c\u4f7fLLM\u80fd\u591f\u7cbe\u786e\u91cd\u5efa\u539f\u59cb\u6587\u672c\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u7279\u6b8a\u7684\u8bb0\u5fc6token\uff0c\u901a\u8fc7\u5728\u56fa\u5b9a\u5e8f\u5217\u4e0a\u8bad\u7ec3\u6765\u4f18\u5316\u5176\u5d4c\u5165\u3002\u5f53\u7528\u8fd9\u4e2a\u5d4c\u5165\u8fdb\u884c\u63d0\u793a\u65f6\uff0c\u6a21\u578b\u80fd\u591f\u7cbe\u786e\u91cd\u5efa\u8be5\u56fa\u5b9a\u5e8f\u5217\u3002", "result": "\u5728\u82f1\u8bed\u548c\u897f\u73ed\u7259\u8bed\u6570\u636e\u96c6\u4e0a\uff0c\u5bf9\u957f\u8fbe\u7ea6240\u4e2atoken\u7684\u5e8f\u5217\u4ee5\u53ca\u4ece100M\u52308B\u53c2\u6570\u7684\u6a21\u578b\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002Llama 3.1 8B\u6210\u529f\u91cd\u5efa\u4e86\u6240\u6709\u6d4b\u8bd5\u5e8f\u5217\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u7a81\u51fa\u4e86LLM\u7684\u4e00\u9879\u6709\u8da3\u80fd\u529b\uff0c\u5e76\u8868\u660e\u5176\u5728\u57fa\u4e8e\u8bb0\u5fc6\u7684\u68c0\u7d22\u3001\u538b\u7f29\u548c\u53d7\u63a7\u6587\u672c\u751f\u6210\u65b9\u9762\u5177\u6709\u6f5c\u5728\u5e94\u7528\u3002"}}
