<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Outcome-Based Education: Evaluating Students' Perspectives Using Transformer](https://arxiv.org/abs/2506.17223)
*Shuvra Smaran Das,Anirban Saha Anik,Md Kishor Morol,Mohammad Sakib Mahmood*

Main category: cs.CL

TL;DR: 本文利用DistilBERT和LIME分析学生反馈，为成果导向教育（OBE）提供了一个强大且可解释的框架，以改进教育成果。


<details>
  <summary>Details</summary>
Motivation: 评估和改进教育成果，特别是通过识别学生学习经历中的模式，以实现成果导向教育（OBE）的可衡量目标。

Method: 使用基于Transformer的模型（特别是DistilBERT）来分析包含学生反馈的NLP数据集，并应用LIME来解释模型预测。

Result: 结合Transformer模型和LIME解释，形成了一个强大而直接的框架，用于分析学生反馈，其性能优于其他机器学习模型。

Conclusion: 该框架与成果导向教育（OBE）的原则更紧密地结合，并通过数据驱动的见解确保教育实践的改进。

Abstract: Outcome-Based Education (OBE) emphasizes the development of specific
competencies through student-centered learning. In this study, we reviewed the
importance of OBE and implemented transformer-based models, particularly
DistilBERT, to analyze an NLP dataset that includes student feedback. Our
objective is to assess and improve educational outcomes. Our approach is better
than other machine learning models because it uses the transformer's deep
understanding of language context to classify sentiment better, giving better
results across a wider range of matrices. Our work directly contributes to
OBE's goal of achieving measurable outcomes by facilitating the identification
of patterns in student learning experiences. We have also applied LIME (local
interpretable model-agnostic explanations) to make sure that model predictions
are clear. This gives us understandable information about how key terms affect
sentiment. Our findings indicate that the combination of transformer models and
LIME explanations results in a strong and straightforward framework for
analyzing student feedback. This aligns more closely with the principles of OBE
and ensures the improvement of educational practices through data-driven
insights.

</details>


### [2] [Efficient and Stealthy Jailbreak Attacks via Adversarial Prompt Distillation from LLMs to SLMs](https://arxiv.org/abs/2506.17231)
*Xiang Li,Chong Zhang,Jia Wang,Fangyu Wu,Yushi Li,Xiaobo Jin*

Main category: cs.CL

TL;DR: 提出一种对抗性提示蒸馏方法，使小型语言模型能够有效越狱大型语言模型，提高了攻击效率和跨模型适应性，并揭示了模型漏洞，为LLM安全研究提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 当前针对大型语言模型的越狱攻击方法存在效率低、计算成本高以及跨模型适应性和通用性差的问题，难以应对大型语言模型的快速发展和新的防御策略。

Method: 本文提出了一种对抗性提示蒸馏方法，该方法通过提示生成和蒸馏，结合了掩蔽语言建模、强化学习和动态温度控制。

Result: 实验结果验证了所提出方法在攻击成功率和危害性方面的优越性，并体现了资源效率和跨模型适应性。

Conclusion: 这项研究探索了将大型语言模型（LLM）的越狱能力蒸馏到小型语言模型（SLM）的可行性，揭示了模型的脆弱性，并为LLM安全研究提供了新的思路。

Abstract: Attacks on large language models (LLMs) in jailbreaking scenarios raise many
security and ethical issues. Current jailbreak attack methods face problems
such as low efficiency, high computational cost, and poor cross-model
adaptability and versatility, which make it difficult to cope with the rapid
development of LLM and new defense strategies. Our work proposes an Adversarial
Prompt Distillation, which combines masked language modeling, reinforcement
learning, and dynamic temperature control through a prompt generation and
distillation method. It enables small language models (SLMs) to jailbreak
attacks on mainstream LLMs. The experimental results verify the superiority of
the proposed method in terms of attack success rate and harm, and reflect the
resource efficiency and cross-model adaptability. This research explores the
feasibility of distilling the jailbreak ability of LLM to SLM, reveals the
model's vulnerability, and provides a new idea for LLM security research.

</details>
