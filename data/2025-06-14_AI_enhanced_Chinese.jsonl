{"id": "2506.10019", "pdf": "https://arxiv.org/pdf/2506.10019", "abs": "https://arxiv.org/abs/2506.10019", "authors": ["Tian Lan", "Yang-Hao Zhou", "Zi-Ao Ma", "Fanshu Sun", "Rui-Qing Sun", "Junyu Luo", "Rong-Cheng Tu", "Heyan Huang", "Chen Xu", "Zhijing Wu", "Xian-Ling Mao"], "title": "A Survey of Automatic Evaluation Methods on Text, Visual and Speech Generations", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Recent advances in deep learning have significantly enhanced generative AI\ncapabilities across text, images, and audio. However, automatically evaluating\nthe quality of these generated outputs presents ongoing challenges. Although\nnumerous automatic evaluation methods exist, current research lacks a\nsystematic framework that comprehensively organizes these methods across text,\nvisual, and audio modalities. To address this issue, we present a comprehensive\nreview and a unified taxonomy of automatic evaluation methods for generated\ncontent across all three modalities; We identify five fundamental paradigms\nthat characterize existing evaluation approaches across these domains. Our\nanalysis begins by examining evaluation methods for text generation, where\ntechniques are most mature. We then extend this framework to image and audio\ngeneration, demonstrating its broad applicability. Finally, we discuss\npromising directions for future research in cross-modal evaluation\nmethodologies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8de8\u6a21\u6001\u751f\u6210\u5185\u5bb9\u81ea\u52a8\u8bc4\u4f30\u65b9\u6cd5\u7684\u7edf\u4e00\u5206\u7c7b\u6846\u67b6\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u4e00\u4e2a\u7cfb\u7edf\u6027\u7684\u6846\u67b6\u6765\u7ec4\u7ec7\u8de8\u6587\u672c\u3001\u89c6\u89c9\u548c\u97f3\u9891\u6a21\u6001\u7684\u751f\u6210\u5185\u5bb9\u81ea\u52a8\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5c3d\u7ba1\u6df1\u5ea6\u5b66\u4e60\u5728\u751f\u6210\u5f0fAI\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u8bc4\u4f30\u751f\u6210\u5185\u5bb9\u8d28\u91cf\u4ecd\u5177\u6311\u6218\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u8bc4\u4f30\u65b9\u6cd5\u5206\u7c7b\u6846\u67b6\uff0c\u6db5\u76d6\u6587\u672c\u3001\u56fe\u50cf\u548c\u97f3\u9891\u6a21\u6001\uff0c\u5e76\u8bc6\u522b\u4e86\u4e94\u79cd\u57fa\u672c\u8bc4\u4f30\u8303\u5f0f\u3002", "result": "\u8be5\u6846\u67b6\u9996\u5148\u5ba1\u89c6\u4e86\u6587\u672c\u751f\u6210\u8bc4\u4f30\u65b9\u6cd5\uff0c\u7136\u540e\u5c06\u5176\u6269\u5c55\u5230\u56fe\u50cf\u548c\u97f3\u9891\u751f\u6210\uff0c\u5c55\u793a\u4e86\u5176\u5e7f\u6cdb\u9002\u7528\u6027\u3002", "conclusion": "\u8bba\u6587\u8ba8\u8bba\u4e86\u8de8\u6a21\u6001\u8bc4\u4f30\u65b9\u6cd5\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
