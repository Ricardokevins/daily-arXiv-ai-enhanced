<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 38]
- [cs.SD](#cs.SD) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.CV](#cs.CV) [Total: 3]
- [cs.AI](#cs.AI) [Total: 5]
- [cs.LG](#cs.LG) [Total: 8]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Towards Probabilistic Question Answering Over Tabular Data](https://arxiv.org/abs/2506.20747)
*Chen Shen,Sajjadur Rahman,Estevam Hruschka*

Main category: cs.CL

TL;DR: 本文介绍了一个针对表格数据概率问答的新基准LUCARIO和一个框架，该框架通过从表格中推断贝叶斯网络并将自然语言查询转换为概率查询来解决问题，并利用大型语言模型生成答案。实验结果表明，该方法显著优于基线，突出了混合符号-神经推理的优势。


<details>
  <summary>Details</summary>
Motivation: 现有的表格数据问答方法（如NL2SQL系统）在处理需要不确定性推理的概率性问题时表现不佳。

Method: 提出一个新的基准LUCARIO和一个概率问答框架。该方法从表格中推断贝叶斯网络，将自然语言查询转换为概率查询，并利用大型语言模型（LLMs）生成最终答案。

Result: 实验结果表明，该方法显著优于基线。

Conclusion: 混合符号-神经推理（hybrid symbolic-neural reasoning）在概率问答中具有显著优势。

Abstract: Current approaches for question answering (QA) over tabular data, such as
NL2SQL systems, perform well for factual questions where answers are directly
retrieved from tables. However, they fall short on probabilistic questions
requiring reasoning under uncertainty. In this paper, we introduce a new
benchmark LUCARIO and a framework for probabilistic QA over large tabular data.
Our method induces Bayesian Networks from tables, translates natural language
queries into probabilistic queries, and uses large language models (LLMs) to
generate final answers. Empirical results demonstrate significant improvements
over baselines, highlighting the benefits of hybrid symbolic-neural reasoning.

</details>


### [2] [Multi-lingual Functional Evaluation for Large Language Models](https://arxiv.org/abs/2506.20793)
*Victor Ojewale,Inioluwa Deborah Raji,Suresh Venkatasubramanian*

Main category: cs.CL

TL;DR: 现有的大型语言模型多语言基准测试不足以评估实际性能和鲁棒性。本文创建了新的跨语言功能基准测试，结果表明静态基准测试在反映实际功能性能方面存在显著差异，且模型在不同语言间的鲁棒性也各不相同。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型多语言能力评估通常通过静态数据基准进行，但这些评估未能充分理解模型在多语言环境下的实际性能和鲁棒性。

Method: 通过将现有的功能基准模板从英语翻译成法语、西班牙语、印地语、阿拉伯语和约鲁巴语等五种额外语言，创建了多语言功能基准测试——跨语言小学数学符号（CL-GSM Symbolic）和跨语言指令遵循评估（CL-IFEval）。

Result: 结果显示，某些静态多语言基准测试比其他测试更能捕捉功能性能（例如，M-GSM 和 CL-GSM Symbolic 之间在英语、法语和西班牙语中的性能分别下降了24%、17%和18%；Belebele 和 CL-IFEval 之间在不同语言中性能下降了15-24%；而 M-MMLU 和 CL-IFEval 之间仅下降了0.5%-3%）。同时，模型在不同语言间的鲁棒性差异显著，某些语言（如阿拉伯语、英语）在评估迭代中表现最稳定。

Conclusion: 静态多语言基准测试在捕捉大型语言模型的实际功能性能和跨语言鲁棒性方面存在局限性，功能性基准测试提供了更深入的评估视角，并揭示了模型在不同语言间表现的不一致性。

Abstract: Multi-lingual competence in large language models is often evaluated via
static data benchmarks such as Belebele, M-MMLU and M-GSM. However, these
evaluations often fail to provide an adequate understanding of the practical
performance and robustness of models across multi-lingual settings. In
response, we create multi-lingual functional benchmarks -- Cross-Lingual Grade
School Math Symbolic (CL-GSM Symbolic) and Cross-Lingual Instruction-Following
Eval (CL-IFEval)-- by translating existing functional benchmark templates from
English to five additional languages that span the range of resources available
for NLP: French, Spanish, Hindi, Arabic and Yoruba. Our results reveal that
some static multi-lingual benchmarks capture functional performance much more
closely than others (i.e. across models, there is a 24%, 17% and 18% decrease
in performance between M-GSM and CL-GSM Symbolic in English, French and Spanish
respectively; similarly there's a 15 - 24% performance drop across languages
between Belebele and CL-IFEval, and only a 0.5% to 3% performance drop between
M-MMLU and CL-IFEval). Similarly, we find that model robustness across
languages varies significantly, with certain languages (eg. Arabic, English)
being the most consistently well performing across evaluation iterations.

</details>


### [3] [The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus Human Research Ideas](https://arxiv.org/abs/2506.20803)
*Chenglei Si,Tatsunori Hashimoto,Diyi Yang*

Main category: cs.CL

TL;DR: LLM生成的想法在执行后表现不如人类生成的想法，揭示了当前LLM在产生有效研究想法方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 以往研究发现LLM生成的想法可能比人类专家的想法更具新颖性，但一个好的想法不仅要看起来新颖，还要在执行后带来更好的研究成果。本研究旨在测试AI生成的想法是否能带来更好的研究成果。

Method: 招募43位专家研究人员执行随机分配的想法（专家编写或LLM生成），每位专家花费超过100小时实施想法并撰写4页短论文，随后由NLP专家盲审所有已执行的项目。

Result: 与执行前相比，LLM生成想法的评分在所有评估指标（新颖性、兴奋度、有效性和整体）上均显著下降，且下降幅度远大于专家编写的想法。执行研究的汇总评分甚至显示，在许多指标上，人类想法的排名高于LLM想法。

Conclusion: 这种构思-执行差距突出了当前LLM在生成真正有效的研究想法方面的局限性，以及在没有执行结果的情况下评估研究想法的挑战。

Abstract: Large Language Models (LLMs) have shown promise in accelerating the
scientific research pipeline. A key capability for this process is the ability
to generate novel research ideas, and prior studies have found settings in
which LLM-generated research ideas were judged as more novel than human-expert
ideas. However, a good idea should not simply appear to be novel, it should
also result in better research after being executed. To test whether
AI-generated ideas lead to better research outcomes, we conduct an execution
study by recruiting 43 expert researchers to execute randomly-assigned ideas,
either written by experts or generated by an LLM. Each expert spent over 100
hours implementing the idea and wrote a 4-page short paper to document the
experiments. All the executed projects are then reviewed blindly by expert NLP
researchers. Comparing the review scores of the same ideas before and after
execution, the scores of the LLM-generated ideas decrease significantly more
than expert-written ideas on all evaluation metrics (novelty, excitement,
effectiveness, and overall; p < 0.05), closing the gap between LLM and human
ideas observed at the ideation stage. When comparing the aggregated review
scores from the execution study, we even observe that for many metrics there is
a flip in rankings where human ideas score higher than LLM ideas. This
ideation-execution gap highlights the limitations of current LLMs in generating
truly effective research ideas and the challenge of evaluating research ideas
in the absence of execution outcomes.

</details>


### [4] [MultiFinRAG: An Optimized Multimodal Retrieval-Augmented Generation (RAG) Framework for Financial Question Answering](https://arxiv.org/abs/2506.20821)
*Chinmay Gondhalekar,Urjitkumar Patel,Fang-Chun Yeh*

Main category: cs.CL

TL;DR: MultiFinRAG是一个为金融问答设计的检索增强生成框架，通过处理多模态数据（文本、表格、图像）解决了传统大语言模型和RAG管道的局限性，在金融QA任务中比ChatGPT-4o的准确率高出19%。


<details>
  <summary>Details</summary>
Motivation: 传统的LLM和RAG管道在处理金融文档时，由于令牌限制、布局丢失和碎片化的跨模态上下文，难以回答需要跨模态推理的问题。

Method: 本文引入了MultiFinRAG框架。它首先使用轻量级、量化的开源多模态LLM对表格和图像进行多模态提取，生成结构化JSON输出和简洁的文本摘要。然后，将这些输出与叙述文本一起进行嵌入和索引，并采用模态感知的相似性阈值进行精确检索。最后，采用分层回退策略，在必要时动态地从纯文本升级到文本+表格+图像上下文，以实现跨模态推理。

Result: MultiFinRAG在复杂的金融问答任务中，比ChatGPT-4o（免费版）的准确率高出19个百分点，即使在普通硬件上也能运行。

Conclusion: MultiFinRAG为金融QA提供了一个高效且准确的解决方案，它通过专门设计的多模态处理和检索策略，有效地克服了现有模型在处理复杂金融文档时的局限性。

Abstract: Financial documents--such as 10-Ks, 10-Qs, and investor presentations--span
hundreds of pages and combine diverse modalities, including dense narrative
text, structured tables, and complex figures. Answering questions over such
content often requires joint reasoning across modalities, which strains
traditional large language models (LLMs) and retrieval-augmented generation
(RAG) pipelines due to token limitations, layout loss, and fragmented
cross-modal context. We introduce MultiFinRAG, a retrieval-augmented generation
framework purpose-built for financial QA. MultiFinRAG first performs multimodal
extraction by grouping table and figure images into batches and sending them to
a lightweight, quantized open-source multimodal LLM, which produces both
structured JSON outputs and concise textual summaries. These outputs, along
with narrative text, are embedded and indexed with modality-aware similarity
thresholds for precise retrieval. A tiered fallback strategy then dynamically
escalates from text-only to text+table+image contexts when necessary, enabling
cross-modal reasoning while reducing irrelevant context. Despite running on
commodity hardware, MultiFinRAG achieves 19 percentage points higher accuracy
than ChatGPT-4o (free-tier) on complex financial QA tasks involving text,
tables, images, and combined multimodal reasoning.

</details>


### [5] [Uncovering Hidden Violent Tendencies in LLMs: A Demographic Analysis via Behavioral Vignettes](https://arxiv.org/abs/2506.20822)
*Quintin Myers,Yanjun Gao*

Main category: cs.CL

TL;DR: 首次研究评估了LLM对日常冲突中暴力行为的推理能力，发现其表面生成与内部偏好不一致，且暴力倾向存在人口统计学偏差，这与社会科学研究相悖。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在检测和响应在线暴力内容方面的能力日益受到关注，但它们在道德模糊的现实场景中进行推理的能力尚未得到充分检验。

Method: 本研究首次使用经过验证的社会科学工具——暴力行为情景问卷（VBVQ）来评估LLM。为评估潜在偏差，引入了基于角色的提示，在美国境内变化种族、年龄和地理身份。在统一的零样本设置下，评估了来自不同地缘政治和组织背景的六个LLM。

Result: 研究揭示了两个关键发现：1）LLM的表面文本生成往往与其内部对暴力回应的偏好存在差异；2）它们的暴力倾向在不同人口统计学特征上有所不同，这经常与犯罪学、社会科学和心理学中的既定发现相矛盾。

Conclusion: LLM在暴力行为推理方面存在内在一致性问题，并且表现出的偏见与人类行为模式相悖。这表明在将LLM应用于敏感领域时需要谨慎，并需要进一步研究。

Abstract: Large language models (LLMs) are increasingly proposed for detecting and
responding to violent content online, yet their ability to reason about morally
ambiguous, real-world scenarios remains underexamined. We present the first
study to evaluate LLMs using a validated social science instrument designed to
measure human response to everyday conflict, namely the Violent Behavior
Vignette Questionnaire (VBVQ). To assess potential bias, we introduce
persona-based prompting that varies race, age, and geographic identity within
the United States. Six LLMs developed across different geopolitical and
organizational contexts are evaluated under a unified zero-shot setting. Our
study reveals two key findings: (1) LLMs surface-level text generation often
diverges from their internal preference for violent responses; (2) their
violent tendencies vary across demographics, frequently contradicting
established findings in criminology, social science, and psychology.

</details>


### [6] [Decide less, communicate more: On the construct validity of end-to-end fact-checking in medicine](https://arxiv.org/abs/2506.20876)
*Sebastian Joseph,Lily Chen,Barry Wei,Michael Mackert,Iain J. Marshall,Paul Pu Liang,Ramez Kouzy,Byron C. Wallace,Junyi Jessy Li*

Main category: cs.CL

TL;DR: 医学领域自动事实核查系统虽然有需求但未被充分利用。本研究通过考察临床专家如何核查真实医疗声明，揭示了连接声明与证据、声明模糊性以及真实性标签主观性等根本挑战。文章认为，事实核查应被视为一个交互式沟通问题，而非端到端过程。


<details>
  <summary>Details</summary>
Motivation: 尽管技术进步使得自动事实核查成为可能，并且在公共卫生和医学领域对此类系统的兴趣日益增长，但现有的端到端事实核查系统在医学领域仍未被广泛使用。主要动机是理解为什么这些系统未被充分利用，以及医学通信中的挑战（如多数用户医学素养不足）如何阻碍了其应用。

Method: 本研究首次考察了临床专家如何通过综合医学证据来核实社交媒体上的真实声明。

Result: 研究揭示了将端到端事实核查应用于医学领域时存在的根本挑战，包括：难以将“野生”声明与临床试验等科学证据关联起来；未充分明确的声明存在歧义并伴随意图不匹配；以及真实性标签本身具有主观性。

Conclusion: 事实核查应被视为一个交互式沟通问题，而不是一个简单的端到端过程。

Abstract: Technological progress has led to concrete advancements in tasks that were
regarded as challenging, such as automatic fact-checking. Interest in adopting
these systems for public health and medicine has grown due to the high-stakes
nature of medical decisions and challenges in critically appraising a vast and
diverse medical literature. Evidence-based medicine connects to every
individual, and yet the nature of it is highly technical, rendering the medical
literacy of majority users inadequate to sufficiently navigate the domain. Such
problems with medical communication ripens the ground for end-to-end
fact-checking agents: check a claim against current medical literature and
return with an evidence-backed verdict. And yet, such systems remain largely
unused. To understand this, we present the first study examining how clinical
experts verify real claims from social media by synthesizing medical evidence.
In searching for this upper-bound, we reveal fundamental challenges in
end-to-end fact-checking when applied to medicine: Difficulties connecting
claims in the wild to scientific evidence in the form of clinical trials;
ambiguities in underspecified claims mixed with mismatched intentions; and
inherently subjective veracity labels. We argue that fact-checking should be
approached and evaluated as an interactive communication problem, rather than
an end-to-end process.

</details>


### [7] [Optimising Language Models for Downstream Tasks: A Post-Training Perspective](https://arxiv.org/abs/2506.20917)
*Zhengyan Shi*

Main category: cs.CL

TL;DR: 该论文提出了一系列方法，以应对语言模型在特定任务适应中面临的挑战，如数据未充分利用、过拟合和高计算成本。其核心在于引入了新颖的持续预训练、参数高效微调、改进的监督微调以及新的评估方法，旨在显著提升语言模型的鲁棒性、效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在NLP中表现出色，但在高效、鲁棒地适应特定任务时仍面临挑战。随着模型规模和复杂性的增长，在标注数据上进行微调常导致未标注数据利用不足、在小型任务特定数据集上过拟合，并产生显著的计算成本，这限制了它们在开放式现实世界语言任务中的应用。

Method: 本文提出了一系列方法来更好地将语言模型应用于下游应用。首先，探索从未标注数据中提取任务相关知识的策略，引入一种新颖的持续预训练技术。其次，提出一种参数高效的微调方法，显著降低内存和计算成本。还引入了改进的监督微调方法，使语言模型能更好地遵循指令，尤其是在标注数据稀缺时。最后，开发了新的评估方法和基准，如多跳空间推理任务。

Result: 通过在各种NLP任务中进行广泛的实证研究，结果表明这些方法显著提高了语言模型的鲁棒性、效率和泛化能力，使其更适应广泛的应用。

Conclusion: 这些进展标志着在构建更鲁棒和高效的语言模型方面迈出了重要一步，使我们更接近实现通用人工智能的目标。

Abstract: Language models (LMs) have demonstrated remarkable capabilities in NLP, yet
adapting them efficiently and robustly to specific tasks remains challenging.
As their scale and complexity grow, fine-tuning LMs on labelled data often
underutilizes available unlabelled data, leads to overfitting on small
task-specific sets, and imposes significant computational costs. These
limitations hamper their application to the open-ended landscape of real-world
language tasks.
  This thesis proposes a series of methods to better adapt LMs to downstream
applications. First, we explore strategies for extracting task-relevant
knowledge from unlabelled data, introducing a novel continued pre-training
technique that outperforms state-of-the-art semi-supervised approaches. Next,
we present a parameter-efficient fine-tuning method that substantially reduces
memory and compute costs while maintaining competitive performance. We also
introduce improved supervised fine-tuning methods that enable LMs to better
follow instructions, especially when labelled data is scarce, enhancing their
performance across a range of NLP tasks, including open-ended generation.
Finally, we develop new evaluation methods and benchmarks, such as multi-hop
spatial reasoning tasks, to assess LM capabilities and adaptation more
comprehensively.
  Through extensive empirical studies across diverse NLP tasks, our results
demonstrate that these approaches substantially improve LM robustness,
efficiency, and generalization, making them more adaptable to a broad range of
applications. These advances mark a significant step towards more robust and
efficient LMs, bringing us closer to the goal of artificial general
intelligence.

</details>


### [8] [FineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data Processing to Every Language](https://arxiv.org/abs/2506.20920)
*Guilherme Penedo,Hynek Kydlíček,Vinko Sabolčec,Bettina Messmer,Negar Foroutan,Amir Hossein Kargaran,Colin Raffel,Martin Jaggi,Leandro Von Werra,Thomas Wolf*

Main category: cs.CL

TL;DR: 该研究介绍了一种基于FineWeb的新型预训练数据集整理流程，该流程可自动适应多种语言，以解决多语言LLM训练数据稀缺和质量问题。通过该流程，他们创建了FineWeb2（一个20TB的多语言数据集），并证明其能生成性能优于现有模型的多语言模型。


<details>
  <summary>Details</summary>
Motivation: 预训练最先进的大型语言模型需要大量干净且多样化的文本数据。尽管高质量英文预训练数据集的开放开发取得了显著进展，但训练高性能多语言LLM仍然是一个挑战，这主要是因为为大量语言定制过滤和去重管道固有的困难。

Method: 本文引入了一种基于FineWeb的新的预训练数据集整理管道，该管道可以自动适应支持任何语言。他们在一组九种不同语言上广泛消除了管道设计选择的影响，并通过基于可衡量标准的新颖选择过程选定了一组有意义且信息丰富的评估任务进行指导。他们还引入了一种直接且有原则的数据集重新平衡方法，该方法考虑了重复计数和质量。最后，他们将管道扩展到1000多种语言，使用近100个Common Crawl快照生成了FineWeb2。

Result: 结果表明，该管道可以用于创建非英语语料库，从而生成比现有数据集性能更好的模型。此外，重新平衡数据集的方法提供了额外的性能提升。他们还生成了FineWeb2，一个20TB（50亿文档）的多语言数据集。

Conclusion: 该研究成功开发了一个可自动适应多种语言的高质量预训练数据集整理管道，解决了多语言LLM训练数据的挑战。该管道能够生成性能优于现有数据集的多语言模型，并发布了大规模的FineWeb2多语言数据集及相关代码。

Abstract: Pre-training state-of-the-art large language models (LLMs) requires vast
amounts of clean and diverse text data. While the open development of large
high-quality English pre-training datasets has seen substantial recent
progress, training performant multilingual LLMs remains a challenge, in large
part due to the inherent difficulty of tailoring filtering and deduplication
pipelines to a large number of languages. In this work, we introduce a new
pre-training dataset curation pipeline based on FineWeb that can be
automatically adapted to support any language. We extensively ablate our
pipeline design choices on a set of nine diverse languages, guided by a set of
meaningful and informative evaluation tasks that were chosen through a novel
selection process based on measurable criteria. Ultimately, we show that our
pipeline can be used to create non-English corpora that produce more performant
models than prior datasets. We additionally introduce a straightforward and
principled approach to rebalance datasets that takes into consideration both
duplication count and quality, providing an additional performance uplift.
Finally, we scale our pipeline to over 1000 languages using almost 100 Common
Crawl snapshots to produce FineWeb2, a new 20 terabyte (5 billion document)
multilingual dataset which we release along with our pipeline, training, and
evaluation codebases.

</details>


### [9] [KaLM-Embedding-V2: Superior Training Techniques and Data Inspire A Versatile Embedding Model](https://arxiv.org/abs/2506.20923)
*Xinping Zhao,Xinshuo Hu,Zifei Shan,Shouzheng Huang,Yao Zhou,Zetian Sun,Zhenyu Liu,Dongfang Li,Xinyuan Wei,Qian Chen,Youcheng Pan,Yang Xiang,Meishan Zhang,Haofen Wang,Jun Yu,Baotian Hu,Min Zhang*

Main category: cs.CL

TL;DR: 论文提出了KaLM-Embedding-V2，一个通用且紧凑的文本嵌入模型。它通过改进架构、多阶段训练、难样本处理和大规模多样化数据，在MTEB基准测试中表现出色，超越同规模模型并与大得多模型竞争，为小型嵌入模型树立了新标杆。


<details>
  <summary>Details</summary>
Motivation: 提出一个通用且紧凑的嵌入模型KaLM-Embedding-V2，通过优越的训练技术和数据，在通用文本嵌入任务中取得令人印象深刻的性能。

Method: 1. 移除因果注意力掩码，采用全双向Transformer和简单的均值池化生成固定长度嵌入。2. 采用多阶段训练流程：(i) 大规模弱监督开源语料预训练；(ii) 高质量检索和非检索数据集微调；(iii) 模型融合（model-soup）参数平均以增强泛化能力。3. 引入焦点式重加权机制，关注难样本学习，以及在线难负样本混合策略。4. 收集超过20类预训练数据和100类微调数据。

Result: 在MTEB中文和英文基准测试中，KaLM-Embedding-V2显著优于同等规模模型，并能与大3倍、14倍、18倍和26倍的嵌入模型竞争。

Conclusion: 提出了一种参数少于1B的通用且紧凑的嵌入模型，并为其设定了新标准。

Abstract: In this paper, we propose KaLM-Embedding-V2, a versatile and compact
embedding model, which achieves impressive performance in general-purpose text
embedding tasks by leveraging superior training techniques and data. Our key
innovations include: (1) To better align the architecture with representation
learning, we remove the causal attention mask and adopt a fully bidirectional
transformer with simple yet effective mean-pooling to produce fixed-length
embeddings; (2) We employ a multi-stage training pipeline: (i) pre-training on
large-scale weakly supervised open-source corpora; (ii) fine-tuning on
high-quality retrieval and non-retrieval datasets; and (iii) model-soup
parameter averaging for robust generalization. Besides, we introduce a
focal-style reweighting mechanism that concentrates learning on difficult
samples and an online hard-negative mixing strategy to continuously enrich hard
negatives without expensive offline mining; (3) We collect over 20 categories
of data for pre-training and 100 categories of data for fine-tuning, to boost
both the performance and generalization of the embedding model. Extensive
evaluations on the Massive Text Embedding Benchmark (MTEB) Chinese and English
show that our model significantly outperforms others of comparable size, and
competes with 3x, 14x, 18x, and 26x larger embedding models, setting a new
standard for a versatile and compact embedding model with less than 1B
parameters.

</details>


### [10] [Can Gradient Descent Simulate Prompting?](https://arxiv.org/abs/2506.20989)
*Eric Zhang,Leshem Choshen,Jacob Andreas*

Main category: cs.CL

TL;DR: 该论文提出了一种元训练语言模型的方法，使其梯度更新能够模拟提示（prompting）的效果，从而使得微调（fine-tuning）也能像提示一样高效地整合新信息。


<details>
  <summary>Details</summary>
Motivation: 目前语言模型整合新信息有两种主要方式：修改提示或修改参数（例如通过微调）。提示在很多情况下更有效，但参数更新没有长期存储成本。作者想探究是否能修改模型，使微调也能模拟提示的效果。

Method: 本文描述了一种元训练语言模型的方法，使得梯度更新能够模拟条件化新信息的效果。该方法利用了基于梯度的元学习工具，但使用语言模型自身的提示预测作为目标，无需真实标签。

Result: 随后的梯度下降训练恢复了部分（有时是全部）提示模型的性能，在“反转诅咒”任务上有所改进，并且在单次梯度更新后能够回答关于文本段落的问题。

Conclusion: 结果表明，通过适当的初始化，梯度下降可以表现出惊人的表达能力。这些结果为长上下文建模提供了新途径，并为基于梯度的学习的泛化能力提供了见解。

Abstract: There are two primary ways of incorporating new information into a language
model (LM): changing its prompt or changing its parameters, e.g. via
fine-tuning. Parameter updates incur no long-term storage cost for model
changes. However, for many model updates, prompting is significantly more
effective: prompted models can generalize robustly from single examples and
draw logical inferences that do not occur under standard fine-tuning. Can
models be modified so that fine-tuning does emulate prompting? This paper
describes a method for meta-training LMs such that gradient updates emulate the
effects of conditioning on new information. Our approach uses tools from
gradient-based meta-learning but uses an LM's own prompted predictions as
targets, eliminating the need for ground-truth labels. Subsequent gradient
descent training recovers some (and occasionally all) of prompted model
performance -- showing improvement on the ``reversal curse'' tasks, and
answering questions about text passages after a single gradient update. These
results suggest that, with appropriate initialization, gradient descent can be
surprisingly expressive. Our results suggest new avenues for long-context
modeling and offer insight into the generalization capabilities of
gradient-based learning.

</details>


### [11] [SAC: A Framework for Measuring and Inducing Personality Traits in LLMs with Dynamic Intensity Control](https://arxiv.org/abs/2506.20993)
*Adithya Chittem,Aishna Shrivastava,Sai Tarun Pendela,Jagat Sesh Challa,Dhruv Kumar*

Main category: cs.CL

TL;DR: 该论文提出了一种新的方法，通过扩展到16PF模型并引入结构化强度控制框架，使大型语言模型（LLMs）能够展现更细致和可控的个性，并表明LLMs能够内化多维度的个性结构。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型个性建模主要依赖于粗略的“大五人格”框架，并且缺乏对个性特质强度的控制机制。

Method: 将机器个性清单（MPI）扩展到16种人格因素（16PF）模型，以实现对十六种不同特质的表达控制。开发了一个名为特定属性控制（SAC）的结构化框架，通过基于形容词的语义锚定和涵盖频率、深度、阈值、努力和意愿五个强度因素的行为问题，来评估和动态诱导LLMs的特质强度。

Result: 将强度建模为连续谱比二元特质切换能产生更一致和可控的个性表达。目标特质强度的变化会系统性地影响密切相关的特质，这表明LLMs内化了多维度的个性结构。

Conclusion: 这项工作为医疗、教育和面试等领域中受控和细致的人机交互开辟了新途径，使我们离真正像人类的社交机器更近了一步。

Abstract: Large language models (LLMs) have gained significant traction across a wide
range of fields in recent years. There is also a growing expectation for them
to display human-like personalities during interactions. To meet this
expectation, numerous studies have proposed methods for modelling LLM
personalities through psychometric evaluations. However, most existing models
face two major limitations: they rely on the Big Five (OCEAN) framework, which
only provides coarse personality dimensions, and they lack mechanisms for
controlling trait intensity. In this paper, we address this gap by extending
the Machine Personality Inventory (MPI), which originally used the Big Five
model, to incorporate the 16 Personality Factor (16PF) model, allowing
expressive control over sixteen distinct traits. We also developed a structured
framework known as Specific Attribute Control (SAC) for evaluating and
dynamically inducing trait intensity in LLMs. Our method introduces
adjective-based semantic anchoring to guide trait intensity expression and
leverages behavioural questions across five intensity factors:
\textit{Frequency}, \textit{Depth}, \textit{Threshold}, \textit{Effort}, and
\textit{Willingness}. Through experimentation, we find that modelling intensity
as a continuous spectrum yields substantially more consistent and controllable
personality expression compared to binary trait toggling. Moreover, we observe
that changes in target trait intensity systematically influence closely related
traits in psychologically coherent directions, suggesting that LLMs internalize
multi-dimensional personality structures rather than treating traits in
isolation. Our work opens new pathways for controlled and nuanced human-machine
interactions in domains such as healthcare, education, and interviewing
processes, bringing us one step closer to truly human-like social machines.

</details>


### [12] [Large Language Models Acing Chartered Accountancy](https://arxiv.org/abs/2506.21031)
*Jatin Gupta,Akhil Sharma,Saransh Singhania,Mohammad Adnan,Sakshi Deo,Ali Imam Abidi,Keshav Gupta*

Main category: cs.CL

TL;DR: 本文介绍了CA-Ben，这是一个新的基准测试，用于评估大型语言模型（LLMs）在印度特许会计师（CA）领域的金融、法律和定量推理能力。结果显示，Claude 3.5 Sonnet和GPT-4o表现最佳，但在数值计算和法律解释方面仍存在挑战，表明未来需要通过混合推理和检索增强生成方法进行改进。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在金融领域发挥着重要作用，但它们捕捉和应用特定领域金融知识的程度仍不确定，尤其是在印度金融背景下，存在评估这一能力的空白。

Method: 引入了CA-Ben，一个专门为评估LLMs金融、法律和定量推理能力而设计的特许会计师基准。该基准包含来自印度特许会计师协会（ICAI）严格考试的结构化问答数据集。使用标准化协议评估了六个主流LLM（GPT 4o, LLAMA 3.3 70B, LLAMA 3.1 405B, MISTRAL Large, Claude 3.5 Sonnet, 和 Microsoft Phi 4）。

Result: LLMs的性能存在差异，其中Claude 3.5 Sonnet和GPT-4o表现优于其他模型，尤其是在概念和法律推理方面。在数值计算和法律解释方面出现了显著挑战。

Conclusion: 研究结果强调了当前LLM的优点和局限性，并建议未来通过混合推理和检索增强生成方法（特别是针对定量分析和准确的法律解释）进行改进。

Abstract: Advanced intelligent systems, particularly Large Language Models (LLMs), are
significantly reshaping financial practices through advancements in Natural
Language Processing (NLP). However, the extent to which these models
effectively capture and apply domain-specific financial knowledge remains
uncertain. Addressing a critical gap in the expansive Indian financial context,
this paper introduces CA-Ben, a Chartered Accountancy benchmark specifically
designed to evaluate the financial, legal, and quantitative reasoning
capabilities of LLMs. CA-Ben comprises structured question-answer datasets
derived from the rigorous examinations conducted by the Institute of Chartered
Accountants of India (ICAI), spanning foundational, intermediate, and advanced
CA curriculum stages. Six prominent LLMs i.e. GPT 4o, LLAMA 3.3 70B, LLAMA 3.1
405B, MISTRAL Large, Claude 3.5 Sonnet, and Microsoft Phi 4 were evaluated
using standardized protocols. Results indicate variations in performance, with
Claude 3.5 Sonnet and GPT-4o outperforming others, especially in conceptual and
legal reasoning. Notable challenges emerged in numerical computations and legal
interpretations. The findings emphasize the strengths and limitations of
current LLMs, suggesting future improvements through hybrid reasoning and
retrieval-augmented generation methods, particularly for quantitative analysis
and accurate legal interpretation.

</details>


### [13] [A Semi-supervised Scalable Unified Framework for E-commerce Query Classification](https://arxiv.org/abs/2506.21049)
*Chunyuan Yuan,Chong Zhang,Zheng Fang,Ming Pang,Xue Jiang,Changping Peng,Zhangang Lin,Ching Law*

Main category: cs.CL

TL;DR: 本文提出SSUF框架，通过知识增强、标签增强和结构增强模块统一电商查询分类任务，解决了信息不足、依赖点击行为和缺乏统一框架的问题，实验证明其优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 电商查询分类面临短查询、上下文缺失、信息不足、依赖用户点击行为导致马太效应以及缺乏统一框架等问题。

Method: 提出半监督可扩展统一框架（SSUF），包含知识增强模块（利用世界知识增强查询表示）、标签增强模块（利用标签语义和半监督信号减少对后验标签的依赖）和结构增强模块（基于复杂标签关系增强标签表示）。各模块高度可插拔。

Result: 广泛的离线和在线A/B实验结果表明，SSUF显著优于现有最先进的模型。

Conclusion: SSUF框架成功地统一了电商查询分类任务，并通过其增强模块有效解决了现有方法的不足。

Abstract: Query classification, including multiple subtasks such as intent and category
prediction, is vital to e-commerce applications. E-commerce queries are usually
short and lack context, and the information between labels cannot be used,
resulting in insufficient prior information for modeling. Most existing
industrial query classification methods rely on users' posterior click behavior
to construct training samples, resulting in a Matthew vicious cycle.
Furthermore, the subtasks of query classification lack a unified framework,
leading to low efficiency for algorithm optimization.
  In this paper, we propose a novel Semi-supervised Scalable Unified Framework
(SSUF), containing multiple enhanced modules to unify the query classification
tasks. The knowledge-enhanced module uses world knowledge to enhance query
representations and solve the problem of insufficient query information. The
label-enhanced module uses label semantics and semi-supervised signals to
reduce the dependence on posterior labels. The structure-enhanced module
enhances the label representation based on the complex label relations. Each
module is highly pluggable, and input features can be added or removed as
needed according to each subtask. We conduct extensive offline and online A/B
experiments, and the results show that SSUF significantly outperforms the
state-of-the-art models.

</details>


### [14] [MT2-CSD: A New Dataset and Multi-Semantic Knowledge Fusion Method for Conversational Stance Detection](https://arxiv.org/abs/2506.21053)
*Fuqiang Niu,Genan Dai,Yisha Lu,Jiayu Liao,Xiang Li,Hu Huang,Bowen Zhang*

Main category: cs.CL

TL;DR: 该论文提出了一个大型多目标、多轮对话立场检测数据集（MT2-CSD）和一个增强型大语言模型会话关系注意力网络（LLM-CRAN），LLM-CRAN在对话立场检测任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统的立场检测研究局限于单个实例，难以模拟真实社交媒体中的多方讨论，且缺乏能真实捕捉社交媒体互动动态的数据集，阻碍了对话立场检测的发展。

Method: 本文引入了MT2-CSD数据集，用于多目标、多轮对话立场检测。同时，提出了大语言模型增强的会话关系注意力网络（LLM-CRAN），利用LLM的推理能力来提高会话理解能力。

Result: 实验结果表明，LLM-CRAN在对话立场检测任务中显著优于强大的基线模型。

Conclusion: LLM-CRAN在对话立场检测任务中表现出色，且MT2-CSD数据集的引入为该领域提供了新的挑战和机会。

Abstract: In the realm of contemporary social media, automatic stance detection is
pivotal for opinion mining, as it synthesizes and examines user perspectives on
contentious topics to uncover prevailing trends and sentiments. Traditional
stance detection research often targets individual instances, thereby limiting
its capacity to model multi-party discussions typical in real social media
scenarios. This shortcoming largely stems from the scarcity of datasets that
authentically capture the dynamics of social media interactions, hindering
advancements in conversational stance detection. In this paper, we introduce
MT2-CSD, a comprehensive dataset for multi-target, multi-turn conversational
stance detection. To the best of our knowledge, MT2-CSD is the largest dataset
available for this purpose, comprising 24,457 annotated instances and
exhibiting the greatest conversational depth, thereby presenting new challenges
for stance detection. To address these challenges, we propose the Large
Language model enhanced Conversational Relational Attention Network (LLM-CRAN),
which exploits the reasoning capabilities of LLMs to improve conversational
understanding. We conduct extensive experiments to evaluate the efficacy of
LLM-CRAN on the MT2-CSD dataset. The experimental results indicate that
LLM-CRAN significantly outperforms strong baseline models in the task of
conversational stance detection.

</details>


### [15] [DALR: Dual-level Alignment Learning for Multimodal Sentence Representation Learning](https://arxiv.org/abs/2506.21096)
*Kang He,Yuzhe Ding. Haining Wang,Fei Li,Chong Teng,Donghong Ji*

Main category: cs.CL

TL;DR: DALR通过双层对齐学习解决多模态句子表示中的跨模态错位和模态内语义发散问题，在STS和TR任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多模态句子表示学习中，通常在粗粒度上对齐图像和文本，面临跨模态错位偏差和模态内语义分歧两大挑战，严重影响句子表示质量。

Method: 提出DALR（多模态句子表示的双层对齐学习）方法。为了解决跨模态对齐问题，引入一致性学习模块，通过软化负样本和利用辅助任务的语义相似性实现细粒度跨模态对齐。此外，通过将排序蒸馏与全局模态内对齐学习相结合，更好地捕获句子关系并提升表示质量。

Result: 在语义文本相似性（STS）和迁移（TR）任务上的综合实验验证了我们方法的有效性，并持续展现出优于现有基线方法的性能。

Conclusion: 本研究提出的DALR方法有效解决了多模态句子表示学习中的跨模态错位和模态内语义分歧问题，并通过双层对齐学习显著提升了句子表示质量，在多项任务上超越了现有先进方法。

Abstract: Previous multimodal sentence representation learning methods have achieved
impressive performance. However, most approaches focus on aligning images and
text at a coarse level, facing two critical challenges:cross-modal misalignment
bias and intra-modal semantic divergence, which significantly degrade sentence
representation quality. To address these challenges, we propose DALR
(Dual-level Alignment Learning for Multimodal Sentence Representation). For
cross-modal alignment, we propose a consistency learning module that softens
negative samples and utilizes semantic similarity from an auxiliary task to
achieve fine-grained cross-modal alignment. Additionally, we contend that
sentence relationships go beyond binary positive-negative labels, exhibiting a
more intricate ranking structure. To better capture these relationships and
enhance representation quality, we integrate ranking distillation with global
intra-modal alignment learning. Comprehensive experiments on semantic textual
similarity (STS) and transfer (TR) tasks validate the effectiveness of our
approach, consistently demonstrating its superiority over state-of-the-art
baselines.

</details>


### [16] [ComRAG: Retrieval-Augmented Generation with Dynamic Vector Stores for Real-time Community Question Answering in Industry](https://arxiv.org/abs/2506.21098)
*Qinwen Chen,Wenbiao Tao,Zhiwei Zhu,Mingfan Xi,Liangzhong Guo,Yuan Wang,Wei Wang,Yunshi Lan*

Main category: cs.CL

TL;DR: ComRAG是一个用于实时工业CQA的检索增强生成框架，它利用基于质心的内存机制整合静态知识和动态历史QA对，显著优于现有基线方法，在向量相似度、延迟和块增长方面均有提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法在社区问答（CQA）平台中未能有效利用外部知识、动态历史问答上下文或缺乏适合工业部署的内存机制。

Method: 提出ComRAG框架，一个用于实时工业CQA的检索增强生成框架，通过基于质心的内存机制，整合静态知识与动态历史问答对，以实现检索、生成和高效存储。

Result: 在三个工业CQA数据集上，ComRAG性能持续优于所有基线方法，向量相似度提升高达25.9%，延迟降低8.7%至23.3%，块增长从20.23%降至2.06%。

Conclusion: ComRAG框架能够有效解决实时工业CQA平台中知识利用、动态上下文整合和内存机制的挑战，并取得了显著的性能提升。

Abstract: Community Question Answering (CQA) platforms can be deemed as important
knowledge bases in community, but effectively leveraging historical
interactions and domain knowledge in real-time remains a challenge. Existing
methods often underutilize external knowledge, fail to incorporate dynamic
historical QA context, or lack memory mechanisms suited for industrial
deployment. We propose ComRAG, a retrieval-augmented generation framework for
real-time industrial CQA that integrates static knowledge with dynamic
historical QA pairs via a centroid-based memory mechanism designed for
retrieval, generation, and efficient storage. Evaluated on three industrial CQA
datasets, ComRAG consistently outperforms all baselines--achieving up to 25.9%
improvement in vector similarity, reducing latency by 8.7% to 23.3%, and
lowering chunk growth from 20.23% to 2.06% over iterations.

</details>


### [17] [Progtuning: Progressive Fine-tuning Framework for Transformer-based Language Models](https://arxiv.org/abs/2506.21119)
*Xiaoshuang Ji,Zhendong Zhao,Xiaojun Chen,Xin Zhao,Zeyao Liu*

Main category: cs.CL

TL;DR: 一种名为Progtuning的新型微调方法，通过逐步减少更新的Transformer块数量，在保持性能的同时减少了25%的更新参数。


<details>
  <summary>Details</summary>
Motivation: 现有的大型Transformer模型微调成本高昂，且当前的参数高效微调方法未能有效分配计算资源，忽略了Transformer块之间贡献的不均衡性。

Method: 本文提出了Progtuning，一个结合渐进式学习的Transformer语言模型微调框架。Progtuning根据贡献程度逐步减少需要更新的Transformer块数量。

Result: Progtuning优化了资源分配，将更新参数的数量减少了约25%，同时保持了有竞争力的性能。它还与参数高效微调方法表现出高度的适应性，在各种适应场景中展现出卓越的性能。

Conclusion: Progtuning为大型Transformer模型的微调提供了一个高效且适应性强的解决方案，通过智能地减少更新参数，解决了现有方法的资源分配效率问题。

Abstract: Fine-tuning is a promising technique for leveraging Transformer-based
language models in downstream tasks. As model sizes continue to grow, updating
all model parameters becomes increasingly costly. Parameter-efficient
fine-tuning methods effectively address this issue by selectively updating a
small subset of parameters. However, fine-tuning and most existing
parameter-efficient fine-tuning methods require updating the same number of
parameters as the initial size, ignoring the unequal contribution across
Transformer blocks and leading to extremely inefficient allocation of computing
resources. In this paper, we propose Progtuning, the novel fine-tuning
framework combined with progressive learning for Transformer-based language
models. Specifically, Progtuning progressively reduces the number of updated
transformer blocks based on the contribution. Remarkably, Progtuning optimizes
resource allocation and reduces the number of updated parameters by
approximately 25\%, while still maintaining competitive performance. And it
also exhibits high adaptability with parameter-efficient fine-tuning methods,
demonstrating excellent performance across various adaptation scenarios.

</details>


### [18] [Compressed and Smooth Latent Space for Text Diffusion Modeling](https://arxiv.org/abs/2506.21170)
*Viacheslav Meshchaninov,Egor Chimbulatov,Alexander Shabalin,Aleksandr Abramov,Dmitry Vetrov*

Main category: cs.CL

TL;DR: Cosmos是一种基于扩散模型的新型文本生成方法，它在压缩的潜在空间中运行，生成质量与现有模型相当或更优，且推理速度提升超过2倍。


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型存在解码慢和全局一致性差的问题。扩散模型虽有潜力，但因高维度的词元表示而难以应用于文本生成。

Method: 提出Cosmos，一种在压缩、平滑的潜在空间中进行文本生成的新方法。该空间通过自编码器学习，自编码器同时进行词元级重建和与预训练语言编码器激活的对齐。

Result: 文本表示可压缩8倍，生成质量与词元级扩散模型相当。增加潜在序列长度后，Cosmos能超越基于扩散和自回归的基线模型。在四种生成任务上，Cosmos实现了相当或更优的生成质量，推理速度提高2倍以上。

Conclusion: Cosmos通过在压缩潜在空间中操作，成功解决了传统文本生成模型的局限性，在生成质量和推理速度上均表现出色。

Abstract: Autoregressive language models dominate modern text generation, yet their
sequential nature introduces fundamental limitations: decoding is slow, and
maintaining global coherence remains challenging. Diffusion models offer a
promising alternative by enabling parallel generation and flexible control;
however, their application to text generation is hindered by the high
dimensionality of token-level representations. We introduce Cosmos, a novel
approach to text generation that operates entirely in a compressed, smooth
latent space tailored specifically for diffusion. This space is learned using
an autoencoder trained simultaneously for token-level reconstruction and
alignment with frozen activations from a pretrained language encoder, providing
robust semantic grounding and enabling effective perturbation-based
augmentations. Empirically, we demonstrate that text representations can be
compressed by $8\times$ while maintaining generation quality comparable to
token-level diffusion models. Furthermore, increasing the latent sequence
length allows Cosmos to surpass both diffusion-based and autoregressive
baselines. We evaluate Cosmos on four diverse generative tasks including story
generation, question generation, summarization, and detoxification and compare
it with various generative paradigms. Cosmos achieves comparable or superior
generation quality while offering more than $2\times$ faster inference.

</details>


### [19] [Maintaining MTEB: Towards Long Term Usability and Reproducibility of Embedding Benchmarks](https://arxiv.org/abs/2506.21182)
*Isaac Chung,Imene Kerboua,Marton Kardos,Roman Solomatin,Kenneth Enevoldsen*

Main category: cs.CL

TL;DR: 这篇论文讨论了MTEB基准测试平台的工程实践和策略，以确保其可复现性和可扩展性，并为其他基准测试维护者提供了宝贵的经验。


<details>
  <summary>Details</summary>
Motivation: 尽管MTEB已成为文本嵌入模型评估的标准平台，但本研究侧重于工程方面，以确保MTEB的持续可复现性和可扩展性。挑战在于在扩展的同时保持质量和相关性。

Method: 本文介绍了维护强大的持续集成管道的方法（包括验证数据集完整性、自动化测试执行和评估基准结果的通用性），详细阐述了提高可复现性和可用性的设计选择，并讨论了处理社区贡献以及用新任务和数据集扩展基准的策略。

Result: 这些工程实践在使MTEB变得更全面、同时保持质量并最终与领域保持相关性方面发挥了重要作用。

Conclusion: 本研究的经验为面临类似挑战的基准维护者提供了宝贵的见解，以确保机器学习评估框架的可复现性和可用性。

Abstract: The Massive Text Embedding Benchmark (MTEB) has become a standard evaluation
platform for text embedding models. While previous work has established the
core benchmark methodology, this paper focuses on the engineering aspects that
ensure MTEB's continued reproducibility and extensibility. We present our
approach to maintaining robust continuous integration pipelines that validate
dataset integrity, automate test execution, and assess benchmark results'
generalizability. We detail the design choices that collectively enhance
reproducibility and usability. Furthermore, we discuss our strategies for
handling community contributions and extending the benchmark with new tasks and
datasets. These engineering practices have been instrumental in scaling MTEB to
become more comprehensive while maintaining quality and, ultimately, relevance
to the field. Our experiences offer valuable insights for benchmark maintainers
facing similar challenges in ensuring reproducibility and usability in machine
learning evaluation frameworks. The MTEB repository is available at:
https://github.com/embeddings-benchmark/mteb

</details>


### [20] [Prompt-Guided Turn-Taking Prediction](https://arxiv.org/abs/2506.21191)
*Koji Inoue,Mikey Elmers,Yahui Fu,Zi Haur Pang,Divesh Lala,Keiko Ochi,Tatsuya Kawahara*

Main category: cs.CL

TL;DR: 一个基于Transformer的新模型，允许通过文本提示（例如“更快”、“更平静”）控制实时轮流预测，通过集成LLM生成的提示嵌入来提高口语对话系统的准确性和适应性。


<details>
  <summary>Details</summary>
Motivation: 现有的轮流预测模型在对话系统和机器人中至关重要，但缺乏动态控制。本文旨在通过文本提示实现轮流预测的动态控制，以更好地适应对话伙伴和语境。

Method: 本文提出一个新模型，其基础是基于Transformer的语音活动预测（VAP）模型，并将文本提示嵌入到通道内和跨通道的Transformer中。由于缺少现有数据集中的文本提示数据，研究者利用大型语言模型（LLM）生成合成提示语句。

Result: 实验结果表明，所提出的模型提高了预测准确性，并能根据文本提示有效地改变轮流时序行为。

Conclusion: 所提出的模型成功地实现了通过文本提示动态控制轮流预测，提高了对话系统的适应性和准确性。

Abstract: Turn-taking prediction models are essential components in spoken dialogue
systems and conversational robots. Recent approaches leverage transformer-based
architectures to predict speech activity continuously and in real-time. In this
study, we propose a novel model that enables turn-taking prediction to be
dynamically controlled via textual prompts. This approach allows intuitive and
explicit control through instructions such as "faster" or "calmer" adapting
dynamically to conversational partners and contexts. The proposed model builds
upon a transformer-based voice activity projection (VAP) model, incorporating
textual prompt embeddings into both channel-wise transformers and a
cross-channel transformer. We evaluated the feasibility of our approach using
over 950 hours of human-human spoken dialogue data. Since textual prompt data
for the proposed approach was not available in existing datasets, we utilized a
large language model (LLM) to generate synthetic prompt sentences. Experimental
results demonstrated that the proposed model improved prediction accuracy and
effectively varied turn-taking timing behaviors according to the textual
prompts.

</details>


### [21] [Enhancing Automatic Term Extraction with Large Language Models via Syntactic Retrieval](https://arxiv.org/abs/2506.21222)
*Yongchan Chun,Minhyuk Kim,Dongjun Kim,Chanjun Park,Heuiseok Lim*

Main category: cs.CL

TL;DR: 本文提出了一种基于句法检索的提示策略，用于在少样本设置下利用LLMs进行自动术语提取（ATE），实验证明该方法显著提高了ATE的F1分数，并强调了句法线索在术语提取中的重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在各种自然语言处理任务中取得了显著进展，但它们在自动术语提取（ATE）方面的潜力尚未得到充分检验。

Method: 提出了一种基于检索的提示策略，在少样本设置中，根据句法而非语义相似性选择示例。这种句法检索方法是领域无关的，并为捕获术语边界提供了更可靠的指导。

Result: 在三个专门的ATE基准测试上的实验表明，句法检索提高了F1分数。

Conclusion: 这些发现强调了在将大型语言模型应用于术语提取任务时，句法线索的重要性。

Abstract: Automatic Term Extraction (ATE) identifies domain-specific expressions that
are crucial for downstream tasks such as machine translation and information
retrieval. Although large language models (LLMs) have significantly advanced
various NLP tasks, their potential for ATE has scarcely been examined. We
propose a retrieval-based prompting strategy that, in the few-shot setting,
selects demonstrations according to \emph{syntactic} rather than semantic
similarity. This syntactic retrieval method is domain-agnostic and provides
more reliable guidance for capturing term boundaries. We evaluate the approach
in both in-domain and cross-domain settings, analyzing how lexical overlap
between the query sentence and its retrieved examples affects performance.
Experiments on three specialized ATE benchmarks show that syntactic retrieval
improves F1-score. These findings highlight the importance of syntactic cues
when adapting LLMs to terminology-extraction tasks.

</details>


### [22] [Agent-RewardBench: Towards a Unified Benchmark for Reward Modeling across Perception, Planning, and Safety in Real-World Multimodal Agents](https://arxiv.org/abs/2506.21252)
*Tianyi Men,Zhuoran Jin,Pengfei Cao,Yubo Chen,Kang Liu,Jun Zhao*

Main category: cs.CL

TL;DR: Agent-RewardBench 是一个新基准，旨在评估多模态大语言模型（MLLM）作为AI代理的奖励模型的能力，结果表明当前模型表现不佳，需要专门训练。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在实际任务中展现出潜力，但由于缺乏外部反馈，在自我纠正和泛化方面表现不佳。奖励模型是一种有前景的外部反馈方式，但目前尚不清楚如何为代理选择合适的奖励模型，因此迫切需要建立一个面向代理的奖励基准。

Method: 提出 Agent-RewardBench，一个旨在评估 MLLMs 奖励建模能力的基准。该基准具有三个主要特点：1) 多维度和真实世界代理场景评估（涵盖感知、规划和安全性，共7个场景）；2) 步级奖励评估，提供更细致的性能视图；3) 适当的难度和高质量，通过从10个不同模型中采样、难度控制和人工验证确保数据完整性。

Result: 实验表明，即使是最先进的多模态模型也表现出有限的性能。

Conclusion: 需要对代理奖励建模进行专门的训练。

Abstract: As Multimodal Large Language Models (MLLMs) advance, multimodal agents show
promise in real-world tasks like web navigation and embodied intelligence.
However, due to limitations in a lack of external feedback, these agents
struggle with self-correction and generalization. A promising approach is to
use reward models as external feedback, but there is no clear on how to select
reward models for agents. Thus, there is an urgent need to build a reward bench
targeted at agents. To address these challenges, we propose Agent-RewardBench,
a benchmark designed to evaluate reward modeling ability in MLLMs. The
benchmark is characterized by three key features: (1) Multiple dimensions and
real-world agent scenarios evaluation. It covers perception, planning, and
safety with 7 scenarios; (2) Step-level reward evaluation. It allows for the
assessment of agent capabilities at the individual steps of a task, providing a
more granular view of performance during the planning process; and (3)
Appropriately difficulty and high-quality. We carefully sample from 10 diverse
models, difficulty control to maintain task challenges, and manual verification
to ensure the integrity of the data. Experiments demonstrate that even
state-of-the-art multimodal models show limited performance, highlighting the
need for specialized training in agent reward modeling. Code is available at
github.

</details>


### [23] [Cat and Mouse -- Can Fake Text Generation Outpace Detector Systems?](https://arxiv.org/abs/2506.21274)
*Andrea McGlinchey,Peter J Barclay*

Main category: cs.CL

TL;DR: 大型语言模型能生成逼真的“假文本”。本研究探讨了随着模型规模增大，检测假文本是否仍可行。结果显示，Gemini生成欺骗性文本的能力增强，而GPT没有，暗示检测仍可能有效。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）能够生成令人信服的“假文本”，引发了检测方法与生成能力之间的“军备竞赛”。本文旨在探讨随着LLMs规模的增大，其生成文本的欺骗性是否会达到一个平台期，以及相对简单的检测器是否仍能有效识别假文本。

Method: 本研究通过统计分类器，检测模仿经典侦探小说风格的“假文本”，并比较了Gemini和GPT模型在版本更新0.5后生成欺骗性文本的能力变化。

Result: Gemini在版本更新0.5后生成欺骗性文本的能力有所增强，而GPT没有表现出类似的变化。

Conclusion: 即使面对规模更大的模型，可靠的假文本检测可能仍然可行，尽管新的模型架构可能会提高其欺骗性。

Abstract: Large language models can produce convincing "fake text" in domains such as
academic writing, product reviews, and political news. Many approaches have
been investigated for the detection of artificially generated text. While this
may seem to presage an endless "arms race", we note that newer LLMs use ever
more parameters, training data, and energy, while relatively simple classifiers
demonstrate a good level of detection accuracy with modest resources. To
approach the question of whether the models' ability to beat the detectors may
therefore reach a plateau, we examine the ability of statistical classifiers to
identify "fake text" in the style of classical detective fiction. Over a 0.5
version increase, we found that Gemini showed an increased ability to generate
deceptive text, while GPT did not. This suggests that reliable detection of
fake text may remain feasible even for ever-larger models, though new model
architectures may improve their deceptiveness

</details>


### [24] [Double-Checker: Enhancing Reasoning of Slow-Thinking LLMs via Self-Critical Fine-Tuning](https://arxiv.org/abs/2506.21285)
*Xin Xu,Tianhao Chen,Fan Zhang,Wanlong Liu,Pengxiang Li,Ajay Kumar Jaiswal,Yuchen Yan,Jishan Hu,Yang Wang,Hao Chen,Shiwei Liu,Shizhe Diao,Can Yang,Lu Yin*

Main category: cs.CL

TL;DR: Double-Checker是一个框架，通过自批判和迭代改进，显著提升了慢思考LLM的推理能力，尤其是在AIME基准测试上。


<details>
  <summary>Details</summary>
Motivation: 慢思考大型语言模型（LLM）虽然表现出类反思的推理能力，但其生成有益批判和完善先前解决方案的能力有限。

Method: 本文引入了Double-Checker框架，旨在通过促进明确的自我批判和对其先前解决方案的迭代完善来增强慢思考LLM的推理能力。通过在我们精心策划的1,730个自批判实例上进行微调，Double-Checker使长链思维（long-CoT）LLM能够在推理过程中迭代地批判和完善其输出，直到它们在自我生成的批判下评估其解决方案是正确的。

Result: Double-Checker在全面的推理基准测试中验证了其有效性，证明迭代自批判显著增强了长链思维LLM的推理能力。值得注意的是，与原始长链思维LLM相比，我们的Double-Checker在挑战性的AIME基准测试上将pass@1性能从4.4%提高到18.2%。

Conclusion: 这些结果为开发更值得信赖、更有效的、能够进行结构化自我批判的LLM指明了一个有前景的方向。

Abstract: While slow-thinking large language models (LLMs) exhibit reflection-like
reasoning, commonly referred to as the "aha moment:, their ability to generate
informative critiques and refine prior solutions remains limited. In this
paper, we introduce Double-Checker, a principled framework designed to enhance
the reasoning capabilities of slow-thinking LLMs by fostering explicit
self-critique and iterative refinement of their previous solutions. By
fine-tuning on our curated 1,730 self-critical instances, Double-Checker
empowers long-CoT LLMs to iteratively critique and refine their outputs during
inference until they evaluate their solutions as correct under self-generated
critiques. We validate the efficacy of Double-Checker across a comprehensive
suite of reasoning benchmarks, demonstrating that iterative self-critique
significantly enhances the reasoning capabilities of long-CoT LLMs. Notably,
our Double-Checker increases the pass@1 performance on challenging AIME
benchmarks from 4.4% to 18.2% compared to the original long-CoT LLMs. These
results highlight a promising direction for developing more trustworthy and
effective LLMs capable of structured self-critique.

</details>


### [25] [Small Encoders Can Rival Large Decoders in Detecting Groundedness](https://arxiv.org/abs/2506.21288)
*Istabrak Abbes,Gabriele Prato,Quentin Fournier,Fernando Rodriguez,Alaa Boukhary,Adam Elwood,Sarath Chandar*

Main category: cs.CL

TL;DR: 轻量级模型能够准确判断LLM查询是否基于给定上下文，且速度远超大型LLM，从而减少幻觉并节省资源。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在外部上下文缺失时，容易进行无根据的推测，生成不真实的内容。为了确保事实一致性和可信度，需要判断查询是否严格基于所提供的上下文。

Method: 本文专注于在LLM生成答案之前，检测给定查询是否基于所提供的文档。研究使用轻量级、特定任务的编码器模型（如RoBERTa和NomicBERT），并在精选数据集上进行微调。

Result: 轻量级编码器模型在接地性检测方面的准确性可与Llama3 8B和GPT4o等最先进的LLM相媲美，同时将推理延迟降低了几个数量级。

Conclusion: 轻量级编码器模型在LLM接地性检测中表现出色，其性能与大型LLM相当，但计算成本显著降低，有效解决了LLM生成无根据内容的问题。

Abstract: Augmenting large language models (LLMs) with external context significantly
improves their performance in natural language processing (NLP) tasks. However,
LLMs struggle to answer queries reliably when the provided context lacks
information, often resorting to ungrounded speculation or internal knowledge.
Groundedness - generating responses strictly supported by the context - is
essential for ensuring factual consistency and trustworthiness. This study
focuses on detecting whether a given query is grounded in a document provided
in context before the costly answer generation by LLMs. Such a detection
mechanism can significantly reduce both inference time and resource
consumption. We show that lightweight, task specific encoder models such as
RoBERTa and NomicBERT, fine-tuned on curated datasets, can achieve accuracy
comparable to state-of-the-art LLMs, such as Llama3 8B and GPT4o, in
groundedness detection while reducing inference latency by orders of magnitude.
The code is available at : https://github.com/chandarlab/Hallucinate-less

</details>


### [26] [Detecting Referring Expressions in Visually Grounded Dialogue with Autoregressive Language Models](https://arxiv.org/abs/2506.21294)
*Bram Willemsen,Gabriel Skantze*

Main category: cs.CL

TL;DR: 本文探讨了文本模式的语言模型在视觉对话中提取指称表达的能力，发现其在仅依赖语言上下文的情况下仍有效，但指出该任务本质上是多模态的。


<details>
  <summary>Details</summary>
Motivation: 探究仅凭语言上下文，在多大程度上能够识别视觉对话中具有视觉参照物的指称表达。

Method: 采用预训练的大型语言模型（LLM），通过预测下一个词元的方式，在对话文本中粗粒度地标注指称表达的边界，这是一种纯文本、自回归的语言建模方法。

Result: 研究发现，即使使用中等规模的LLM、相对较小的数据集和参数高效的微调，纯文本方法仍然有效，突显了语言上下文在该任务中的相对重要性。

Conclusion: 该任务本质上是一个多模态问题，并且单模态方法存在固有的局限性。

Abstract: In this paper, we explore the use of a text-only, autoregressive language
modeling approach for the extraction of referring expressions from visually
grounded dialogue. More specifically, the aim is to investigate the extent to
which the linguistic context alone can inform the detection of mentions that
have a (visually perceivable) referent in the visual context of the
conversation. To this end, we adapt a pretrained large language model (LLM) to
perform a relatively course-grained annotation of mention spans in unfolding
conversations by demarcating mention span boundaries in text via next-token
prediction. Our findings indicate that even when using a moderately sized LLM,
relatively small datasets, and parameter-efficient fine-tuning, a text-only
approach can be effective, highlighting the relative importance of the
linguistic context for this task. Nevertheless, we argue that the task
represents an inherently multimodal problem and discuss limitations fundamental
to unimodal approaches.

</details>


### [27] [Structuralist Approach to AI Literary Criticism: Leveraging Greimas Semiotic Square for Large Language Models](https://arxiv.org/abs/2506.21360)
*Fangzhou Dong,Yifan Zeng,Yingpeng Sang,Hong Shen*

Main category: cs.CL

TL;DR: GLASS (基于格雷马斯符号方阵的文学分析框架) 提升了大型语言模型 (LLMs) 进行深度文学分析的能力，并提供了首个相关数据集和评估指标，其分析结果表现出色，可作为AI辅助文学研究和教育的工具。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在处理具有深刻思想和复杂叙事的文学作品时，难以提供专业的文学批评。

Method: 本文提出了GLASS（Greimas Literary Analysis via Semiotic Square），一个基于格雷马斯符号方阵（GSS）的结构化分析框架，旨在增强LLM进行深度文学分析的能力。此外，论文还提出了首个用于GSS文学批评的数据集，并基于“LLM-as-a-judge”范式提出了GSS文学批评的量化指标。

Result: 与专家批评和多种LLM的比较显示，GLASS框架表现出高性能。通过将GLASS应用于39部经典作品，产生了原创且高质量的分析，填补了现有研究空白。

Conclusion: 这项研究为文学研究和教育提供了一个AI工具，并深入了解了文学参与背后的认知机制。

Abstract: Large Language Models (LLMs) excel in understanding and generating text but
struggle with providing professional literary criticism for works with profound
thoughts and complex narratives. This paper proposes GLASS (Greimas Literary
Analysis via Semiotic Square), a structured analytical framework based on
Greimas Semiotic Square (GSS), to enhance LLMs' ability to conduct in-depth
literary analysis. GLASS facilitates the rapid dissection of narrative
structures and deep meanings in narrative works. We propose the first dataset
for GSS-based literary criticism, featuring detailed analyses of 48 works. Then
we propose quantitative metrics for GSS-based literary criticism using the
LLM-as-a-judge paradigm. Our framework's results, compared with expert
criticism across multiple works and LLMs, show high performance. Finally, we
applied GLASS to 39 classic works, producing original and high-quality analyses
that address existing research gaps. This research provides an AI-based tool
for literary research and education, offering insights into the cognitive
mechanisms underlying literary engagement.

</details>


### [28] [Leveraging LLM-Assisted Query Understanding for Live Retrieval-Augmented Generation](https://arxiv.org/abs/2506.21384)
*Guanting Dong,Xiaoxi Li,Yuyao Zhang,Mengjie Deng*

Main category: cs.CL

TL;DR: Omni-RAG是一个为实时RAG系统设计的框架，通过LLM辅助查询理解、意图感知检索和重排生成，解决噪声和复杂查询问题，提升系统鲁棒性和有效性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的RAG系统在处理嘈杂、模糊和多意图的用户查询时面临挑战，现有系统难以处理此类复杂输入。

Method: 提出Omni-RAG框架，通过LLM辅助查询理解预处理用户输入。包含三个关键模块：1) 深度查询理解和分解，利用LLM纠正拼写错误并将多意图查询分解为结构化子查询；2) 意图感知知识检索，对每个子查询执行检索并聚合结果；3) 重排和生成，使用重排器（如BGE）精炼文档选择，然后由LLM（如Falcon-10B）使用思维链提示生成最终响应。

Result: 提高了RAG系统在实时、开放领域设置中的鲁棒性和有效性。

Conclusion: Omni-RAG旨在通过稳健处理复杂和嘈杂的查询，弥合当前RAG能力与实际应用需求之间的差距。

Abstract: Real-world live retrieval-augmented generation (RAG) systems face significant
challenges when processing user queries that are often noisy, ambiguous, and
contain multiple intents. While RAG enhances large language models (LLMs) with
external knowledge, current systems typically struggle with such complex
inputs, as they are often trained or evaluated on cleaner data. This paper
introduces Omni-RAG, a novel framework designed to improve the robustness and
effectiveness of RAG systems in live, open-domain settings. Omni-RAG employs
LLM-assisted query understanding to preprocess user inputs through three key
modules: (1) Deep Query Understanding and Decomposition, which utilizes LLMs
with tailored prompts to denoise queries (e.g., correcting spelling errors) and
decompose multi-intent queries into structured sub-queries; (2) Intent-Aware
Knowledge Retrieval, which performs retrieval for each sub-query from a corpus
(i.e., FineWeb using OpenSearch) and aggregates the results; and (3) Reranking
and Generation, where a reranker (i.e., BGE) refines document selection before
a final response is generated by an LLM (i.e., Falcon-10B) using a
chain-of-thought prompt. Omni-RAG aims to bridge the gap between current RAG
capabilities and the demands of real-world applications, such as those
highlighted by the SIGIR 2025 LiveRAG Challenge, by robustly handling complex
and noisy queries.

</details>


### [29] [Domain Knowledge-Enhanced LLMs for Fraud and Concept Drift Detection](https://arxiv.org/abs/2506.21443)
*Ali Şenol,Garima Agrawal,Huan Liu*

Main category: cs.CL

TL;DR: 一个领域知识增强的LLM框架，通过整合领域知识和概念漂移检测，高精度地识别欺骗性对话和语义漂移。


<details>
  <summary>Details</summary>
Motivation: 由于语言模式演变、概念漂移以及大型语言模型在风险敏感场景中处理上下文模糊性和幻觉的困难，检测动态平台上的欺骗性对话变得越来越困难。

Method: 本文提出了一个领域知识（DK）增强的LLM框架，该框架将预训练的LLM与结构化、任务特定的洞察相结合，以执行欺诈和概念漂移检测。该架构包括三个主要组件：(1)一个DK-LLM模块用于检测虚假或欺骗性对话；(2)一个漂移检测单元（OCDD）用于确定是否发生了语义漂移；(3)第二个DK-LLM模块用于将漂移分类为良性或欺诈性。

Result: 我们的系统能高精度地检测虚假对话并有效分类漂移的性质。在结构化提示的指导下，基于LLaMA的实现达到了98%的分类准确率。与零样本基线的比较研究表明，整合领域知识和漂移感知显著提高了高风险NLP应用程序的性能、可解释性和鲁棒性。

Conclusion: 通过整合领域知识和漂移感知，所提出的领域知识增强型LLM框架能够有效应对检测欺骗性对话和概念漂移的挑战，显著提升了性能、可解释性和鲁棒性。

Abstract: Detecting deceptive conversations on dynamic platforms is increasingly
difficult due to evolving language patterns and Concept Drift (CD)-i.e.,
semantic or topical shifts that alter the context or intent of interactions
over time. These shifts can obscure malicious intent or mimic normal dialogue,
making accurate classification challenging. While Large Language Models (LLMs)
show strong performance in natural language tasks, they often struggle with
contextual ambiguity and hallucinations in risk-sensitive scenarios. To address
these challenges, we present a Domain Knowledge (DK)-Enhanced LLM framework
that integrates pretrained LLMs with structured, task-specific insights to
perform fraud and concept drift detection. The proposed architecture consists
of three main components: (1) a DK-LLM module to detect fake or deceptive
conversations; (2) a drift detection unit (OCDD) to determine whether a
semantic shift has occurred; and (3) a second DK-LLM module to classify the
drift as either benign or fraudulent. We first validate the value of domain
knowledge using a fake review dataset and then apply our full framework to
SEConvo, a multiturn dialogue dataset that includes various types of fraud and
spam attacks. Results show that our system detects fake conversations with high
accuracy and effectively classifies the nature of drift. Guided by structured
prompts, the LLaMA-based implementation achieves 98% classification accuracy.
Comparative studies against zero-shot baselines demonstrate that incorporating
domain knowledge and drift awareness significantly improves performance,
interpretability, and robustness in high-stakes NLP applications.

</details>


### [30] [Text2Cypher Across Languages: Evaluating Foundational Models Beyond English](https://arxiv.org/abs/2506.21445)
*Makbule Gulcin Ozsoy,William Tai*

Main category: cs.CL

TL;DR: 该研究评估了基础大型语言模型在多语言Text2Cypher任务上的表现，发现英文性能最佳，西班牙语次之，土耳其语最差，并发布了一个新的多语言测试集。


<details>
  <summary>Details</summary>
Motivation: 目前大多数Text2SQL类研究仅关注英文，对其他语言的评估有限。

Method: 通过将英文问题翻译成西班牙语和土耳其语，并保留原始Cypher查询，创建并发布了一个多语言Text2Cypher测试集；使用标准化提示和指标评估了多个基础模型；还探讨了任务提示翻译的影响。

Result: 模型性能表现出一致的模式：英文最高，西班牙语次之，土耳其语最低；指令翻译对评估指标影响很小甚至没有影响。

Conclusion: 研究结果强调了在多语言查询生成中进行更具包容性的评估和开发的必要性。

Abstract: Recent advances in large language models have enabled natural language
interfaces that translate user questions into database queries, such as
Text2SQL, Text2SPARQL, and Text2Cypher. While these interfaces enhance database
accessibility, most research today focuses solely on English, with limited
evaluation in other languages. This paper investigates the performance of
foundational LLMs on the Text2Cypher task across multiple languages. We create
and release a multilingual test set by translating English questions into
Spanish and Turkish while preserving the original Cypher queries, enabling fair
cross-lingual comparison. We evaluate multiple foundational models using
standardized prompts and metrics. Our results show a consistent performance
pattern: highest on English, then Spanish, and lowest on Turkish. We attribute
this to differences in training data availability and linguistic
characteristics. Additionally, we explore the impact of translating task
prompts into Spanish and Turkish. Results show little to no change in
evaluation metrics, suggesting prompt translation has minor impact. Our
findings highlight the need for more inclusive evaluation and development in
multilingual query generation. Future work includes schema localization and
fine-tuning across diverse languages.

</details>


### [31] [Aligning Spoken Dialogue Models from User Interactions](https://arxiv.org/abs/2506.21463)
*Anne Wu,Laurent Mazaré,Neil Zeghidour,Alexandre Défossez*

Main category: cs.CL

TL;DR: 该论文提出了一种新的偏好对齐框架，并利用大型数据集改进了实时语音对话模型，使其在真实世界互动中更具事实性、安全性和上下文对齐性。


<details>
  <summary>Details</summary>
Motivation: 当前的偏好学习方法主要关注基于文本的语言模型，不适用于实时语音交互的复杂性，因为实时语音交互具有更丰富的动态（例如，打断、插入语）且说话人之间没有明确的转折分割。

Method: 提出了一种新颖的偏好对齐框架，用于从用户交互中改进实时对话的口语对话模型。创建了一个包含超过150,000对偏好的大规模数据集，该数据集来自原始多轮语音对话，并用AI反馈进行标注。利用离线对齐方法微调了一个全双工自回归语音到语音模型。

Result: 广泛的实验表明，对通用对话的反馈可以持续有效地改进口语对话模型，使其产生更具事实性、更安全和更具上下文对齐性的交互。部署了微调后的模型并进行了整体人工评估，以评估其在单轮对话之外的影响。

Conclusion: 研究结果揭示了在各种动态之间实现良好校准平衡的重要性，这对于自然的实时语音对话系统至关重要。

Abstract: We propose a novel preference alignment framework for improving spoken
dialogue models on real-time conversations from user interactions. Current
preference learning methods primarily focus on text-based language models, and
are not directly suited to the complexities of real-time speech interactions,
with richer dynamics (e.g. interruption, interjection) and no explicit
segmentation between speaker turns.We create a large-scale dataset of more than
150,000 preference pairs from raw multi-turn speech conversations, annotated
with AI feedback, to cover preferences over both linguistic content and
temporal context variations. We leverage offline alignment methods to finetune
a full-duplex autoregressive speech-to-speech model. Extensive experiments
demonstrate that feedback on generic conversations can be consistently
effective in improving spoken dialogue models to produce more factual, safer
and more contextually aligned interactions. We deploy the finetuned model and
conduct holistic human evaluations to assess the impact beyond single-turn
conversations. Our findings shed light on the importance of a well-calibrated
balance among various dynamics, crucial for natural real-time speech dialogue
systems.

</details>


### [32] [TopK Language Models](https://arxiv.org/abs/2506.21468)
*Ryosuke Takahashi,Tatsuro Inaba,Kentaro Inui,Benjamin Heinzerling*

Main category: cs.CL

TL;DR: 稀疏自编码器（SAE）存在后验训练和特征稳定性问题。本文提出TopK LM，通过在Transformer架构中集成TopK激活函数来解决这些问题，从而无需后验训练并提供强大的可解释性，有助于理解和控制语言模型。


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器（SAE）作为分析和解释Transformer语言模型激活空间的重要工具，存在局限性。具体表现为：后验训练导致无法区分是SAE还是底层语言模型未表示某个概念；训练条件和架构选择影响特征学习；以及特征缺乏稳定性，难以比较不同检查点学到的特征。

Method: 为解决现有SAE的局限性，本文提出修改Transformer架构，在选定层引入TopK激活函数，使模型的隐藏状态等同于TopK SAE的潜在特征。这种方法消除了后验训练的需要，同时提供了与SAE相当的解释性。

Result: 所提出的TopK LM在模型大小、计算效率和可解释性之间实现了良好的平衡，并且在进行简单的架构更改后仍能保持其原始能力。实验表明，TopK LM学习到的稀疏表示能够通过定向神经元干预实现成功的模型引导，并有助于详细分析跨检查点和层的神经元形成过程。

Conclusion: TopK LM作为一种稳定可靠的工具，有助于深入理解语言模型如何学习和表示概念，有望显著推动未来模型可解释性和可控性的研究。

Abstract: Sparse autoencoders (SAEs) have become an important tool for analyzing and
interpreting the activation space of transformer-based language models (LMs).
However, SAEs suffer several shortcomings that diminish their utility and
internal validity. Since SAEs are trained post-hoc, it is unclear if the
failure to discover a particular concept is a failure on the SAE's side or due
to the underlying LM not representing this concept. This problem is exacerbated
by training conditions and architecture choices affecting which features an SAE
learns. When tracing how LMs learn concepts during training, the lack of
feature stability also makes it difficult to compare SAEs features across
different checkpoints. To address these limitations, we introduce a
modification to the transformer architecture that incorporates a TopK
activation function at chosen layers, making the model's hidden states
equivalent to the latent features of a TopK SAE. This approach eliminates the
need for post-hoc training while providing interpretability comparable to SAEs.
The resulting TopK LMs offer a favorable trade-off between model size,
computational efficiency, and interpretability. Despite this simple
architectural change, TopK LMs maintain their original capabilities while
providing robust interpretability benefits. Our experiments demonstrate that
the sparse representations learned by TopK LMs enable successful steering
through targeted neuron interventions and facilitate detailed analysis of
neuron formation processes across checkpoints and layers. These features make
TopK LMs stable and reliable tools for understanding how language models learn
and represent concepts, which we believe will significantly advance future
research on model interpretability and controllability.

</details>


### [33] [Bridging Offline and Online Reinforcement Learning for LLMs](https://arxiv.org/abs/2506.21495)
*Jack Lanchantin,Angelica Chen,Janice Lan,Xian Li,Swarnadeep Saha,Tianlu Wang,Jing Xu,Ping Yu,Weizhe Yuan,Jason E Weston,Sainbayar Sukhbaatar,Ilia Kulikov*

Main category: cs.CL

TL;DR: 研究发现，在线和半在线强化学习微调LLM在可验证和不可验证任务上均优于离线方法，DPO和GRPO表现相似，多任务学习能进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探究强化学习方法在不同在线模式（离线、半在线、完全在线）下，对可验证和不可验证任务的大型语言模型进行微调的有效性。

Method: 作者比较了在线和半在线直接偏好优化（DPO）和群组奖励策略优化（GRPO）目标函数，并在可验证的数学任务和不可验证的指令遵循任务上进行了实验。研究还分析了训练动态和超参数选择策略，并探索了可验证和不可验证奖励的联合多任务处理。

Result: 实验结果显示，在线和半在线的DPO和GRPO变体在性能和收敛性上相似，并且都显著优于离线方法。此外，可验证和不可验证奖励的联合多任务处理能提升两类任务的性能。

Conclusion: 总的来说，强化学习方法，特别是在线和半在线设置下的方法，在微调大型语言模型以处理可验证和不可验证任务方面表现出色，并优于离线方法。联合多任务学习可以进一步提升性能。

Abstract: We investigate the effectiveness of reinforcement learning methods for
finetuning large language models when transitioning from offline to semi-online
to fully online regimes for both verifiable and non-verifiable tasks. Our
experiments cover training on verifiable math as well as non-verifiable
instruction following with a set of benchmark evaluations for both. Across
these settings, we extensively compare online and semi-online Direct Preference
Optimization and Group Reward Policy Optimization objectives, and surprisingly
find similar performance and convergence between these variants, which all
strongly outperform offline methods. We provide a detailed analysis of the
training dynamics and hyperparameter selection strategies to achieve optimal
results. Finally, we show that multi-tasking with verifiable and non-verifiable
rewards jointly yields improved performance across both task types.

</details>


### [34] [Enhancing User Engagement in Socially-Driven Dialogue through Interactive LLM Alignments](https://arxiv.org/abs/2506.21497)
*Jiashuo Wang,Kaitao Song,Chunpu Xu,Changhe Song,Yang Xiao,Dongsheng Li,Lili Qiu,Wenjie Li*

Main category: cs.CL

TL;DR: 该论文提出了一种新方法，通过利用未来对话信号和用户反应，并结合i×MCTS和DPO来提高交互式大型语言模型（LLM）的用户参与度，在社交对话场景中表现出有效性。


<details>
  <summary>Details</summary>
Motivation: 以往的工作虽然优化了模型来推断相关知识或规划对话行为流程，但用户参与度与知识或对话行为之间的关系微妙，不能保证在社交驱动对话中的用户参与度。

Method: 通过利用对话未来发展的信号，使交互式LLMs能够学习用户参与度。具体而言，采用与对话意图相关的用户反应作为奖励信号来对齐交互式LLMs。为此，开发了一个用户模拟器，并使用i×MCTS（用于交互的蒙特卡洛树搜索）来探索用户与交互式LLM系统之间的交互。通过这种方式，收集包含高质量和低质量体验对的数据集，并使用直接偏好优化（DPO）来对齐交互式LLM以实现高水平用户参与度。

Result: 在两种社交驱动对话场景（情感支持对话和劝导）中进行的实验表明，所提出的方法有效提升了交互式LLM中的用户参与度。

Conclusion: 该方法通过利用未来对话信号和基于用户反应进行优化，有效提高了交互式LLMs中的用户参与度。

Abstract: Enhancing user engagement through interactions plays an essential role in
socially-driven dialogues. While prior works have optimized models to reason
over relevant knowledge or plan a dialogue act flow, the relationship between
user engagement and knowledge or dialogue acts is subtle and does not guarantee
user engagement in socially-driven dialogues. To this end, we enable
interactive LLMs to learn user engagement by leveraging signals from the future
development of conversations. Specifically, we adopt a more direct and relevant
indicator of user engagement, i.e., the user's reaction related to dialogue
intention after the interaction, as a reward to align interactive LLMs. To
achieve this, we develop a user simulator to interact with target interactive
LLMs and explore interactions between the user and the interactive LLM system
via \textit{i$\times$MCTS} (\textit{M}onte \textit{C}arlo \textit{T}ree
\textit{S}earch for \textit{i}nteraction). In this way, we collect a dataset
containing pairs of higher and lower-quality experiences using
\textit{i$\times$MCTS}, and align interactive LLMs for high-level user
engagement by direct preference optimization (DPO) accordingly. Experiments
conducted on two socially-driven dialogue scenarios (emotional support
conversations and persuasion for good) demonstrate that our method effectively
enhances user engagement in interactive LLMs.

</details>


### [35] [skLEP: A Slovak General Language Understanding Benchmark](https://arxiv.org/abs/2506.21508)
*Marek Šuppa,Andrej Ridzik,Daniel Hládek,Tomáš Javůrek,Viktória Ondrejová,Kristína Sásiková,Martin Tamajka,Marián Šimko*

Main category: cs.CL

TL;DR: 引入了skLEP，首个斯洛伐克语NLU综合基准，包含多任务数据集、模型评估结果和开源工具，旨在推动该领域研究。


<details>
  <summary>Details</summary>
Motivation: 针对斯洛伐克语自然语言理解（NLU）模型，目前缺乏一个全面的基准测试。

Method: 本文引入了skLEP，这是第一个专门用于评估斯洛伐克语NLU模型的综合基准。它包含了九项多样化的任务，涵盖了词元级、句子对级和文档级挑战。为此，作者整理了新的原创斯洛伐克语数据集，并精心翻译了已有的英语NLU资源。同时，作者还对多种斯洛伐克语专用、多语言和英语预训练语言模型进行了系统而广泛的评估。

Result: 发布了完整的基准数据集、一个便于模型微调和评估的开源工具包，以及一个公共排行榜。

Conclusion: 旨在促进斯洛伐克语NLU领域研究的可复现性和进一步发展。

Abstract: In this work, we introduce skLEP, the first comprehensive benchmark
specifically designed for evaluating Slovak natural language understanding
(NLU) models. We have compiled skLEP to encompass nine diverse tasks that span
token-level, sentence-pair, and document-level challenges, thereby offering a
thorough assessment of model capabilities. To create this benchmark, we curated
new, original datasets tailored for Slovak and meticulously translated
established English NLU resources. Within this paper, we also present the first
systematic and extensive evaluation of a wide array of Slovak-specific,
multilingual, and English pre-trained language models using the skLEP tasks.
Finally, we also release the complete benchmark data, an open-source toolkit
facilitating both fine-tuning and evaluation of models, and a public
leaderboard at https://github.com/slovak-nlp/sklep in the hopes of fostering
reproducibility and drive future research in Slovak NLU.

</details>


### [36] [Potemkin Understanding in Large Language Models](https://arxiv.org/abs/2506.21521)
*Marina Mancoridis,Bec Weeks,Keyon Vafa,Sendhil Mullainathan*

Main category: cs.CL

TL;DR: 大型语言模型（LLM）在基准测试上的成功可能只是“波将金式理解”（Potemkin understanding）的幻觉，即它们以非人类的方式误解概念。研究发现这种现象普遍存在，并反映了概念表示的深层内部不连贯性。


<details>
  <summary>Details</summary>
Motivation: 目前评估大型语言模型（LLM）能力的基准测试，其有效性值得商榷。如果LLM对概念的误解方式与人类不同，那么它们在这些测试上的成功可能仅仅是“波将金式理解”——一种理解的假象。

Method: 本文首先提出了一个形式框架来解决这个问题。然后介绍了两种量化“波将金式理解”存在的方法：一种是使用在三个领域中专门设计的基准测试，另一种是提供其普遍性下限的通用程序。

Result: 研究发现，“波将金式理解”在不同模型、任务和领域中普遍存在。这些失败不仅反映了错误的理解，还反映了概念表示中更深层次的内部不连贯性。

Conclusion: 如果大型语言模型对概念的误解方式与人类不一致，那么现有的基准测试可能无法有效评估其真实能力，从而导致“波将金式理解”的普遍存在，这表明我们需要重新思考评估LLM的方法。

Abstract: Large language models (LLMs) are regularly evaluated using benchmark
datasets. But what justifies making inferences about an LLM's capabilities
based on its answers to a curated set of questions? This paper first introduces
a formal framework to address this question. The key is to note that the
benchmarks used to test LLMs -- such as AP exams -- are also those used to test
people. However, this raises an implication: these benchmarks are only valid
tests if LLMs misunderstand concepts in ways that mirror human
misunderstandings. Otherwise, success on benchmarks only demonstrates potemkin
understanding: the illusion of understanding driven by answers irreconcilable
with how any human would interpret a concept. We present two procedures for
quantifying the existence of potemkins: one using a specially designed
benchmark in three domains, the other using a general procedure that provides a
lower-bound on their prevalence. We find that potemkins are ubiquitous across
models, tasks, and domains. We also find that these failures reflect not just
incorrect understanding, but deeper internal incoherence in concept
representations.

</details>


### [37] ["What's Up, Doc?": Analyzing How Users Seek Health Information in Large-Scale Conversational AI Datasets](https://arxiv.org/abs/2506.21532)
*Akshay Paruchuri,Maryam Aziz,Rohit Vartak,Ayman Ali,Best Uchehara,Xin Liu,Ishan Chatterjee,Monica Agrawal*

Main category: cs.CL

TL;DR: 该研究分析了用户如何与大型语言模型（LLM）进行医疗健康信息查询，通过构建HealthChat-11K数据集，揭示了用户互动模式、潜在风险以及LLM在医疗支持方面需要改进的地方。


<details>
  <summary>Details</summary>
Motivation: 人们越来越多地通过交互式聊天机器人向大型语言模型（LLM）寻求医疗保健信息，然而这些对话的性质和固有风险在很大程度上仍未被探索。

Method: 本文筛选了大规模对话式AI数据集，构建了HealthChat-11K，一个包含1.1万个真实世界对话和2.5万条用户消息的精选数据集。研究使用HealthChat-11K和一个由临床医生驱动的分类法，系统地研究了用户在21个不同健康专业领域寻求医疗保健信息时与LLM的互动。

Result: 分析揭示了关于用户如何以及为何寻求健康信息的见解，例如常见的互动、不完整上下文的实例、情感行为以及可能诱导奉承的互动（例如，引导性问题）。

Conclusion: 强调了部署为对话式AI的LLM在医疗保健支持能力方面需要改进。

Abstract: People are increasingly seeking healthcare information from large language
models (LLMs) via interactive chatbots, yet the nature and inherent risks of
these conversations remain largely unexplored. In this paper, we filter
large-scale conversational AI datasets to achieve HealthChat-11K, a curated
dataset of 11K real-world conversations composed of 25K user messages. We use
HealthChat-11K and a clinician-driven taxonomy for how users interact with LLMs
when seeking healthcare information in order to systematically study user
interactions across 21 distinct health specialties. Our analysis reveals
insights into the nature of how and why users seek health information, such as
common interactions, instances of incomplete context, affective behaviors, and
interactions (e.g., leading questions) that can induce sycophancy, underscoring
the need for improvements in the healthcare support capabilities of LLMs
deployed as conversational AI. Code and artifacts to retrieve our analyses and
combine them into a curated dataset can be found here:
https://github.com/yahskapar/HealthChat

</details>


### [38] [Data Efficacy for Language Model Training](https://arxiv.org/abs/2506.21545)
*Yalun Dai,Yangyu Huang,Xin Zhang,Wenshan Wu,Chong Li,Wenhui Lu,Shijie Cao,Li Dong,Scarlett Li*

Main category: cs.CL

TL;DR: 该论文提出了DELT，一种在语言模型训练中考虑数据功效的新范式，它侧重于优化训练数据组织。DELT包含数据评分、数据选择和数据排序三个组件，并提出了学习能力-质量评分（LQS）和折叠排序（FO）。实验证明DELT能提升LM性能，尤其是LQS和FO的结合效果最佳，且数据功效可与数据效率结合。


<details>
  <summary>Details</summary>
Motivation: 当前研究主要关注数据效率，即通过选择训练数据的子集来最大化性能。为补充这一点，本文定义了“数据功效”，旨在通过优化训练数据的组织来最大化性能，而这一领域相对未被充分探索。

Method: 本文引入了一种通用范式DELT，用于在LM训练中考虑数据功效，该范式强调了训练数据组织的重要性。DELT包含三个组件：数据评分、数据选择和数据排序。其中，设计了学习能力-质量评分（LQS）作为数据评分的一个新实例，它从梯度一致性的角度考虑每个数据样本的可学习性和质量。此外，还设计了折叠排序（FO）作为数据排序的一个新实例，以解决模型遗忘和数据分布偏差等问题。

Result: 全面的实验验证了LM训练中的数据功效：
1. 提出的DELT的各种实例在不增加数据规模和模型大小的情况下，不同程度地提升了LM性能。
2. 在这些实例中，所提出的LQS用于数据评分和折叠排序相结合取得了最显著的改进。
3. 数据功效可以通过应用数据选择与数据效率一起实现。

Conclusion: 数据功效是语言模型训练中一个有前景的基础领域。

Abstract: Data is fundamental to the training of language models (LM). Recent research
has been dedicated to data efficiency, which aims to maximize performance by
selecting a minimal or optimal subset of training data. Techniques such as data
filtering, sampling, and selection play a crucial role in this area. To
complement it, we define Data Efficacy, which focuses on maximizing performance
by optimizing the organization of training data and remains relatively
underexplored. This work introduces a general paradigm, DELT, for considering
data efficacy in LM training, which highlights the significance of training
data organization. DELT comprises three components: Data Scoring, Data
Selection, and Data Ordering. Among these components, we design
Learnability-Quality Scoring (LQS), as a new instance of Data Scoring, which
considers both the learnability and quality of each data sample from the
gradient consistency perspective. We also devise Folding Ordering (FO), as a
novel instance of Data Ordering, which addresses issues such as model
forgetting and data distribution bias. Comprehensive experiments validate the
data efficacy in LM training, which demonstrates the following: Firstly,
various instances of the proposed DELT enhance LM performance to varying
degrees without increasing the data scale and model size. Secondly, among these
instances, the combination of our proposed LQS for data scoring and Folding for
data ordering achieves the most significant improvement. Lastly, data efficacy
can be achieved together with data efficiency by applying data selection.
Therefore, we believe that data efficacy is a promising foundational area in LM
training.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [39] [Exploring Adapter Design Tradeoffs for Low Resource Music Generation](https://arxiv.org/abs/2506.21298)
*Atharva Mehta,Shivam Chauhan,Monojit Choudhury*

Main category: cs.SD

TL;DR: 该研究探讨了MusicGen和Mustango两种音乐AI模型在不同音乐流派中各种适配器配置的有效性。研究发现不同类型的适配器在捕捉音乐细节和长程依赖方面各有优势，中等大小的适配器能达到表达力与质量的最佳平衡。同时，扩散模型（如Mustango）能生成更多样化的内容但计算成本高且稳定性欠佳，而自回归模型（如MusicGen）训练更快、效率更高，但可能存在冗余。


<details>
  <summary>Details</summary>
Motivation: 微调大型音乐生成模型成本高昂，而参数高效微调（PEFT）技术，尤其是基于适配器的方法，虽有潜力，但其最佳设计选择（架构、放置、大小）在低资源音乐流派中的效果尚不明确。

Method: 本研究通过在两种AI音乐模型（MusicGen和Mustango）上，针对印度斯坦古典音乐和土耳其Makam音乐两种流派，系统性地研究了各种适配器配置。

Result: 1. 卷积适配器擅长捕捉精细的局部音乐细节；而Transformer适配器能更好地保留长程依赖。
2. 中等大小的适配器（40M参数）在表达力和质量之间取得了最佳平衡。
3. 扩散模型Mustango能生成更多样化的输出，但音符稳定性、节奏对齐和美学方面不足，且计算密集，训练时间长。
4. 自回归模型MusicGen训练更快、效率更高，能生成更高质量的输出，但其生成内容冗余度稍高。

Conclusion: 本研究揭示了在低资源音乐流派中，不同适配器设计选择（如卷积型和Transformer型）在捕捉音乐细节和保持结构上的权衡，并指出了中等大小适配器在性能和资源消耗上的优化点。同时，对比了扩散模型和自回归模型在音乐生成方面的优缺点及计算成本。

Abstract: Fine-tuning large-scale music generation models, such as MusicGen and
Mustango, is a computationally expensive process, often requiring updates to
billions of parameters and, therefore, significant hardware resources.
Parameter-Efficient Fine-Tuning (PEFT) techniques, particularly adapter-based
methods, have emerged as a promising alternative, enabling adaptation with
minimal trainable parameters while preserving model performance. However, the
design choices for adapters, including their architecture, placement, and size,
are numerous, and it is unclear which of these combinations would produce
optimal adapters and why, for a given case of low-resource music genre. In this
paper, we attempt to answer this question by studying various adapter
configurations for two AI music models, MusicGen and Mustango, on two genres:
Hindustani Classical and Turkish Makam music.
  Our findings reveal distinct trade-offs: convolution-based adapters excel in
capturing fine-grained local musical details such as ornamentations and short
melodic phrases, while transformer-based adapters better preserve long-range
dependencies crucial for structured improvisation. Additionally, we analyze
computational resource requirements across different adapter scales,
demonstrating how mid-sized adapters (40M parameters) achieve an optimal
balance between expressivity and quality. Furthermore, we find that Mustango, a
diffusion-based model, generates more diverse outputs with better adherence to
the description in the input prompt while lacking in providing stability in
notes, rhythm alignment, and aesthetics. Also, it is computationally intensive
and requires significantly more time to train. In contrast, autoregressive
models like MusicGen offer faster training and are more efficient, and can
produce better quality output in comparison, but have slightly higher
redundancy in their generations.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [40] [Hybrid Deep Learning and Signal Processing for Arabic Dialect Recognition in Low-Resource Settings](https://arxiv.org/abs/2506.21386)
*Ghazal Al-Shwayyat,Omer Nezih Gerek*

Main category: eess.AS

TL;DR: 该研究为低资源阿拉伯语方言识别评估了两种混合模型（MFCC+CNN和DWT+RNN），MFCC+CNN表现最佳，准确率达91.2%。


<details>
  <summary>Details</summary>
Motivation: 由于语言多样性和缺乏大型标注数据集，尤其是在低资源场景下，阿拉伯语方言识别面临重大挑战。本研究旨在通过混合建模策略解决此问题。

Method: 开发并评估了两种混合模型：梅尔频率倒谱系数（MFCC）结合卷积神经网络（CNN），以及离散小波变换（DWT）特征结合循环神经网络（RNN）。模型在Common Voice阿拉伯语数据集的方言过滤子集上进行训练。

Result: 实验结果表明，MFCC+CNN架构表现优异，准确率达91.2%，显著优于准确率为66.5%的Wavelet+RNN配置。

Conclusion: 研究强调了谱特征与卷积模型在阿拉伯语方言识别中的有效性，尤其是在标注数据有限的情况下。该研究为资源受限环境下阿拉伯语方言识别的未来发展奠定了坚实的基础，并提出了未来的研究方向和改进建议。

Abstract: Arabic dialect recognition presents a significant challenge in speech
technology due to the linguistic diversity of Arabic and the scarcity of large
annotated datasets, particularly for underrepresented dialects. This research
investigates hybrid modeling strategies that integrate classical signal
processing techniques with deep learning architectures to address this problem
in low-resource scenarios. Two hybrid models were developed and evaluated: (1)
Mel-Frequency Cepstral Coefficients (MFCC) combined with a Convolutional Neural
Network (CNN), and (2) Discrete Wavelet Transform (DWT) features combined with
a Recurrent Neural Network (RNN). The models were trained on a dialect-filtered
subset of the Common Voice Arabic dataset, with dialect labels assigned based
on speaker metadata. Experimental results demonstrate that the MFCC + CNN
architecture achieved superior performance, with an accuracy of 91.2% and
strong precision, recall, and F1-scores, significantly outperforming the
Wavelet + RNN configuration, which achieved an accuracy of 66.5%. These
findings highlight the effectiveness of leveraging spectral features with
convolutional models for Arabic dialect recognition, especially when working
with limited labeled data. The study also identifies limitations related to
dataset size, potential regional overlaps in labeling, and model optimization,
providing a roadmap for future research. Recommendations for further
improvement include the adoption of larger annotated corpora, integration of
self-supervised learning techniques, and exploration of advanced neural
architectures such as Transformers. Overall, this research establishes a strong
baseline for future developments in Arabic dialect recognition within
resource-constrained environments.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [41] [HumanOmniV2: From Understanding to Omni-Modal Reasoning with Context](https://arxiv.org/abs/2506.21277)
*Qize Yang,Shimin Yao,Weixuan Chen,Shenghao Fu,Detao Bai,Jiaxing Zhao,Boyuan Sun,Bowen Yin,Xihan Wei,Jingren Zhou*

Main category: cs.CV

TL;DR: 该论文通过引入新的由LLM评估的奖励（上下文和逻辑奖励）和新的基准（IntentBench），解决了多模态大语言模型中存在的上下文理解不足和捷径问题，从而提升了模型在理解复杂人类意图方面的性能。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型的快速发展，理解和解释人类意图的能力变得至关重要，但这需要深入的推理。强化学习（RL）在增强大型语言模型（LLM）的推理能力方面展现了潜力，但将其应用于多模态数据和格式仍面临挑战。现有模型存在两个主要问题：全局上下文理解不足和捷径问题。

Method: 为解决现有模型中全局上下文理解不足和捷径问题，该研究强调了模型理解多模态输入中全局上下文的必要性。具体方法包括：1. 引入由大型语言模型评估的上下文奖励，以及格式和准确性奖励，以确保对多模态上下文信息的准确解释。2. 利用LLM评估逻辑奖励，判断推理过程是否成功整合了多模态信息与逻辑方法，以提高复杂推理能力。3. 引入一个推理全模态基准（IntentBench），用于评估模型理解复杂人类意图和情感的能力。

Result: 所提出的方法在多个全模态基准测试中，相比其他开源全模态模型，展现出了先进的性能。

Conclusion: 该研究通过解决多模态推理模型中存在的全局上下文理解不足和捷径问题，并引入创新的奖励机制（上下文奖励和逻辑奖励）以及新的评估基准（IntentBench），显著提升了模型理解复杂人类意图的能力。

Abstract: With the rapid evolution of multimodal large language models, the capacity to
deeply understand and interpret human intentions has emerged as a critical
capability, which demands detailed and thoughtful reasoning. In recent studies,
Reinforcement Learning (RL) has demonstrated potential in enhancing the
reasoning capabilities of Large Language Models (LLMs). Nonetheless, the
challenges associated with adapting RL to multimodal data and formats remain
largely unaddressed. In this paper, we identify two issues in existing
multimodal reasoning models: insufficient global context understanding and
shortcut problems. Insufficient context understanding can happen when a model
misinterprets multimodal context, resulting in incorrect answers. The shortcut
problem occurs when the model overlooks crucial clues in multimodal inputs,
directly addressing the query without considering the multimodal information.
To tackle these issues, we emphasize the necessity for the model to reason with
a clear understanding of the global context within multimodal inputs. This
global context understanding can effectively prevent the model from overlooking
key multimodal cues and ensure a thorough reasoning process. To ensure the
accurate interpretation of multimodal context information, we implement a
context reward judged by a large language model, alongside format and accuracy
rewards. Additionally, to improve complex reasoning capability, we employ the
LLM to assess the logical reward, determining whether the reasoning process
successfully integrates multimodal information with logical methods. We also
introduce a reasoning omni-modal benchmark, IntentBench, aimed at evaluating
models in understanding complex human intentions and emotions. Our proposed
method demonstrates advanced performance across multiple omni-modal benchmarks
compared to other open-source omni-modal models.

</details>


### [42] [Logios : An open source Greek Polytonic Optical Character Recognition system](https://arxiv.org/abs/2506.21474)
*Perifanos Konstantinos,Goutsos Dionisis*

Main category: cs.CV

TL;DR: 一个用于希腊语多音素文本的OCR系统，它结合了卷积层和循环层，提高了准确性和效率，并以开源库的形式发布。


<details>
  <summary>Details</summary>
Motivation: 解决希腊语多音素文字带来的独特挑战，并克服传统OCR方法的局限性。

Method: 本文提出了一个光学字符识别（OCR）系统，专门用于希腊语多音素文本的准确识别和数字化。该系统结合了卷积层进行特征提取和循环层进行序列学习。

Result: 该方法显著提高了准确性和效率。该系统底层模型已作为开源库发布，并且OCR平台可供学术使用。

Conclusion: 所提出的系统有效解决了希腊语多音素文本的OCR问题，并提供了显著的性能提升，同时通过开源促进了学术研究和应用。

Abstract: In this paper, we present an Optical Character Recognition (OCR) system
specifically designed for the accurate recognition and digitization of Greek
polytonic texts. By leveraging the combined strengths of convolutional layers
for feature extraction and recurrent layers for sequence learning, our system
addresses the unique challenges posed by Greek polytonic scripts. This approach
aims to overcome the limitations of traditional OCR methods, offering
significant improvements in accuracy and efficiency. We release the underlying
model as an open-source library and make our OCR platform available for
academic use.

</details>


### [43] [HalluSegBench: Counterfactual Visual Reasoning for Segmentation Hallucination Evaluation](https://arxiv.org/abs/2506.21546)
*Xinzhuo Li,Adheesh Juvekar,Xingyou Liu,Muntasir Wahed,Kiet A. Nguyen,Ismini Lourentzou*

Main category: cs.CV

TL;DR: 引入HalluSegBench基准，通过反事实视觉推理评估视觉语言分割模型中的幻觉，发现视觉驱动的幻觉比标签驱动的更普遍。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言分割模型存在幻觉问题，即为图像中不存在的物体生成分割掩码或错误标记不相关区域。当前的评估协议主要关注标签或文本幻觉，未能操纵视觉上下文，限制了诊断关键失败的能力。

Method: 引入HalluSegBench，这是首个专门通过反事实视觉推理来评估视觉接地中幻觉的基准。它包含一个新颖的数据集（1340个反事实实例对，涵盖281个独特对象类别）和一套新引入的指标，用于量化视觉连贯场景编辑下的幻觉敏感性。

Result: 在HalluSegBench上对最先进的视觉语言分割模型进行的实验表明，视觉驱动的幻觉比标签驱动的幻觉更为普遍，模型经常在错误的分割中持续存在。

Conclusion: 迫切需要反事实推理来诊断接地保真度，因为视觉驱动的幻觉更为普遍，并且模型在错误的分割中持续存在。

Abstract: Recent progress in vision-language segmentation has significantly advanced
grounded visual understanding. However, these models often exhibit
hallucinations by producing segmentation masks for objects not grounded in the
image content or by incorrectly labeling irrelevant regions. Existing
evaluation protocols for segmentation hallucination primarily focus on label or
textual hallucinations without manipulating the visual context, limiting their
capacity to diagnose critical failures. In response, we introduce
HalluSegBench, the first benchmark specifically designed to evaluate
hallucinations in visual grounding through the lens of counterfactual visual
reasoning. Our benchmark consists of a novel dataset of 1340 counterfactual
instance pairs spanning 281 unique object classes, and a set of newly
introduced metrics that quantify hallucination sensitivity under visually
coherent scene edits. Experiments on HalluSegBench with state-of-the-art
vision-language segmentation models reveal that vision-driven hallucinations
are significantly more prevalent than label-driven ones, with models often
persisting in false segmentation, highlighting the need for counterfactual
reasoning to diagnose grounding fidelity.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [44] [MAGPIE: A dataset for Multi-AGent contextual PrIvacy Evaluation](https://arxiv.org/abs/2506.20737)
*Gurusha Juneja,Alon Albalak,Wenyue Hua,William Yang Wang*

Main category: cs.AI

TL;DR: 该研究探讨了基于LLM的代理在多轮对话中对上下文隐私的理解和保护能力。发现现有模型在识别和保护隐私信息方面表现不佳，即使在明确指示下也常泄露隐私，并在多智能体任务中失败率高。


<details>
  <summary>Details</summary>
Motivation: 在LLM驱动的智能体协作系统中，隐私至关重要，因为智能体经常访问需要严格保密信息的专有工具和领域特定数据库。本文旨在探讨LLM智能体是否理解上下文隐私，以及在收到指示时，它们是否能在非对抗性多轮对话中保护用户隐私。

Method: 现有基准主要评估单轮、低复杂度的隐私任务，本文提出了一个名为MAGPIE的基准，包含158个跨15个领域的真实高风险场景。然后，使用该基准评估了SOTA LLM（如GPT-4o和Claude-2.7-Sonnet）对上下文私有数据的理解能力，以及它们在不侵犯用户隐私的情况下进行协作的能力。

Result: 实验结果表明，包括GPT-4o和Claude-2.7-Sonnet在内的当前模型缺乏对上下文隐私的深入理解，分别有25.2%和43.6%的时间错误地将私人数据归类为可共享数据。在多轮对话中，即使有明确的隐私指示，这些模型在59.9%和50.5%的案例中披露了私人信息。此外，多智能体系统在71%的场景中未能完成任务。

Conclusion: 目前基于LLM的模型在上下文隐私保护和协作任务解决方面尚未完全对齐。

Abstract: The proliferation of LLM-based agents has led to increasing deployment of
inter-agent collaboration for tasks like scheduling, negotiation, resource
allocation etc. In such systems, privacy is critical, as agents often access
proprietary tools and domain-specific databases requiring strict
confidentiality. This paper examines whether LLM-based agents demonstrate an
understanding of contextual privacy. And, if instructed, do these systems
preserve inference time user privacy in non-adversarial multi-turn
conversation. Existing benchmarks to evaluate contextual privacy in LLM-agents
primarily assess single-turn, low-complexity tasks where private information
can be easily excluded. We first present a benchmark - MAGPIE comprising 158
real-life high-stakes scenarios across 15 domains. These scenarios are designed
such that complete exclusion of private data impedes task completion yet
unrestricted information sharing could lead to substantial losses. We then
evaluate the current state-of-the-art LLMs on (a) their understanding of
contextually private data and (b) their ability to collaborate without
violating user privacy. Empirical experiments demonstrate that current models,
including GPT-4o and Claude-2.7-Sonnet, lack robust understanding of contextual
privacy, misclassifying private data as shareable 25.2\% and 43.6\% of the
time. In multi-turn conversations, these models disclose private information in
59.9\% and 50.5\% of cases even under explicit privacy instructions.
Furthermore, multi-agent systems fail to complete tasks in 71\% of scenarios.
These results underscore that current models are not aligned towards both
contextual privacy preservation and collaborative task-solving.

</details>


### [45] [Beyond Reactive Safety: Risk-Aware LLM Alignment via Long-Horizon Simulation](https://arxiv.org/abs/2506.20949)
*Chenkai Sun,Denghui Zhang,ChengXiang Zhai,Heng Ji*

Main category: cs.AI

TL;DR: 鉴于语言模型代理在社会决策中的影响力日益增长，理解其建议的深远影响至关重要。本文提出了一个概念验证框架，用于预测模型生成的建议如何在宏观社会系统中传播，并引入了一个包含100个间接危害场景的数据集，以评估模型的长期安全意识。该方法在新数据集上取得了20%以上的改进，并在现有安全基准上取得了70%以上的胜率，为更安全的代理指明了方向。


<details>
  <summary>Details</summary>
Motivation: 鉴于语言模型代理在重要的社会决策中影响力日益增长，为了确保其有益影响，需要理解其建议的深远影响。

Method: 提出了一个概念验证框架，用于预测模型生成的建议如何随时间在宏观社会系统中传播。同时，引入了一个包含100个间接危害场景的数据集，用于测试模型预见看似无害的用户提示可能导致的非显而易见的负面结果的能力。

Result: 该方法在新数据集上实现了20%以上的改进，并且在现有安全基准（如AdvBench、SafeRLHF、WildGuardMix）上，相对于强基线，平均胜率超过70%。

Conclusion: 研究结果表明，这为开发更安全的代理提供了一个有希望的方向。

Abstract: Given the growing influence of language model-based agents on high-stakes
societal decisions, from public policy to healthcare, ensuring their beneficial
impact requires understanding the far-reaching implications of their
suggestions. We propose a proof-of-concept framework that projects how
model-generated advice could propagate through societal systems on a
macroscopic scale over time, enabling more robust alignment. To assess the
long-term safety awareness of language models, we also introduce a dataset of
100 indirect harm scenarios, testing models' ability to foresee adverse,
non-obvious outcomes from seemingly harmless user prompts. Our approach
achieves not only over 20% improvement on the new dataset but also an average
win rate exceeding 70% against strong baselines on existing safety benchmarks
(AdvBench, SafeRLHF, WildGuardMix), suggesting a promising direction for safer
agents.

</details>


### [46] [Unveiling Causal Reasoning in Large Language Models: Reality or Mirage?](https://arxiv.org/abs/2506.21215)
*Haoang Chi,He Li,Wenjing Yang,Feng Liu,Long Lan,Xiaoguang Ren,Tongliang Liu,Bo Han*

Main category: cs.AI

TL;DR: 大型语言模型（LLM）在因果推理方面表现出浅层（L1）能力，缺乏人类般的深层（L2）理解。本研究通过分析LLM的自回归机制并引入新的基准测试CausalProbe-2024来证实这一点。为弥补L2因果推理的不足，我们提出了G^2-Reasoner，该方法融合了通用知识和目标导向提示，显著提升了LLM在全新和反事实语境下的因果推理能力，为LLM迈向真正因果推理指明了方向。


<details>
  <summary>Details</summary>
Motivation: 因果推理能力对推动大型语言模型（LLM）实现强大人工智能至关重要。尽管多功能LLM似乎在理解上下文因果关系和提供符合因果律的响应方面表现出能力，但它们是否执行类似人类的真正因果推理仍不清楚。目前的证据表明并非如此，LLM主要停留在浅层（一级）因果推理，缺乏真正类人（二级）因果推理的能力。

Method: 方法上，深入研究了基于Transformer的LLM的自回归机制，揭示其并非固有因果。实证上，引入了一个新的因果问答基准CausalProbe-2024，其语料库对所研究的LLM来说是全新的且几乎未曾见过。为了弥合向二级因果推理的差距，我们提出了G^2-Reasoner，该方法将通用知识和目标导向提示融入到LLM的因果推理过程中。

Result: LLM在CausalProbe-2024上的表现比早期基准有显著下降，这表明它们主要进行一级因果推理。实验表明，G^2-Reasoner显著增强了LLM的因果推理能力，特别是在全新和反事实的上下文中。

Conclusion: 这项工作为LLM朝着真正的因果推理迈进、超越一级并向二级迈进提供了一条新途径。

Abstract: Causal reasoning capability is critical in advancing large language models
(LLMs) toward strong artificial intelligence. While versatile LLMs appear to
have demonstrated capabilities in understanding contextual causality and
providing responses that obey the laws of causality, it remains unclear whether
they perform genuine causal reasoning akin to humans. However, current evidence
indicates the contrary. Specifically, LLMs are only capable of performing
shallow (level-1) causal reasoning, primarily attributed to the causal
knowledge embedded in their parameters, but they lack the capacity for genuine
human-like (level-2) causal reasoning. To support this hypothesis,
methodologically, we delve into the autoregression mechanism of
transformer-based LLMs, revealing that it is not inherently causal.
Empirically, we introduce a new causal Q&A benchmark called CausalProbe-2024,
whose corpora are fresh and nearly unseen for the studied LLMs. The LLMs
exhibit a significant performance drop on CausalProbe-2024 compared to earlier
benchmarks, indicating the fact that they primarily engage in level-1 causal
reasoning. To bridge the gap towards level-2 causal reasoning, we draw
inspiration from the fact that human reasoning is usually facilitated by
general knowledge and intended goals. We propose G^2-Reasoner, a method that
incorporates general knowledge and goal-oriented prompts into LLMs' causal
reasoning processes. Experiments demonstrate that G^2-Reasoner significantly
enhances LLMs' causal reasoning capability, particularly in fresh and
counterfactual contexts. This work sheds light on a new path for LLMs to
advance towards genuine causal reasoning, going beyond level-1 and making
strides towards level-2.

</details>


### [47] [Spatial Mental Modeling from Limited Views](https://arxiv.org/abs/2506.21458)
*Baiqiao Yin,Qineng Wang,Pingyue Zhang,Jianshu Zhang,Kangrui Wang,Zihan Wang,Jieyu Zhang,Keshigeyan Chandrasegaran,Han Liu,Ranjay Krishna,Saining Xie,Manling Li,Jiajun Wu,Li Fei-Fei*

Main category: cs.AI

TL;DR: 视觉语言模型（VLM）在仅有少量视角的情况下难以像人类一样想象完整场景。本文提出了MindCube基准来揭示这一差距，并通过“先地图后推理”（map-then-reason）的方法，即联合训练模型先生成认知地图再进行推理，并结合强化学习，显著提高了VLM对不可观测空间的理解能力。


<details>
  <summary>Details</summary>
Motivation: 人类能够从少数视角想象完整的场景，并形成空间心理模型来推理布局、视角和运动。然而，现有的视觉语言模型（VLM）在这方面存在关键差距，表现出接近随机的性能。本文旨在揭示并解决VLM在构建鲁棒空间心理模型方面的不足。

Method: 1. 引入了一个名为MindCube的新基准，包含21,154个问题和3,268张图像，用于系统评估VLM在表示位置（认知映射）、方向（透视采纳）和动态（心理模拟）方面构建空间心理模型的能力。
2. 探索了三种帮助VLM近似空间心理模型的方法：未见的中间视图、自然语言推理链和认知地图。
3. 提出了一种协同方法，称为“先地图后推理”（map-then-reason），该方法联合训练模型，使其首先生成认知地图，然后在此基础上进行推理。
4. 进一步引入强化学习来提升模型的性能。

Result: 1. 现有VLM在MindCube基准上的表现接近随机。
2. “先地图后推理”方法将准确率从37.8%提升到60.8%（提高了23.0%）。
3. 加入强化学习后，性能进一步提升至70.7%（提高了32.9%）。

Conclusion: 通过主动构建和利用内部结构化空间表示并结合灵活的推理过程来构建空间心理模型，可以显著提高视觉语言模型（VLM）对不可观测空间的理解能力。

Abstract: Can Vision Language Models (VLMs) imagine the full scene from just a few
views, like humans do? Humans form spatial mental models, internal
representations of unseen space, to reason about layout, perspective, and
motion. Our new MindCube benchmark with 21,154 questions across 3,268 images
exposes this critical gap, where existing VLMs exhibit near-random performance.
Using MindCube, we systematically evaluate how well VLMs build robust spatial
mental models through representing positions (cognitive mapping), orientations
(perspective-taking), and dynamics (mental simulation for "what-if" movements).
We then explore three approaches to help VLMs approximate spatial mental
models, including unseen intermediate views, natural language reasoning chains,
and cognitive maps. The significant improvement comes from a synergistic
approach, "map-then-reason", that jointly trains the model to first generate a
cognitive map and then reason upon it. By training models to reason over these
internal maps, we boosted accuracy from 37.8% to 60.8% (+23.0%). Adding
reinforcement learning pushed performance even further to 70.7% (+32.9%). Our
key insight is that such scaffolding of spatial mental models, actively
constructing and utilizing internal structured spatial representations with
flexible reasoning processes, significantly improves understanding of
unobservable space.

</details>


### [48] [Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge](https://arxiv.org/abs/2506.21506)
*Boyu Gou,Zanming Huang,Yuting Ning,Yu Gu,Michael Lin,Weijian Qi,Andrei Kopanev,Botao Yu,Bernal Jiménez Gutiérrez,Yiheng Shu,Chan Hee Song,Jiaman Wu,Shijie Chen,Hanane Nour Moussa,Tianshu Zhang,Jian Xie,Yifei Li,Tianci Xue,Zeyi Liao,Kai Zhang,Boyuan Zheng,Zhaowei Cai,Viktor Rozgic,Morteza Ziyadi,Huan Sun,Yu Su*

Main category: cs.AI

TL;DR: 该论文介绍了Mind2Web 2，一个用于评估自主搜索系统的基准测试，以及Agent-as-a-Judge框架。结果显示，OpenAI Deep Research在性能上已能达到人类的50-70%。


<details>
  <summary>Details</summary>
Motivation: 现有的评估基准和方法已无法满足日益复杂和开放的自主搜索系统的需求。

Method: 引入了Mind2Web 2，一个包含130个真实、高质量、长周期任务的基准测试；提出了一种新颖的Agent-as-a-Judge框架，用于自动评估答案的正确性和来源归属。

Result: 最佳性能系统OpenAI Deep Research已能达到人类性能的50-70%，同时花费一半的时间。

Conclusion: Mind2Web 2为开发和评估下一代自主搜索系统奠定了坚实的基础。

Abstract: Agentic search such as Deep Research systems, where large language models
autonomously browse the web, synthesize information, and return comprehensive
citation-backed answers, represents a major shift in how users interact with
web-scale information. While promising greater efficiency and cognitive
offloading, the growing complexity and open-endedness of agentic search have
outpaced existing evaluation benchmarks and methodologies, which largely assume
short search horizons and static answers. In this paper, we introduce Mind2Web
2, a benchmark of 130 realistic, high-quality, and long-horizon tasks that
require real-time web browsing and extensive information synthesis, constructed
with over 1,000 hours of human labor. To address the challenge of evaluating
time-varying and complex answers, we propose a novel Agent-as-a-Judge
framework. Our method constructs task-specific judge agents based on a
tree-structured rubric design to automatically assess both answer correctness
and source attribution. We conduct a comprehensive evaluation of nine frontier
agentic search systems and human performance, along with a detailed error
analysis to draw insights for future development. The best-performing system,
OpenAI Deep Research, can already achieve 50-70% of human performance while
spending half the time, showing a great potential. Altogether, Mind2Web 2
provides a rigorous foundation for developing and benchmarking the next
generation of agentic search systems.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [49] [Leaner Training, Lower Leakage: Revisiting Memorization in LLM Fine-Tuning with LoRA](https://arxiv.org/abs/2506.20856)
*Fei Wang,Baochun Li*

Main category: cs.LG

TL;DR: LoRA微调显著降低大模型记忆化风险，同时保持性能，这与之前在预训练和完全微调中的发现不同。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）中的记忆化使其容易受到数据提取攻击。虽然预训练阶段的记忆化已被广泛研究，但对微调，特别是LoRA微调中的记忆化影响，研究较少。

Method: 本文重新审视了微调中的记忆化，并发现不同微调策略与先前的研究结果存在差异。研究采用了一种更宽松的基于相似性的记忆化度量标准。

Result: 模型规模和数据重复等因素，在LoRA微调中与预训练和完全微调的记忆化趋势不同。研究表明，与完全微调相比，LoRA显著降低了记忆化风险，同时仍保持了强大的任务性能。

Conclusion: LoRA微调在保持模型性能的同时，能有效降低大型语言模型在微调过程中的记忆化风险。

Abstract: Memorization in large language models (LLMs) makes them vulnerable to data
extraction attacks. While pre-training memorization has been extensively
studied, fewer works have explored its impact in fine-tuning, particularly for
LoRA fine-tuning, a widely adopted parameter-efficient method.
  In this work, we re-examine memorization in fine-tuning and uncover a
surprising divergence from prior findings across different fine-tuning
strategies. Factors such as model scale and data duplication, which strongly
influence memorization in pre-training and full fine-tuning, do not follow the
same trend in LoRA fine-tuning. Using a more relaxed similarity-based
memorization metric, we demonstrate that LoRA significantly reduces
memorization risks compared to full fine-tuning, while still maintaining strong
task performance.

</details>


### [50] [SharpZO: Hybrid Sharpness-Aware Vision Language Model Prompt Tuning via Forward-Only Passes](https://arxiv.org/abs/2506.20990)
*Yifan Yang,Zhen Zhang,Rupak Vignesh Swaminathan,Jing Liu,Nathan Susanj,Zheng Zhang*

Main category: cs.LG

TL;DR: SharpZO：一种新的无反向传播VLM微调方法，结合了锐度感知ES和稀疏零阶优化，显著提高了在边缘设备上的准确性和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLM）的微调方法需要反向传播，不适用于内存受限的边缘设备。先前的无反向传播微调方法（如进化策略或零阶优化）性能不佳。

Method: 提出了混合锐度感知零阶优化（SharpZO）方法。该方法分两阶段：首先是锐度感知进化策略阶段，用于全局探索和平滑损失 landscape，以获得良好的初始化；然后是稀疏零阶优化进行精细局部搜索。整个优化过程仅依赖于前向传播。

Result: 在CLIP模型上的实验表明，SharpZO显著提高了准确性和收敛速度，比最先进的仅前向传播方法平均提高了7%。

Conclusion: SharpZO通过锐度感知热身训练，有效提升了零阶VLM微调的性能，解决了现有无反向传播方法的局限性，使其更适用于边缘设备。

Abstract: Fine-tuning vision language models (VLMs) has achieved remarkable performance
across various downstream tasks; yet, it requires access to model gradients
through backpropagation (BP), making them unsuitable for memory-constrained,
inference-only edge devices. To address this limitation, previous work has
explored various BP-free fine-tuning methods. However, these approaches often
rely on high-variance evolutionary strategies (ES) or zeroth-order (ZO)
optimization, and often fail to achieve satisfactory performance. In this
paper, we propose a hybrid Sharpness-aware Zeroth-order optimization (SharpZO)
approach, specifically designed to enhance the performance of ZO VLM
fine-tuning via a sharpness-aware warm-up training. SharpZO features a
two-stage optimization process: a sharpness-aware ES stage that globally
explores and smooths the loss landscape to construct a strong initialization,
followed by a fine-grained local search via sparse ZO optimization. The entire
optimization relies solely on forward passes. Detailed theoretical analysis and
extensive experiments on CLIP models demonstrate that SharpZO significantly
improves accuracy and convergence speed, achieving up to 7% average gain over
state-of-the-art forward-only methods.

</details>


### [51] [Enhancing LLM Tool Use with High-quality Instruction Data from Knowledge Graph](https://arxiv.org/abs/2506.21071)
*Jingwei Wang,Zai Zhang,Hao Qian,Chunjing Gan,Binbin Hu,Ziqi Liu,Zhiqiang Zhang,Jun Zhou,Bin Shi,Bo Dong*

Main category: cs.LG

TL;DR: 知识图谱能生成高质量数据，显著提升大语言模型的工具使用能力。


<details>
  <summary>Details</summary>
Motivation: 目前大语言模型（LLMs）在工具使用方面面临挑战，主要原因在于其难以深入理解工具功能和用户意图。以往生成指令数据的方法质量不足。

Method: 提出了一种新方法，利用知识图谱生成高质量的指令数据。具体步骤包括从知识图谱中提取查询路径并转化为用户查询，将实体关系转化为可执行工具，并将查询路径解析为详细的解决方案步骤。

Result: 实验证明，仅用少量合成数据进行微调，就能显著提升大语言模型的工具利用率和整体能力。

Conclusion: 利用知识图谱生成高质量指令数据，是提升大语言模型工具使用能力的一种有效方法。

Abstract: Teaching large language models (LLMs) to use tools is crucial for improving
their problem-solving abilities and expanding their applications. However,
effectively using tools is challenging because it requires a deep understanding
of tool functionalities and user intentions. Previous methods relied mainly on
LLMs to generate instruction data, but the quality of these data was often
insufficient. In this paper, we propose a new method that uses knowledge graphs
to generate high-quality instruction data for LLMs. Knowledge graphs are
manually curated datasets rich in semantic information. We begin by extracting
various query pathways from a given knowledge graph, which are transformed into
a broad spectrum of user queries. We then translate the relationships between
entities into actionable tools and parse the pathways of each query into
detailed solution steps, thereby creating high-quality instruction data. Our
experiments show that fine-tuning on just a small sample of this synthetic data
can significantly improve the tool utilization and overall capabilities of
LLMs.

</details>


### [52] [Learning to Skip the Middle Layers of Transformers](https://arxiv.org/abs/2506.21103)
*Tim Lawson,Laurence Aitchison*

Main category: cs.LG

TL;DR: 该论文提出了一种新的Transformer架构，通过动态跳过中间层来提高效率，但实验结果显示，在验证交叉熵和FLOPs之间的权衡方面，与更少层的密集基线相比，没有实现改进。


<details>
  <summary>Details</summary>
Motivation: 现有条件计算方法通常针对单个模块或独立跳过层，但可解释性研究表明Transformer的中间层冗余度更高，早期层聚合信息。受此启发，本文旨在减少“更简单”token的计算需求，并可能促进多级表示层次结构的出现。

Method: 提出了一种新颖的架构，通过学习的门控机制根据输入动态跳过中心块的对称跨度，并通过门控注意力机制防止后续token关注跳过的token位置。残差范数通过“sandwich”或“perilayernorm”方案控制，门控稀疏性通过自适应正则化损失控制。

Result: 在所研究的规模下，与层数较少的密集基线相比，该方法在验证交叉熵和估计FLOPs之间的权衡方面并未实现改进。

Conclusion: 所提出的动态跳过中间层的Transformer架构，未能如预期般在计算效率上取得显著提升。

Abstract: Conditional computation is a popular strategy to make Transformers more
efficient. Existing methods often target individual modules (e.g.,
mixture-of-experts layers) or skip layers independently of one another.
However, interpretability research has demonstrated that the middle layers of
Transformers exhibit greater redundancy, and that early layers aggregate
information into token positions. Guided by these insights, we propose a novel
architecture that dynamically skips a variable number of layers from the middle
outward. In particular, a learned gating mechanism determines whether to bypass
a symmetric span of central blocks based on the input, and a gated attention
mechanism prevents subsequent tokens from attending to skipped token positions.
Residual norms are controlled with a 'sandwich' or 'perilayernorm' scheme and
gate sparsity with an adaptive regularization loss. We had aimed to reduce
compute requirements for 'simpler' tokens and potentially foster an emergent
multi-level representational hierarchy but, at the scales investigated, our
approach does not achieve improvements in the trade-off between validation
cross-entropy and estimated FLOPs compared to dense baselines with fewer
layers. We release our code at https://github.com/tim-lawson/skip-middle.

</details>


### [53] [Complexity-aware fine-tuning](https://arxiv.org/abs/2506.21220)
*Andrey Goncharov,Daniil Vyazhev,Petr Sychev,Edvard Khalafyan,Alexey Zaytsev*

Main category: cs.LG

TL;DR: 一种新的高效大语言模型微调方法，通过熵识别复杂数据进行推理，性能优于SFT，并与蒸馏法相当，同时减少了62%的数据量。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLMs）微调方法（如SFT）在特定领域表现不佳，而从大型模型中蒸馏思维链虽然能获得更好结果，但成本高昂且需要大量数据。本文旨在提出一种更高效的微调蓝图。

Method: 提出了一种新颖的、高效的微调蓝图，该蓝图仅对通过熵识别的复杂数据使用推理。具体来说，他们通过单个token答案熵将训练数据划分为复杂度类别，并通过SFT和蒸馏对LLMs进行微调。

Result: 该方法显著优于标准的SFT方法（平均准确率0.55 vs 0.43），并且在使用减少62%数据量的情况下，提供了与蒸馏相当的性能（两者平均准确率均为0.55）。

Conclusion: 本文提出了一种高效的微调方法，该方法根据数据复杂性选择性地应用推理，与传统方法相比，在更少的数据下实现了更好或可比的性能。

Abstract: General-purpose Large Language Models (LLMs) are frequently fine-tuned
through supervised fine-tuning (SFT) to enhance performance in specific
domains. Better results can be achieved by distilling the chain-of-thought of a
larger model at the cost of numerous expensive calls and a much greater amount
of data. We propose a novel blueprint for efficient fine-tuning that uses
reasoning only for complex data identified by entropy. Specifically, across two
small open models ($\approx 3B$) we split the training data into complexity
categories by a single token answer entropy (ROC AUC $0.73$), fine-tune large
language models (LLMs) via SFT and distillation, and show that our pipeline
significantly outperforms the standard SFT approach ($0.55$ vs $0.43$ average
accuracy) and provides comparable with distillation performance while using
$62\%$ less data ($0.55$ average accuracy for both). We publish our code and
data to facilitate further research in this direction.

</details>


### [54] [DiLoCoX: A Low-Communication Large-Scale Training Framework for Decentralized Cluster](https://arxiv.org/abs/2506.21263)
*Ji Qi,WenPeng Zhu,Li Li,Ming Wu,YingJun Wu,Wu He,Xun Gao,Jason Zeng,Michael Heinrich*

Main category: cs.LG

TL;DR: DiLoCoX是一个低通信量的大规模去中心化集群训练框架，它结合了多种策略，可以在慢速网络上对千亿参数模型进行预训练，相比传统方法实现了显著加速，同时保持了模型收敛性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的分布式训练需要高通信量，因此依赖于具有快速可靠互连的中心化集群。作者希望探索是否能在慢速网络上进行训练，从而在处理千亿参数模型时释放去中心化集群的潜力。

Method: 本文提出了DiLoCoX，一个低通信量的大规模去中心化集群训练框架。它结合了流水线并行、双优化器策略、通信与局部训练的一步延迟重叠以及自适应梯度压缩方案。

Result: DiLoCoX能够在1Gbps网络上预训练一个107B的基础模型。与传统的AllReduce相比，DiLoCoX在分布式训练中实现了357倍的加速，同时模型收敛性下降可忽略不计。

Conclusion: 据作者所知，这是第一个成功应用于超过1000亿参数模型的去中心化训练框架。

Abstract: The distributed training of foundation models, particularly large language
models (LLMs), demands a high level of communication. Consequently, it is
highly dependent on a centralized cluster with fast and reliable interconnects.
Can we conduct training on slow networks and thereby unleash the power of
decentralized clusters when dealing with models exceeding 100 billion
parameters? In this paper, we propose DiLoCoX, a low-communication large-scale
decentralized cluster training framework. It combines Pipeline Parallelism with
Dual Optimizer Policy, One-Step-Delay Overlap of Communication and Local
Training, and an Adaptive Gradient Compression Scheme. This combination
significantly improves the scale of parameters and the speed of model
pre-training. We justify the benefits of one-step-delay overlap of
communication and local training, as well as the adaptive gradient compression
scheme, through a theoretical analysis of convergence. Empirically, we
demonstrate that DiLoCoX is capable of pre-training a 107B foundation model
over a 1Gbps network. Compared to vanilla AllReduce, DiLoCoX can achieve a 357x
speedup in distributed training while maintaining negligible degradation in
model convergence. To the best of our knowledge, this is the first
decentralized training framework successfully applied to models with over 100
billion parameters.

</details>


### [55] [Latent Prototype Routing: Achieving Near-Perfect Load Balancing in Mixture-of-Experts](https://arxiv.org/abs/2506.21328)
*Jiajie Yang*

Main category: cs.LG

TL;DR: 为解决MoE模型中专家负载不平衡问题，本文提出了一种名为Latent Prototype Routing (LPR)的新型路由框架。LPR通过聚类视角重新审视专家路由，在不牺牲性能的前提下实现了近乎完美的负载均衡。


<details>
  <summary>Details</summary>
Motivation: 当前的MoE系统存在严重的负载不平衡问题，导致模型容量和计算资源的利用率低下。

Method: 本文从聚类视角重新审视了专家路由，并提出了Latent Prototype Routing (LPR)这一新颖的路由框架，该框架在推广现有方法的同时，促进了平衡的专家利用。

Result: LPR将专家负载的基尼系数从平均0.70降低到0.035，并将最小-最大专家负载比从1e-6提高到0.70，实现了近乎完美的负载均衡。该方法在DeepSeek-V3、Qwen3-MoE和Mixtral等多个开源MoE模型上进行了验证。

Conclusion: Latent Prototype Routing (LPR)有效解决了Mixture-of-Experts (MoE)架构中的负载不平衡问题，在不损害下游性能的情况下实现了近乎完美的负载均衡。

Abstract: Mixture-of-Experts (MoE) architectures have emerged as a key strategy for
scaling large language models (LLMs) efficiently. However, current MoE systems
suffer from severe load imbalance, where only a small subset of experts is
consistently activated during training and inference, leading to significant
underutilization of model capacity and computational resources. In this work,
we revisit expert routing through a clustering perspective and propose Latent
Prototype Routing (LPR), a novel routing framework that generalizes existing
approaches while promoting balanced expert utilization without compromising
downstream performance. Extensive experiments across multiple open-source MoE
models -- including DeepSeek-V3, Qwen3-MoE, and Mixtral -- demonstrate that LPR
reduces the Gini coefficient of expert load from 0.70 to 0.035 on average,
improves the min-max expert load ratio from 1e-6 to 0.70, achieving
near-perfect load balancing.

</details>


### [56] [Scalable Bayesian Low-Rank Adaptation of Large Language Models via Stochastic Variational Subspace Inference](https://arxiv.org/abs/2506.21408)
*Colin Samplawski,Adam D. Cobb,Manoj Acharya,Ramneet Kaur,Susmit Jha*

Main category: cs.LG

TL;DR: 为大型语言模型（LLMs）的LoRA参数提出了一种可扩展的贝叶斯方法（ScalaBL），它通过在低维子空间中进行推断，有效解决了不确定性量化的问题，同时显著减少了额外参数的需求。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）存在幻觉和校准不良的问题，这使得对这些模型进行不确定性量化至关重要，尤其是在高风险领域。现有方法虽然有效，但由于需要额外的参数，难以扩展到更大的LLMs。

Method: 本文提出了可伸缩贝叶斯低秩适应（ScalaBL），通过随机变分子空间推断。它在LoRA秩r的r维子空间中执行贝叶斯推断，并将LoRA参数重新用作投影矩阵，将子空间中的样本映射到LLM的完整权重空间中。使用随机变分推断学习所有参数。

Result: ScalaBL在仅需要约1000个额外参数的情况下，实现了与最先进方法相当的性能。此外，它成功扩展到迄今为止最大的贝叶斯LLM，其基础参数是先前工作的四倍。

Conclusion: ScalaBL提供了一种高效且可扩展的贝叶斯方法，用于解决大型语言模型的不确定性量化问题，显著降低了参数开销并提升了可扩展性。

Abstract: Despite their widespread use, large language models (LLMs) are known to
hallucinate incorrect information and be poorly calibrated. This makes the
uncertainty quantification of these models of critical importance, especially
in high-stakes domains, such as autonomy and healthcare. Prior work has made
Bayesian deep learning-based approaches to this problem more tractable by
performing inference over the low-rank adaptation (LoRA) parameters of a
fine-tuned model. While effective, these approaches struggle to scale to larger
LLMs due to requiring further additional parameters compared to LoRA. In this
work we present $\textbf{Scala}$ble $\textbf{B}$ayesian $\textbf{L}$ow-Rank
Adaptation via Stochastic Variational Subspace Inference (ScalaBL). We perform
Bayesian inference in an $r$-dimensional subspace, for LoRA rank $r$. By
repurposing the LoRA parameters as projection matrices, we are able to map
samples from this subspace into the full weight space of the LLM. This allows
us to learn all the parameters of our approach using stochastic variational
inference. Despite the low dimensionality of our subspace, we are able to
achieve competitive performance with state-of-the-art approaches while only
requiring ${\sim}1000$ additional parameters. Furthermore, it allows us to
scale up to the largest Bayesian LLM to date, with four times as a many base
parameters as prior work.

</details>
