<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 6]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Adverse Event Extraction from Discharge Summaries: A New Dataset, Annotation Scheme, and Initial Findings](https://arxiv.org/abs/2506.14900)
*Imane Guellil,Salomé Andres,Atul Anand,Bruce Guthrie,Huayu Zhang,Abul Hasan,Honghan Wu,Beatrice Alex*

Main category: cs.CL

TL;DR: 该研究提出了一个针对老年患者出院总结中不良事件（AE）提取的手动标注语料库。该语料库支持非连续和重叠实体。虽然粗粒度提取性能良好，但细粒度任务（特别是对于罕见事件）仍面临显著挑战，突显了检测未充分代表的AE的需求。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏用于老年患者出院总结中不良事件（AE）提取的手动标注语料库，老年患者群体在临床NLP资源中经常代表性不足。之前的研究也很少处理非连续和重叠实体等挑战。

Method: 本研究提出了一个手动标注的语料库，用于从老年患者出院总结中提取不良事件（AE）。该数据集包含14种临床上重要不良事件及其上下文属性。研究人员使用FlairNLP评估了多种模型，涵盖了三种标注粒度：细粒度、粗粒度以及带否定词的粗粒度。

Result: Transformer模型在文档级别的粗粒度提取上表现出色（F1 = 0.943），但在细粒度实体级别任务上性能显著下降（例如F1 = 0.675），特别是对于罕见事件和复杂属性。

Conclusion: 尽管取得了较高的分数，但在检测代表性不足的不良事件和捕获细微的临床语言方面仍然存在重大挑战。该数据集可作为评估AE提取方法的强大基准，并支持未来的跨数据集泛化。

Abstract: In this work, we present a manually annotated corpus for Adverse Event (AE)
extraction from discharge summaries of elderly patients, a population often
underrepresented in clinical NLP resources. The dataset includes 14 clinically
significant AEs-such as falls, delirium, and intracranial haemorrhage, along
with contextual attributes like negation, diagnosis type, and in-hospital
occurrence. Uniquely, the annotation schema supports both discontinuous and
overlapping entities, addressing challenges rarely tackled in prior work. We
evaluate multiple models using FlairNLP across three annotation granularities:
fine-grained, coarse-grained, and coarse-grained with negation. While
transformer-based models (e.g., BERT-cased) achieve strong performance on
document-level coarse-grained extraction (F1 = 0.943), performance drops
notably for fine-grained entity-level tasks (e.g., F1 = 0.675), particularly
for rare events and complex attributes. These results demonstrate that despite
high-level scores, significant challenges remain in detecting underrepresented
AEs and capturing nuanced clinical language. Developed within a Trusted
Research Environment (TRE), the dataset is available upon request via DataLoch
and serves as a robust benchmark for evaluating AE extraction methods and
supporting future cross-dataset generalisation.

</details>


### [2] [Combining Constrained and Unconstrained Decoding via Boosting: BoostCD and Its Application to Information Extraction](https://arxiv.org/abs/2506.14901)
*Marija Šakota,Robert West*

Main category: cs.CL

TL;DR: 为解决自回归语言模型在受限解码时输出质量低的问题，本研究提出了Boosted Constrained Decoding (BoostCD) 方法，通过结合受限与非受限解码，显著提升了结构化NLP任务的性能，并在信息抽取任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前结构化NLP任务中，自回归语言模型在训练时不感知约束条件，尽管这允许动态约束，但在测试阶段进行受限解码时可能导致输出质量低下。

Method: 提出了一种名为Boosted Constrained Decoding (BoostCD) 的两阶段解码方法。第一阶段，基础模型M分别进行受限和非受限解码，得到两个初步预测。第二阶段，一个学习到的自回归增强模型结合这两个初步预测，生成最终预测。

Result: 将BoostCD应用于封闭信息抽取，得到的模型BoostIE在分布内和分布外性能均优于现有方法，并解决了这些方法中常见的错误。

Conclusion: BoostCD通过结合受限和非受限解码，有效利用了基础模型在不同模式下犯错的互补性，从而显著提高了结构化NLP任务的性能。

Abstract: Many recent approaches to structured NLP tasks use an autoregressive language
model $M$ to map unstructured input text $x$ to output text $y$ representing
structured objects (such as tuples, lists, trees, code, etc.), where the
desired output structure is enforced via constrained decoding. During training,
these approaches do not require the model to be aware of the constraints, which
are merely implicit in the training outputs $y$. This is advantageous as it
allows for dynamic constraints without requiring retraining, but can lead to
low-quality output during constrained decoding at test time. We overcome this
problem with Boosted Constrained Decoding (BoostCD), which combines constrained
and unconstrained decoding in two phases: Phase 1 decodes from the base model
$M$ twice, in constrained and unconstrained mode, obtaining two weak
predictions. In phase 2, a learned autoregressive boosted model combines the
two weak predictions into one final prediction. The mistakes made by the base
model with vs. without constraints tend to be complementary, which the boosted
model learns to exploit for improved performance. We demonstrate the power of
BoostCD by applying it to closed information extraction. Our model, BoostIE,
outperforms prior approaches both in and out of distribution, addressing
several common errors identified in those approaches.

</details>


### [3] [CrEst: Credibility Estimation for Contexts in LLMs via Weak Supervision](https://arxiv.org/abs/2506.14912)
*Dyah Adila,Shuai Zhang,Boran Han,Bonan Min,Yuyang Wang*

Main category: cs.CL

TL;DR: CrEst是一个新的弱监督框架，通过评估文档间的语义一致性来自动评估LLM上下文文档的可信度，显著提高了LLM在知识密集型任务上的性能，尤其在高噪声环境下表现稳健。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了上下文文档可信度差异大的问题，可能导致不可靠信息的传播。

Method: 引入CrEst，一个新型弱监督框架，用于在LLM推理过程中评估上下文文档的可信度，无需手动标注。基于可信文档与其他可信文档语义一致性更高的洞察，通过文档间一致性实现自动可信度评估。提出了两种整合策略：黑盒方法和白盒方法。

Result: 在三种模型架构和五个数据集上，CrEst持续优于现有基线，准确率提高高达26.86%，F1分数提高3.49%。在高度噪声条件下仍保持稳健性能。

Conclusion: CrEst有效解决了LLM推理中上下文文档可信度评估的问题，显著提升了模型性能，并在复杂环境下表现稳健。

Abstract: The integration of contextual information has significantly enhanced the
performance of large language models (LLMs) on knowledge-intensive tasks.
However, existing methods often overlook a critical challenge: the credibility
of context documents can vary widely, potentially leading to the propagation of
unreliable information. In this paper, we introduce CrEst, a novel weakly
supervised framework for assessing the credibility of context documents during
LLM inference--without requiring manual annotations. Our approach is grounded
in the insight that credible documents tend to exhibit higher semantic
coherence with other credible documents, enabling automated credibility
estimation through inter-document agreement. To incorporate credibility into
LLM inference, we propose two integration strategies: a black-box approach for
models without access to internal weights or activations, and a white-box
method that directly modifies attention mechanisms. Extensive experiments
across three model architectures and five datasets demonstrate that CrEst
consistently outperforms strong baselines, achieving up to a 26.86% improvement
in accuracy and a 3.49% increase in F1 score. Further analysis shows that CrEst
maintains robust performance even under high-noise conditions.

</details>


### [4] [MDBench: A Synthetic Multi-Document Reasoning Benchmark Generated with Knowledge Guidance](https://arxiv.org/abs/2506.14927)
*Joseph J. Peper,Wenzhao Qiu,Ali Payani,Lu Wang*

Main category: cs.CL

TL;DR: 该论文介绍了MDBench，一个用于评估大型语言模型（LLMs）多文档推理能力的新数据集。MDBench通过新颖的合成生成过程创建，旨在解决现有基准稀缺和标注成本高昂的问题。实验表明，MDBench对现有LLMs构成了显著挑战，并且其生成方法支持有针对性的分析和快速适应。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在处理长上下文输入方面能力日益增强，但在多文档（MD）推理领域，缺乏足够严格的评估基准。此外，由于长文本标注成本高昂，多文档基准的创建面临挑战。

Method: 本文引入了MDBench数据集，通过新颖的合成生成过程创建，以可控且高效的方式生成具有挑战性的文档集和相应的问答（QA）示例。该方法基于浓缩的结构化种子知识，通过LLM辅助编辑引入多文档特有的推理挑战，然后将这些结构化知识转换为自然文本形式。

Result: MDBench对所有流行的LLMs和提示技术都构成了重大挑战，即使文档集相对较短。此外，所提出的知识引导生成技术（1）能够对MD特定推理能力进行有针对性的分析，并且（2）可以快速适应新的挑战和未来的模型改进。

Conclusion: MDBench是一个有效且具有挑战性的多文档推理评估基准，其合成生成方法克服了传统基准创建成本高昂的问题。该研究揭示了当前LLMs在多文档推理方面的局限性，并提供了一种适应性强的分析工具。

Abstract: Natural language processing evaluation has made significant progress, largely
driven by the proliferation of powerful large language mod-els (LLMs). New
evaluation benchmarks are of increasing priority as the reasoning capabilities
of LLMs are expanding at a rapid pace. In particular, while multi-document (MD)
reasoning is an area of extreme relevance given LLM capabilities in handling
longer-context inputs, few benchmarks exist to rigorously examine model
behavior in this setting. Moreover, the multi-document setting is historically
challenging for benchmark creation due to the expensive cost of annotating long
inputs. In this work, we introduce MDBench, a new dataset for evaluating LLMs
on the task of multi-document reasoning. Notably, MDBench is created through a
novel synthetic generation process, allowing us to controllably and efficiently
generate challenging document sets and the corresponding question-answer (QA)
examples. Our novel technique operates on condensed structured seed knowledge,
modifying it through LLM-assisted edits to induce MD-specific reasoning
challenges. We then convert this structured knowledge into a natural text
surface form, generating a document set and corresponding QA example. We
analyze the behavior of popular LLMs and prompting techniques, finding that
MDBENCH poses significant challenges for all methods, even with relatively
short document sets. We also see our knowledge-guided generation technique (1)
allows us to readily perform targeted analysis of MD-specific reasoning
capabilities and (2) can be adapted quickly to account for new challenges and
future modeling improvements.

</details>


### [5] [From Chat to Checkup: Can Large Language Models Assist in Diabetes Prediction?](https://arxiv.org/abs/2506.14949)
*Shadman Sakib,Oishy Fatema Akhand,Ajwad Abrar*

Main category: cs.CL

TL;DR: 本研究探讨大型语言模型（LLMs）在糖尿病预测中的应用，发现专有LLMs优于开源LLMs，部分LLMs甚至超越了传统机器学习模型。


<details>
  <summary>Details</summary>
Motivation: 目前机器学习（ML）和深度学习（DL）模型已广泛用于糖尿病预测，但大型语言模型（LLMs）在结构化数值数据上的应用探索不足。

Method: 本研究通过零样本、单样本和三样本提示方法，测试了六种LLMs（包括四种开源模型和两种专有模型）在Pima印第安糖尿病数据库（PIDD）上预测糖尿病的有效性。同时，将LLMs的性能与三种传统机器学习模型（随机森林、逻辑回归和支持向量机）进行了比较，评估指标包括准确率、精确率、召回率和F1分数。

Result: 研究结果显示，专有LLMs的表现优于开源LLMs，其中GPT-4o和Gemma-2-27B在少样本设置中获得了最高的准确率。值得注意的是，Gemma-2-27B在F1分数方面也超越了传统机器学习模型。然而，仍存在提示策略间性能差异以及需要进行领域特定微调等问题。

Conclusion: 本研究表明LLMs可用于医疗预测任务，并鼓励未来的研究在提示工程和混合方法方面进行探索，以改进医疗健康预测。

Abstract: While Machine Learning (ML) and Deep Learning (DL) models have been widely
used for diabetes prediction, the use of Large Language Models (LLMs) for
structured numerical data is still not well explored. In this study, we test
the effectiveness of LLMs in predicting diabetes using zero-shot, one-shot, and
three-shot prompting methods. We conduct an empirical analysis using the Pima
Indian Diabetes Database (PIDD). We evaluate six LLMs, including four
open-source models: Gemma-2-27B, Mistral-7B, Llama-3.1-8B, and Llama-3.2-2B. We
also test two proprietary models: GPT-4o and Gemini Flash 2.0. In addition, we
compare their performance with three traditional machine learning models:
Random Forest, Logistic Regression, and Support Vector Machine (SVM). We use
accuracy, precision, recall, and F1-score as evaluation metrics. Our results
show that proprietary LLMs perform better than open-source ones, with GPT-4o
and Gemma-2-27B achieving the highest accuracy in few-shot settings. Notably,
Gemma-2-27B also outperforms the traditional ML models in terms of F1-score.
However, there are still issues such as performance variation across prompting
strategies and the need for domain-specific fine-tuning. This study shows that
LLMs can be useful for medical prediction tasks and encourages future work on
prompt engineering and hybrid approaches to improve healthcare predictions.

</details>


### [6] [Memory Tokens: Large Language Models Can Generate Reversible Sentence Embeddings](https://arxiv.org/abs/2506.15001)
*Ignacio Sastre,Aiala Rosá*

Main category: cs.CL

TL;DR: 通过优化特殊记忆token的嵌入，LLM无需修改模型权重即可精确重建原始文本，展示了LLM的新能力，在记忆检索、压缩和受控文本生成方面有潜在应用。


<details>
  <summary>Details</summary>
Motivation: 探索一种无需修改LLM模型权重即可生成可逆句子嵌入的方法，使LLM能够精确重建原始文本。

Method: 引入一个特殊的记忆token，通过在固定序列上训练来优化其嵌入。当用这个嵌入进行提示时，模型能够精确重建该固定序列。

Result: 在英语和西班牙语数据集上，对长达约240个token的序列以及从100M到8B参数的模型进行了评估。Llama 3.1 8B成功重建了所有测试序列。

Conclusion: 研究结果突出了LLM的一项有趣能力，并表明其在基于记忆的检索、压缩和受控文本生成方面具有潜在应用。

Abstract: In this work, we observe an interesting phenomenon: it is possible to
generate reversible sentence embeddings that allow an LLM to reconstruct the
original text exactly, without modifying the model's weights. This is achieved
by introducing a special memory token, whose embedding is optimized through
training on a fixed sequence. When prompted with this embedding, the model
reconstructs the fixed sequence exactly. We evaluate this phenomenon across
English and Spanish datasets, sequences of up to approximately 240 tokens, and
model scales ranging from 100M to 8B parameters. Notably, Llama 3.1 8B
successfully reconstructs all tested sequences. Our findings highlight an
interesting capability of LLMs and suggest potential applications in
memory-based retrieval, compression, and controlled text generation.

</details>
