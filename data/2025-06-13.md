<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 7]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [A Survey of Automatic Evaluation Methods on Text, Visual and Speech Generations](https://arxiv.org/abs/2506.10019)
*Tian Lan,Yang-Hao Zhou,Zi-Ao Ma,Fanshu Sun,Rui-Qing Sun,Junyu Luo,Rong-Cheng Tu,Heyan Huang,Chen Xu,Zhijing Wu,Xian-Ling Mao*

Main category: cs.CL

TL;DR: 这篇论文全面回顾并统一了文本、图像和音频生成内容的自动评估方法，提出了五种基本范式，并讨论了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在生成式AI方面取得了显著进展，但自动评估生成内容的质量仍面临挑战，且现有研究缺乏一个系统性的框架来组织跨文本、视觉和音频模态的评估方法。

Method: 本文对跨文本、视觉和音频模态的生成内容自动评估方法进行了全面回顾和统一分类。文章识别了表征现有评估方法的五种基本范式，并从文本生成评估方法（最成熟）开始，将框架扩展到图像和音频生成。

Result: 建立了一个统一的自动评估方法分类体系，涵盖文本、图像和音频模态，并识别了五种基本评估范式，展示了其广泛适用性。

Conclusion: 讨论了跨模态评估方法未来研究的 promising directions。

Abstract: Recent advances in deep learning have significantly enhanced generative AI
capabilities across text, images, and audio. However, automatically evaluating
the quality of these generated outputs presents ongoing challenges. Although
numerous automatic evaluation methods exist, current research lacks a
systematic framework that comprehensively organizes these methods across text,
visual, and audio modalities. To address this issue, we present a comprehensive
review and a unified taxonomy of automatic evaluation methods for generated
content across all three modalities; We identify five fundamental paradigms
that characterize existing evaluation approaches across these domains. Our
analysis begins by examining evaluation methods for text generation, where
techniques are most mature. We then extend this framework to image and audio
generation, demonstrating its broad applicability. Finally, we discuss
promising directions for future research in cross-modal evaluation
methodologies.

</details>


### [2] [TaskCraft: Automated Generation of Agentic Tasks](https://arxiv.org/abs/2506.10055)
*Dingfeng Shi,Jingyi Cao,Qianben Chen,Weichen Sun,Weizhen Li,Hongxuan Lu,Fangchen Dong,Tianrui Qin,King Zhu,Minghao Yang,Jian Yang,Ge Zhang,Jiaheng Liu,Changwang Zhang,Jun Wang,Yuchen Eleanor Jiang,Wangchunshu Zhou*

Main category: cs.CL

TL;DR: TaskCraft是一个自动化工作流，能生成可扩展、多工具的智能体任务，解决了现有数据不足的问题，并有助于智能体模型的训练。


<details>
  <summary>Details</summary>
Motivation: 现有的指令数据缺乏工具交互，当前的智能体基准测试依赖于昂贵的人工标注，限制了其可扩展性。智能体任务在NLP和AI领域变得越来越重要。

Method: 本文提出了TaskCraft，一个自动化的工作流程，用于生成难度可扩展、多工具且可验证的智能体任务及执行轨迹。它通过深度和宽度扩展来创建结构和层次复杂的挑战。

Result: 实验结果表明，这些任务改进了生成工作流程中的提示优化，并增强了智能体基础模型的监督微调。作者提出了一个包含约36,000个不同难度任务的大规模合成数据集。

Conclusion: TaskCraft通过提供自动化、可扩展的智能体任务生成方案，解决了现有数据和基准测试的局限性，并被证明对提示优化和智能体模型微调有益，同时为未来研究提供了有价值的数据集。

Abstract: Agentic tasks, which require multi-step problem solving with autonomy, tool
use, and adaptive reasoning, are becoming increasingly central to the
advancement of NLP and AI. However, existing instruction data lacks tool
interaction, and current agentic benchmarks rely on costly human annotation,
limiting their scalability. We introduce \textsc{TaskCraft}, an automated
workflow for generating difficulty-scalable, multi-tool, and verifiable agentic
tasks with execution trajectories. TaskCraft expands atomic tasks using
depth-based and width-based extensions to create structurally and
hierarchically complex challenges. Empirical results show that these tasks
improve prompt optimization in the generation workflow and enhance supervised
fine-tuning of agentic foundation models. We present a large-scale synthetic
dataset of approximately 36,000 tasks with varying difficulty to support future
research on agent tuning and evaluation.

</details>


### [3] [A quantum semantic framework for natural language processing](https://arxiv.org/abs/2506.10077)
*Christopher J. Agostino,Quan Le Thien,Molly Apsel,Denizhan Pak,Elina Lesyk,Ashabari Majumdar*

Main category: cs.CL

TL;DR: 语义退化使得LLM难以恢复单一意义。本文通过对LLM进行语义贝尔不等式测试，表明语言解释具有观察者依赖性，并展现出非经典语境性，提出贝叶斯方法优于经典频率学方法来表征语言意义。


<details>
  <summary>Details</summary>
Motivation: 抽象指出语义退化是自然语言的基本属性，随着语义表达复杂性的增加，解释代理（包括人类和LLM）恢复单一预期意义的可能性会消失，这挑战了语言形式本身具有意义的经典观点。

Method: 运用柯尔莫哥罗夫复杂性理论，论证随着表达复杂性增加，解释代理恢复单一预期意义的可能性消失；提出意义是通过依赖于观察者的解释行为实现的；使用不同的LLM代理作为“计算认知系统”，在不同的语境设置下解释模糊的词对，进行语义贝尔不等式测试。

Result: 平均CHSH期望值范围为1.2到2.8；多个运行结果（例如2.3-2.4）显著违反了经典边界($|S|\leq2$)；这表明在模糊性下的语言解释可以表现出非经典的语境依赖性，与人类认知实验结果一致。

Conclusion: 基于经典频率论的自然语言分析方法必然是有损的；贝叶斯风格的重复采样方法可以为上下文中的语言意义提供更实用和恰当的表征。

Abstract: Semantic degeneracy represents a fundamental property of natural language
that extends beyond simple polysemy to encompass the combinatorial explosion of
potential interpretations that emerges as semantic expressions increase in
complexity. Large Language Models (LLMs) and other modern NLP systems face
inherent limitations precisely because they operate within natural language
itself, making them subject to the same interpretive constraints imposed by
semantic degeneracy. In this work, we argue using Kolmogorov complexity that as
an expression's complexity grows, the likelihood of any interpreting agent
(human or LLM-powered AI) recovering the single intended meaning vanishes. This
computational intractability suggests the classical view that linguistic forms
possess meaning in and of themselves is flawed. We alternatively posit that
meaning is instead actualized through an observer-dependent interpretive act.
To test this, we conducted a semantic Bell inequality test using diverse LLM
agents as ``computational cognitive systems'' to interpret ambiguous word pairs
under varied contextual settings. Across several independent experiments, we
found average CHSH expectation values ranging from 1.2 to 2.8, with several
runs yielding values (e.g., 2.3-2.4) that significantly violate the classical
boundary ($|S|\leq2$). This demonstrates that linguistic interpretation under
ambiguity can exhibit non-classical contextuality, consistent with results from
human cognition experiments. These results inherently imply that classical
frequentist-based analytical approaches for natural language are necessarily
lossy. Instead, we propose that Bayesian-style repeated sampling approaches can
provide more practically useful and appropriate characterizations of linguistic
meaning in context.

</details>


### [4] [Chat-of-Thought: Collaborative Multi-Agent System for Generating Domain Specific Information](https://arxiv.org/abs/2506.10086)
*Christodoulos Constantinides,Shuxin Lin,Nianjun Zhou,Dhaval Patel*

Main category: cs.CL

TL;DR: Chat-of-Thought是一个多智能体LLM系统，通过多角色讨论和动态任务路由，优化工业FMEA文档的生成和验证。


<details>
  <summary>Details</summary>
Motivation: 解决工业资产故障模式与影响分析（FMEA）文档生成中的挑战。

Method: 提出了一种新颖的多智能体系统Chat-of-Thought，该系统利用多个基于LLM的协作智能体，通过特定角色、先进AI技术和动态任务路由来优化FMEA表格的生成和验证。核心创新是引入“思维聊天”，通过动态、多角色驱动的讨论实现内容的迭代完善。

Result: Chat-of-Thought系统能够优化FMEA表格的生成和验证，并通过交互式、模板驱动的工作流程和上下文感知的智能体协作，在工业设备监控领域展示了解决挑战的潜力。

Conclusion: Chat-of-Thought系统通过其独特的多智能体协作和迭代完善机制，为工业资产FMEA文档的生成提供了一个有效且有潜力的解决方案。

Abstract: This paper presents a novel multi-agent system called Chat-of-Thought,
designed to facilitate the generation of Failure Modes and Effects Analysis
(FMEA) documents for industrial assets. Chat-of-Thought employs multiple
collaborative Large Language Model (LLM)-based agents with specific roles,
leveraging advanced AI techniques and dynamic task routing to optimize the
generation and validation of FMEA tables. A key innovation in this system is
the introduction of a Chat of Thought, where dynamic, multi-persona-driven
discussions enable iterative refinement of content. This research explores the
application domain of industrial equipment monitoring, highlights key
challenges, and demonstrates the potential of Chat-of-Thought in addressing
these challenges through interactive, template-driven workflows and
context-aware agent collaboration.

</details>


### [5] [When Meaning Stays the Same, but Models Drift: Evaluating Quality of Service under Token-Level Behavioral Instability in LLMs](https://arxiv.org/abs/2506.10095)
*Xiao Li,Joel Kreuzwieser,Alan Peters*

Main category: cs.CL

TL;DR: 大语言模型对语义相同但表征不同的提示符表现出行为漂移。本文提出了PBSS框架来衡量这种漂移，发现模型在分词和解码方面存在一致的响应变化，这揭示了模型评估稳定性的一个被忽视的维度。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型如何响应仅在分词层面不同但语义意图相同的提示符（即提示符变异现象）。

Method: 提出了“基于提示符的语义偏移”（PBSS）诊断框架，用于衡量大语言模型在语义等效的提示符重述下的行为漂移，并将其应用于十个受限任务。

Result: PBSS揭示了持续的、模型特定的响应偏移，这表明与分词和解码相关的统计规律。

Conclusion: 这些结果突出了模型在复述下评估稳定性的一个被忽视的维度，并表明分词策略和解码动态可能导致训练后的服务质量不稳定。

Abstract: We investigate how large language models respond to prompts that differ only
in their token-level realization but preserve the same semantic intent, a
phenomenon we call prompt variance. We propose Prompt-Based Semantic Shift
(PBSS), a diagnostic framework for measuring behavioral drift in LLMs under
semantically equivalent prompt rewordings. Applied to ten constrained tasks,
PBSS reveals consistent, model-specific response shifts, suggesting statistical
regularities linked to tokenization and decoding. These results highlight an
overlooked dimension of model evaluation stability under rephrasing and suggest
that tokenization strategies and decoding dynamics may contribute to
post-training quality of service instability.

</details>


### [6] [ChartReasoner: Code-Driven Modality Bridging for Long-Chain Reasoning in Chart Question Answering](https://arxiv.org/abs/2506.10116)
*Caijun Jia,Nan Xu,Jingxuan Wei,Qingli Wang,Lei Wang,Bihui Yu,Junnan Zhu*

Main category: cs.CL

TL;DR: ChartReasoner是一个代码驱动的两阶段框架，通过将图表图像转换为ECharts代码来提高视觉推理能力，解决了现有方法在图表细节保留上的不足，并在多个基准测试中取得了与顶尖模型相媲美的性能，同时参数更少。


<details>
  <summary>Details</summary>
Motivation: 现有方法在图表视觉推理中通过图像到文本的转换会丢失关键的结构和语义信息，导致无法将大型语言模型的长链推理能力有效扩展到视觉推理任务。

Method: 提出ChartReasoner，一个代码驱动的两阶段框架。首先，训练高保真模型将图表图像转换为结构化的ECharts代码。其次，设计一个通用的图表推理数据合成管线，利用预训练的传输模型自动生成推理轨迹并使用代码验证器过滤低质量样本。最后，结合监督微调和强化学习在合成数据集上训练最终的多模态模型。

Result: 在四个公共基准测试上的实验结果清晰地证明了ChartReasoner的有效性。它能最大程度保留图表原始细节，并以更少的参数达到与最先进的开源模型相当的性能，甚至在域外设置中接近GPT-4o等专有系统的性能。

Conclusion: ChartReasoner能够尽可能保留图表的原始细节，并在性能上与最先进的开源模型相媲美，同时使用更少的参数，在域外设置中接近GPT-4o等专有系统的性能。

Abstract: Recently, large language models have shown remarkable reasoning capabilities
through long-chain reasoning before responding. However, how to extend this
capability to visual reasoning tasks remains an open challenge. Existing
multimodal reasoning approaches transfer such visual reasoning task into
textual reasoning task via several image-to-text conversions, which often lose
critical structural and semantic information embedded in visualizations,
especially for tasks like chart question answering that require a large amount
of visual details. To bridge this gap, we propose ChartReasoner, a code-driven
novel two-stage framework designed to enable precise, interpretable reasoning
over charts. We first train a high-fidelity model to convert diverse chart
images into structured ECharts codes, preserving both layout and data semantics
as lossless as possible. Then, we design a general chart reasoning data
synthesis pipeline, which leverages this pretrained transport model to
automatically and scalably generate chart reasoning trajectories and utilizes a
code validator to filter out low-quality samples. Finally, we train the final
multimodal model using a combination of supervised fine-tuning and
reinforcement learning on our synthesized chart reasoning dataset and
experimental results on four public benchmarks clearly demonstrate the
effectiveness of our proposed ChartReasoner. It can preserve the original
details of the charts as much as possible and perform comparably with
state-of-the-art open-source models while using fewer parameters, approaching
the performance of proprietary systems like GPT-4o in out-of-domain settings.

</details>


### [7] [Unsupervised Elicitation of Language Models](https://arxiv.org/abs/2506.10139)
*Jiaxin Wen,Zachary Ankner,Arushi Somani,Peter Hase,Samuel Marks,Jacob Goldman-Wetzler,Linda Petrini,Henry Sleight,Collin Burns,He He,Shi Feng,Ethan Perez,Jan Leike*

Main category: cs.CL

TL;DR: ICM是一种无需外部监督的无监督算法，通过模型自我生成标签来微调预训练语言模型，在多项任务上表现优于人类监督，并能更好地激发超人能力，提升前沿语言模型的训练效果。


<details>
  <summary>Details</summary>
Motivation: 当前预训练语言模型的微调范式依赖人类指定期望行为，但对于具有超人能力的模型，获取高质量的人类监督变得困难或不可能。

Method: 内部一致性最大化（ICM）算法，该算法通过语言模型自身生成的标签进行微调，无需外部监督。

Result: 在GSM8k-verification、TruthfulQA和Alpaca奖励建模任务上，ICM方法达到了黄金监督训练的性能，并优于众包人类监督训练。该方法能显著优于人类标签，更好地激发语言模型的超人能力。此外，通过ICM训练的无监督奖励模型和基于Claude 3.5 Haiku的助手都超越了其人类监督的对应物。

Conclusion: ICM是一种有效的无监督方法，通过利用模型自我生成的标签来微调语言模型，尤其适用于具有超人能力的模型，并能显著提升前沿语言模型的训练效果。

Abstract: To steer pretrained language models for downstream tasks, today's
post-training paradigm relies on humans to specify desired behaviors. However,
for models with superhuman capabilities, it is difficult or impossible to get
high-quality human supervision. To address this challenge, we introduce a new
unsupervised algorithm, Internal Coherence Maximization (ICM), to fine-tune
pretrained language models on their own generated labels, \emph{without
external supervision}. On GSM8k-verification, TruthfulQA, and Alpaca reward
modeling tasks, our method matches the performance of training on golden
supervision and outperforms training on crowdsourced human supervision. On
tasks where LMs' capabilities are strongly superhuman, our method can elicit
those capabilities significantly better than training on human labels. Finally,
we show that our method can improve the training of frontier LMs: we use our
method to train an unsupervised reward model and use reinforcement learning to
train a Claude 3.5 Haiku-based assistant. Both the reward model and the
assistant outperform their human-supervised counterparts.

</details>
