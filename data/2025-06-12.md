<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [LLM-as-a-qualitative-judge: automating error analysis in natural language generation](https://arxiv.org/abs/2506.09147)
*Nadezhda Chirkova,Tunde Oluwaseyi Ajayi,Seth Aycock,Zain Muhammad Mujahid,Vladana Perlić,Ekaterina Borisova,Markarit Vartampetian*

Main category: cs.CL

TL;DR: 该论文提出了一种名为"LLM-as-a-qualitative-judge"的方法，用于对自然语言生成（NLG）系统进行定性评估，通过生成结构化的常见问题报告，而非仅仅是数值分数。实验结果表明，该方法能有效识别问题并生成与人类标注者相似的错误类型报告。


<details>
  <summary>Details</summary>
Motivation: 现有的"LLM-as-a-judge"方法主要侧重于定量评估，即输出数值分数，但这种方式无法为开发者提供关于NLG系统具体改进方向的深入见解。

Method: 本文提出了一种名为"LLM-as-a-qualitative-judge"的基于LLM的评估方法，其主要输出是NLG系统输出中常见问题类型的结构化报告。该方法包括两个主要步骤：开放式逐实例问题分析和使用直观的累积算法对发现的问题进行聚类。此外，还引入了一种评估该方法的策略，并提供了来自12个NLG数据集的约300个实例问题标注。

Result: 实验结果表明，"LLM-as-a-qualitative-judge"在2/3的情况下能正确识别实例特定问题，并且能够生成与人类标注者撰写的报告相似的错误类型报告。

Conclusion: LLM-as-a-qualitative-judge为开发者提供了关于NLG系统可以进行哪些改进的有意义的见解，通过提供定性错误分析，并且在识别和分类问题方面表现出与人类标注相当的性能。

Abstract: Prompting large language models (LLMs) to evaluate generated text, known as
LLM-as-a-judge, has become a standard evaluation approach in natural language
generation (NLG), but is primarily used as a quantitative tool, i.e. with
numerical scores as main outputs. In this work, we propose
LLM-as-a-qualitative-judge, an LLM-based evaluation approach with the main
output being a structured report of common issue types in the NLG system
outputs. Our approach is targeted at providing developers with meaningful
insights on what improvements can be done to a given NLG system and consists of
two main steps, namely open-ended per-instance issue analysis and clustering of
the discovered issues using an intuitive cumulative algorithm. We also
introduce a strategy for evaluating the proposed approach, coupled with ~300
annotations of issues in instances from 12 NLG datasets. Our results show that
LLM-as-a-qualitative-judge correctly recognizes instance-specific issues in 2/3
cases and is capable of producing error type reports resembling the reports
composed by human annotators. Our code and data are publicly available at
https://github.com/tunde-ajayi/llm-as-a-qualitative-judge.

</details>
